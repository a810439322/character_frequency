#!/usr/bin/env python
# -*- coding: utf-8 -*-
# author: è™ç æ–°æ‰‹2ç¾¤-ä¹Ÿæ— é£é›¨ä¹Ÿæ— æ™´
"""
å­—é¢‘ç»Ÿè®¡è„šæœ¬
åŠŸèƒ½ï¼šç»Ÿè®¡txtæ–‡ä»¶ä¸­æ¯ä¸ªå­—çš„å‡ºç°æ¬¡æ•°ï¼Œå¹¶æŒ‰ç…§dictå­—åºæ’åº
"""

import os
import sys
import io
import unicodedata
from collections import Counter

# å°è¯•å¯¼å…¥æ•°æ®åº“ä¸Šä¼ æ¨¡å—ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
try:
    from db_uploader import handle_database_upload
    DB_UPLOAD_AVAILABLE = True
except ImportError:
    DB_UPLOAD_AVAILABLE = False

# ä¿®å¤Windowsæ§åˆ¶å°UTF-8æ˜¾ç¤ºé—®é¢˜ï¼ˆæ”¯æŒæ˜Ÿæ˜Ÿâ˜…ç­‰ç‰¹æ®Šç¬¦å·ï¼‰
if sys.platform == 'win32':
    try:
        # è®¾ç½®æ§åˆ¶å°ä»£ç é¡µä¸ºUTF-8
        import ctypes
        kernel32 = ctypes.windll.kernel32
        kernel32.SetConsoleOutputCP(65001)  # UTF-8
        kernel32.SetConsoleCP(65001)

        # é‡æ–°åŒ…è£…stdoutå’Œstderrä¸ºUTF-8
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    except Exception as e:
        # å¦‚æœè®¾ç½®å¤±è´¥ï¼Œå°è¯•åŸºæœ¬çš„UTF-8åŒ…è£…
        try:
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
            sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
        except:
            pass
        print(f"è­¦å‘Šï¼šæ§åˆ¶å°UTF-8è®¾ç½®å¯èƒ½ä¸å®Œæ•´ï¼ˆ{e}ï¼‰ï¼ŒæŸäº›ç¬¦å·å¯èƒ½æ— æ³•æ­£ç¡®æ˜¾ç¤º")


# ============================================================================
# ã€éš¾åº¦è¯„åˆ†é…ç½®å‚æ•°ã€‘ - å¯ä»¥åœ¨è¿™é‡Œè°ƒæ•´æ‰€æœ‰è¯„åˆ†å‚æ•°
# ============================================================================

# 1. è¦†ç›–ç‡è¯„åˆ†æƒé‡
WEIGHT_COVERAGE_500 = 10      # å‰500å­—è¦†ç›–ç‡æƒé‡
WEIGHT_COVERAGE_1000 = 10     # å‰1000å­—è¦†ç›–ç‡æƒé‡
WEIGHT_COVERAGE_1500 = 20     # å‰1500å­—è¦†ç›–ç‡æƒé‡

# 2. å­—æ•°éœ€æ±‚è¯„åˆ†æƒé‡
WEIGHT_CHARS_95 = 0          # 95%è¦†ç›–æ‰€éœ€å­—æ•°æƒé‡
WEIGHT_CHARS_99 = 0          # 99%è¦†ç›–æ‰€éœ€å­—æ•°æƒé‡

# 3. å­—åºè¯„åˆ†æƒé‡
WEIGHT_ORDER_95 = 50          # 95%å¹³å‡å­—åºæƒé‡
WEIGHT_ORDER_99 = 30          # 99%å¹³å‡å­—åºæƒé‡

# 4. å­—ç§æ•°è¯„åˆ†æƒé‡
WEIGHT_CHAR_TYPES = 10         # å­—ç§æ•°æƒé‡

# ===========================åŒºé—´=================================================
# 5. å­—æ•°éœ€æ±‚è¯„åˆ†åŒºé—´
CHARS_95_MIN = 300            # 95%è¦†ç›–å­—æ•°ä¸‹é™ï¼ˆâ‰¤æ­¤å€¼å¾—0åˆ†ï¼‰
CHARS_95_MAX = 2500           # 95%è¦†ç›–å­—æ•°ä¸Šé™ï¼ˆâ‰¥æ­¤å€¼å¾—æ»¡åˆ†ï¼‰
CHARS_99_MIN = 400           # 99%è¦†ç›–å­—æ•°ä¸‹é™
CHARS_99_MAX = 4000           # 99%è¦†ç›–å­—æ•°ä¸Šé™

# 6. å­—åºè¯„åˆ†åŒºé—´
ORDER_95_MIN = 400            # 95%å¹³å‡å­—åºä¸‹é™ï¼ˆâ‰¤æ­¤å€¼å¾—0åˆ†ï¼Œè¡¨ç¤ºå¾ˆå¸¸ç”¨ï¼‰
ORDER_95_MAX = 2000           # 95%å¹³å‡å­—åºä¸Šé™ï¼ˆâ‰¥æ­¤å€¼å¾—æ»¡åˆ†ï¼Œè¡¨ç¤ºå¾ˆç”Ÿåƒ»ï¼‰
ORDER_99_MIN = 500            # 99%å¹³å‡å­—åºä¸‹é™
ORDER_99_MAX = 3000           # 99%å¹³å‡å­—åºä¸Šé™

# 7. å­—ç§æ•°è¯„åˆ†åŒºé—´
CHAR_TYPES_BASELINE = 1500    # å­—ç§æ•°åŸºå‡†ï¼ˆå¸¸ç”¨å­—æ•°é‡ï¼Œè¶…å‡ºæ­¤åŸºå‡†çš„æ‰ç®—éš¾åº¦ï¼‰
                              # æ­¤å‚æ•°åŒæ—¶ç”¨äºï¼š
                              # 1. å­—ç§æ•°è¯„åˆ†åŸºå‡†
                              # 2. 95%/99%è¦†ç›–å­—æ•°çš„å‰Nå­—åˆ¤æ–­ï¼ˆä½¿ç”¨å‰1500.txtï¼‰
CHAR_TYPES_MIN = 0            # è¶…å‡ºåŸºå‡†çš„å­—ç§æ•°ä¸‹é™ï¼ˆâ‰¤æ­¤å€¼å¾—0åˆ†ï¼‰
CHAR_TYPES_MAX = 4500         # è¶…å‡ºåŸºå‡†çš„å­—ç§æ•°ä¸Šé™ï¼ˆâ‰¥æ­¤å€¼å¾—æ»¡åˆ†ï¼‰

# 8. æ˜Ÿçº§åˆ’åˆ†åŒºé—´
STAR_THRESHOLD_1 = 20         # <20åˆ†ä¸ºâ­
STAR_THRESHOLD_2 = 40         # <40åˆ†ä¸ºâ­â­
STAR_THRESHOLD_3 = 60         # <60åˆ†ä¸ºâ­â­â­
STAR_THRESHOLD_4 = 80         # <80åˆ†ä¸ºâ­â­â­â­ï¼Œâ‰¥80ä¸ºâ­â­â­â­â­

# 9. è¦†ç›–ç‡è¯„åˆ†æ–¹å¼
# True=ç›´æ¥çº¿æ€§æ˜ å°„(0-100%), False=ä½¿ç”¨åŒºé—´æ˜ å°„
COVERAGE_LINEAR_MODE = True

# å¦‚æœä½¿ç”¨åŒºé—´æ˜ å°„æ¨¡å¼ï¼Œè®¾ç½®ä»¥ä¸‹å‚æ•°ï¼ˆå½“COVERAGE_LINEAR_MODE=Falseæ—¶ç”Ÿæ•ˆï¼‰
COVERAGE_500_MIN = 65         # å‰500å­—è¦†ç›–ç‡ä¸‹é™
COVERAGE_500_MAX = 92         # å‰500å­—è¦†ç›–ç‡ä¸Šé™
COVERAGE_1000_MIN = 80        # å‰1000å­—è¦†ç›–ç‡ä¸‹é™
COVERAGE_1000_MAX = 98        # å‰1000å­—è¦†ç›–ç‡ä¸Šé™
COVERAGE_1500_MIN = 88        # å‰1500å­—è¦†ç›–ç‡ä¸‹é™
COVERAGE_1500_MAX = 99.5      # å‰1500å­—è¦†ç›–ç‡ä¸Šé™

# 10. éçº¿æ€§åŠ é€Ÿç³»æ•°ï¼ˆå¹‚å‡½æ•°æŒ‡æ•°ï¼‰
# è¯´æ˜ï¼š
#   - åŠ é€Ÿç³»æ•° = 1.0 æ—¶ä¸ºçº¿æ€§
#   - åŠ é€Ÿç³»æ•° > 1.0 æ—¶ä¸ºå‡é€Ÿå¢é•¿
#   - åŠ é€Ÿç³»æ•° < 1.0 æ—¶ä¸ºåŠ é€Ÿå¢é•¿ï¼ˆæ¨è1.5-3.0ï¼‰ï¼Œæ•°å€¼è¶Šå¤§å¢é•¿è¶Šå¿«
#   - è¦†ç›–ç‡ï¼šä½è¦†ç›–ç‡çš„ä¹¦éš¾åº¦åˆ†æ•°ä¼šåŠ é€Ÿå¢é•¿
#   - å­—åºï¼šé«˜å­—åºï¼ˆç”Ÿåƒ»å­—ï¼‰çš„ä¹¦éš¾åº¦åˆ†æ•°ä¼šåŠ é€Ÿå¢é•¿
COVERAGE_ACCELERATION = 0.8   # è¦†ç›–ç‡åŠ é€Ÿç³»æ•°ï¼ˆæ¨è1.5-3.0ï¼‰
ORDER_ACCELERATION = 0.7      # å­—åºåŠ é€Ÿç³»æ•°ï¼ˆæ¨è1.5-3.0ï¼‰

# ============================================================================
# ä»¥ä¸‹æ˜¯ç¨‹åºä»£ç ï¼Œä¸€èˆ¬ä¸éœ€è¦ä¿®æ”¹
# ============================================================================

# è¾“å‡ºæ–‡ä»¶å¤¹åç§°
OUTPUT_FOLDER = "å­—é¢‘ç»Ÿè®¡ç»“æœ"


def display_width(text):
    """
    è®¡ç®—å­—ç¬¦ä¸²çš„æ˜¾ç¤ºå®½åº¦ï¼ˆä½¿ç”¨East Asian Widthæ ‡å‡†ï¼‰
    - å…¨è§’/å®½å­—ç¬¦ï¼šå®½åº¦ä¸º2
    - åŠè§’/çª„å­—ç¬¦ï¼šå®½åº¦ä¸º1
    """
    width = 0
    for char in text:
        # è·å–å­—ç¬¦çš„East Asian Widthå±æ€§
        ea_width = unicodedata.east_asian_width(char)

        # F=Fullwidth, W=Wide: å®½åº¦ä¸º2
        # A=Ambiguous: åœ¨CJKç¯å¢ƒä¸­é€šå¸¸ä¸º2ï¼ˆåŒ…æ‹¬â˜…â˜†ç­‰ç¬¦å·ï¼‰
        if ea_width in ('F', 'W', 'A'):
            width += 2
        # H=Halfwidth, Na=Narrow, N=Neutral: å®½åº¦ä¸º1
        else:
            width += 1

    return width


class TableFormatter:
    """
    è¡¨æ ¼æ ¼å¼åŒ–å™¨ - ä½¿ç”¨å›ºå®šåˆ—å®½ç¡®ä¿å®Œç¾å¯¹é½
    """
    def __init__(self, headers, col_widths):
        """
        Args:
            headers: è¡¨å¤´åˆ—è¡¨ï¼Œå¦‚ ['åºå·', 'ä¹¦å', 'éš¾åº¦', 'åˆ†æ•°']
            col_widths: å›ºå®šåˆ—å®½åˆ—è¡¨ï¼Œå¦‚ [6, 50, 20, 10]
        """
        self.headers = headers
        self.rows = []
        self.col_widths = col_widths

    def add_row(self, *cols):
        """æ·»åŠ ä¸€è¡Œæ•°æ®"""
        row = [str(col) for col in cols]
        self.rows.append(row)

    def _format_cell(self, text, target_width):
        """
        æ ¼å¼åŒ–å•å…ƒæ ¼ï¼šæˆªæ–­æˆ–å¡«å……åˆ°å›ºå®šå®½åº¦
        """
        text = str(text)
        current_width = display_width(text)

        # å¦‚æœè¶…å‡ºå®½åº¦ï¼Œæˆªæ–­
        if current_width > target_width:
            truncated = ""
            w = 0
            for ch in text:
                ea = unicodedata.east_asian_width(ch)
                ch_w = 2 if ea in ('F', 'W', 'A') else 1
                if w + ch_w > target_width:
                    break
                truncated += ch
                w += ch_w
            return truncated

        # å¦‚æœä¸è¶³å®½åº¦ï¼Œå¡«å……ç©ºæ ¼
        spaces_needed = target_width - current_width
        return text + ' ' * spaces_needed

    def format(self):
        """æ ¼å¼åŒ–è¾“å‡ºæ•´ä¸ªè¡¨æ ¼"""
        lines = []
        total_width = sum(self.col_widths) + len(self.col_widths) - 1  # åŠ ä¸Šåˆ—é—´ç©ºæ ¼

        # è¡¨å¤´
        header_parts = []
        for i, header in enumerate(self.headers):
            header_parts.append(self._format_cell(header, self.col_widths[i]))
        lines.append(' '.join(header_parts))

        # åˆ†éš”çº¿
        lines.append('-' * total_width)

        # æ•°æ®è¡Œ
        for row in self.rows:
            row_parts = []
            for i, col in enumerate(row):
                if i < len(self.col_widths):
                    row_parts.append(self._format_cell(col, self.col_widths[i]))
            lines.append(' '.join(row_parts))

        return '\n'.join(lines)


def format_row(col1, col2, col3, col4, width1=6, width2=52, width3=22, width4=10):
    """
    æ ¼å¼åŒ–ä¸€è¡Œæ•°æ®ï¼Œç¡®ä¿æ¯åˆ—å¯¹é½

    Args:
        col1-col4: å„åˆ—å†…å®¹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        width1-width4: å„åˆ—çš„ç›®æ ‡æ˜¾ç¤ºå®½åº¦

    Returns:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    parts = []

    for col, target_width in [(col1, width1), (col2, width2), (col3, width3), (col4, width4)]:
        col_str = str(col)
        current_width = display_width(col_str)

        # å¦‚æœè¶…å‡ºå®½åº¦ï¼Œæˆªæ–­
        if current_width > target_width:
            truncated = ""
            w = 0
            for ch in col_str:
                ea = unicodedata.east_asian_width(ch)
                ch_w = 2 if ea in ('F', 'W', 'A') else 1
                if w + ch_w > target_width:
                    break
                truncated += ch
                w += ch_w
            col_str = truncated
            current_width = w

        # è®¡ç®—éœ€è¦å¡«å……å¤šå°‘ç©ºæ ¼
        spaces_needed = target_width - current_width
        parts.append(col_str + ' ' * spaces_needed)

    return ''.join(parts)


def ensure_output_folder():
    """ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    if not os.path.exists(OUTPUT_FOLDER):
        os.makedirs(OUTPUT_FOLDER)
        print(f"åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹: {OUTPUT_FOLDER}")
    return OUTPUT_FOLDER


def check_result_exists(file_path):
    """
    æ£€æŸ¥æŒ‡å®šæ–‡ä»¶æ˜¯å¦å·²æœ‰ç»Ÿè®¡ç»“æœ

    Args:
        file_path: æºæ–‡ä»¶è·¯å¾„

    Returns:
        bool: Trueè¡¨ç¤ºå·²æœ‰ç»“æœï¼ŒFalseè¡¨ç¤ºæ²¡æœ‰ç»“æœ
    """
    base_filename = os.path.basename(file_path)
    base_name = os.path.splitext(base_filename)[0]

    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶å¤¹ä¸­æ˜¯å¦å­˜åœ¨å¯¹åº”çš„ç»“æœæ–‡ä»¶
    # ç»“æœæ–‡ä»¶æ ¼å¼ï¼šä¹¦å_å­—é¢‘ç»Ÿè®¡_éš¾åº¦xx.x.txt
    output_folder = OUTPUT_FOLDER
    if os.path.exists(output_folder):
        for existing_file in os.listdir(output_folder):
            # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä»¥ä¹¦åå¼€å¤´ï¼Œä¸”åŒ…å«"_å­—é¢‘ç»Ÿè®¡_éš¾åº¦"
            if existing_file.startswith(base_name) and '_å­—é¢‘ç»Ÿè®¡_éš¾åº¦' in existing_file:
                return True
    return False


def get_resource_path(relative_path):
    """è·å–èµ„æºæ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œæ”¯æŒæ‰“åŒ…åçš„exe"""
    try:
        # PyInstalleråˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹ï¼Œè·¯å¾„å­˜å‚¨åœ¨_MEIPASSä¸­
        base_path = sys._MEIPASS
    except AttributeError:
        # æ²¡æœ‰æ‰“åŒ…ï¼Œä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•
        base_path = os.path.dirname(os.path.abspath(__file__))

    return os.path.join(base_path, relative_path)


def find_txt_files(directory='books'):
    """
    æ‰¾å‡ºæŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰txtæ–‡ä»¶ï¼ˆæ’é™¤è¾…åŠ©æ–‡ä»¶å’Œç»Ÿè®¡ç»“æœï¼‰

    Args:
        directory: è¦æœç´¢çš„ç›®å½•ï¼Œé»˜è®¤ä¸º 'books'

    Returns:
        list: txtæ–‡ä»¶åˆ—è¡¨
    """
    # ç¡®ä¿ books ç›®å½•å­˜åœ¨
    if not os.path.exists(directory):
        try:
            os.makedirs(directory)
            print(f"\nå·²åˆ›å»º {directory} ç›®å½•")
            print(f"è¯·å°†è¦ç»Ÿè®¡çš„txtä¹¦ç±æ–‡ä»¶æ”¾å…¥ {directory} ç›®å½•ä¸­")
            print("=" * 70)
            return []
        except Exception as e:
            print(f"æ— æ³•åˆ›å»º {directory} ç›®å½•: {e}")
            return []

    txt_files = []
    # éœ€è¦æ’é™¤çš„æ–‡ä»¶åï¼ˆè¾…åŠ©æ–‡ä»¶ï¼‰
    excluded_files = {'dict_simple.txt', 'å‰1500.txt', 'dict.txt'}

    try:
        for file in os.listdir(directory):
            if file.endswith('.txt'):
                # æ’é™¤è¾…åŠ©æ–‡ä»¶ã€å·²ç”Ÿæˆçš„ç»Ÿè®¡æ–‡ä»¶
                if (file not in excluded_files and
                    '_å­—é¢‘ç»Ÿè®¡_éš¾åº¦' not in file and
                    not file.endswith('_å­—é¢‘ç»Ÿè®¡.txt')):
                    # è¿”å›ç›¸å¯¹äºbooksç›®å½•çš„æ–‡ä»¶è·¯å¾„
                    txt_files.append(os.path.join(directory, file))
        return txt_files
    except Exception as e:
        print(f"è¯»å– {directory} ç›®å½•å¤±è´¥: {e}")
        return []


def load_reference_chars():
    """
    åŠ è½½å‚è€ƒå­—è¡¨ï¼ˆä»å‰1500.txtï¼‰
    è¿”å›æŒ‰é¡ºåºæ’åˆ—çš„1500ä¸ªå­—çš„åˆ—è¡¨
    """
    ref_file = get_resource_path('å‰1500.txt')

    # å°è¯•å¤šç§ç¼–ç 
    encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'gb18030']

    for encoding in encodings:
        try:
            with open(ref_file, 'r', encoding=encoding) as f:
                content = f.read()

            # æå–æ‰€æœ‰ä¸­æ–‡å­—ç¬¦ï¼ˆåŒ…æ‹¬æ‰©å±•åŒºï¼Œä¿æŒé¡ºåºï¼‰
            chars = [
                char for char in content
                if ('\u4e00' <= char <= '\u9fff') or
                   ('\u3400' <= char <= '\u4dbf') or
                   ('\U00020000' <= char <= '\U0002ebef')
            ]
            if len(chars) > 0:
                print(f"  ä½¿ç”¨ç¼–ç : {encoding}")
                return chars
        except (UnicodeDecodeError, UnicodeError, FileNotFoundError):
            continue

    print(f"âš  è­¦å‘Šï¼šæ— æ³•åŠ è½½å‰1500.txtï¼ˆå°è¯•äº†{len(encodings)}ç§ç¼–ç ï¼‰")
    print(f"   å°†ä½¿ç”¨dict_simple.txtçš„å‰1500ä¸ªå­—ä½œä¸ºæ›¿ä»£æ–¹æ¡ˆ")
    return None


def load_dict_order():
    """åŠ è½½dictå­—åº"""
    dict_file = get_resource_path('dict_simple.txt')

    # å°è¯•å¤šç§ç¼–ç 
    encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'gb18030']

    for encoding in encodings:
        try:
            with open(dict_file, 'r', encoding=encoding) as f:
                lines = f.readlines()

            char_order = {}
            for idx, line in enumerate(lines, start=1):
                char = line.strip()
                if char:
                    char_order[char] = idx

            print(f"  dict_simple.txt ä½¿ç”¨ç¼–ç : {encoding}")
            return char_order
        except (UnicodeDecodeError, UnicodeError, FileNotFoundError):
            continue

    print(f"åŠ è½½dictå­—åºå¤±è´¥ï¼ˆå°è¯•äº†{len(encodings)}ç§ç¼–ç ï¼‰")
    print(f"å°è¯•çš„è·¯å¾„: {dict_file}")
    return {}


def detect_encoding(file_path):
    """è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç ï¼Œä½¿ç”¨chardetåº“æé«˜å‡†ç¡®æ€§"""

    # æ–¹æ³•1: å°è¯•ä½¿ç”¨chardetåº“ï¼ˆå¦‚æœå·²å®‰è£…ï¼‰
    try:
        import chardet

        # è¯»å–æ–‡ä»¶çš„å‰100KBç”¨äºæ£€æµ‹
        with open(file_path, 'rb') as f:
            raw_data = f.read(102400)  # è¯»å–100KB

        # ä½¿ç”¨chardetæ£€æµ‹ç¼–ç 
        result = chardet.detect(raw_data)
        encoding = result['encoding']
        confidence = result['confidence']

        # å¦‚æœç½®ä¿¡åº¦è¾ƒé«˜ï¼ˆ>0.7ï¼‰ï¼Œç›´æ¥ä½¿ç”¨æ£€æµ‹ç»“æœ
        if confidence > 0.7 and encoding:
            # æ ‡å‡†åŒ–ç¼–ç åç§°
            encoding = encoding.lower()
            if encoding in ['gb2312', 'gb18030']:
                encoding = 'gbk'  # ç»Ÿä¸€ä½¿ç”¨gbk
            elif encoding == 'ascii':
                encoding = 'utf-8'  # ASCIIå…¼å®¹UTF-8

            # éªŒè¯æ£€æµ‹ç»“æœæ˜¯å¦æ­£ç¡®
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    f.read(1024)
                print(f"  ç¼–ç æ£€æµ‹: {encoding.upper()} (ç½®ä¿¡åº¦: {confidence:.0%})")
                return encoding
            except:
                pass
    except ImportError:
        # chardetæœªå®‰è£…ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
        pass
    except Exception as e:
        print(f"  ç¼–ç æ£€æµ‹è­¦å‘Š: {e}")

    # æ–¹æ³•2: å¤‡ç”¨æ–¹æ³• - æŒ‰ä¼˜å…ˆçº§å°è¯•å¸¸è§ç¼–ç 
    # å…ˆè¯»å–æ–‡ä»¶çš„å‰10KBå†…å®¹ç”¨äºæ£€æµ‹
    try:
        with open(file_path, 'rb') as f:
            raw_data = f.read(10240)
    except:
        return None

    # æ£€æµ‹BOMæ ‡è®°
    if raw_data.startswith(b'\xef\xbb\xbf'):
        return 'utf-8-sig'
    elif raw_data.startswith(b'\xff\xfe') or raw_data.startswith(b'\xfe\xff'):
        return 'utf-16'

    # æŒ‰ä¼˜å…ˆçº§å°è¯•è§£ç 
    encodings_priority = [
        ('utf-8', 0),
        ('gbk', 0),
        ('gb18030', 0),
        ('big5', 0),
        ('utf-16', 0)
    ]

    valid_encodings = []

    for encoding, _ in encodings_priority:
        try:
            # å°è¯•è§£ç å…¨éƒ¨å†…å®¹
            decoded = raw_data.decode(encoding)

            # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦æ˜¯æ­£ç¡®çš„ä¸­æ–‡ç¼–ç ï¼‰
            chinese_count = sum(1 for c in decoded if '\u4e00' <= c <= '\u9fff' or '\u3400' <= c <= '\u4dbf')
            total_chars = len(decoded)
            chinese_ratio = chinese_count / total_chars if total_chars > 0 else 0

            # å¦‚æœä¸­æ–‡å­—ç¬¦æ¯”ä¾‹è¾ƒé«˜ï¼Œè®¤ä¸ºæ˜¯æœ‰æ•ˆç¼–ç 
            if chinese_ratio > 0.3:  # è¶…è¿‡30%æ˜¯ä¸­æ–‡
                valid_encodings.append((encoding, chinese_ratio))
            elif chinese_ratio > 0.1:  # 10-30%ä¸­æ–‡ï¼Œä¹Ÿå¯èƒ½æ˜¯æ­£ç¡®çš„
                valid_encodings.append((encoding, chinese_ratio * 0.5))  # é™ä½æƒé‡
            elif encoding == 'utf-8' and chinese_ratio == 0:
                # å¯èƒ½æ˜¯çº¯è‹±æ–‡æˆ–æ•°å­—
                valid_encodings.append((encoding, 0.01))
        except (UnicodeDecodeError, UnicodeError):
            continue

    # é€‰æ‹©ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹æœ€é«˜çš„ç¼–ç 
    if valid_encodings:
        valid_encodings.sort(key=lambda x: x[1], reverse=True)
        detected_encoding = valid_encodings[0][0]
        print(f"  ç¼–ç æ£€æµ‹: {detected_encoding.upper()} (ä¸­æ–‡æ¯”ä¾‹: {valid_encodings[0][1]:.1%})")
        return detected_encoding

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„ç¼–ç ï¼Œä½¿ç”¨ç®€å•è¯•é”™æ³•
    print("  ç¼–ç æ£€æµ‹: ä½¿ç”¨è¯•é”™æ³•...")
    encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030', 'big5', 'utf-16']

    for encoding in encodings:
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                f.read(1024)
                return encoding
        except (UnicodeDecodeError, UnicodeError):
            continue

    # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œè¿”å›None
    return None


def count_chars(file_path):
    """ç»Ÿè®¡æ–‡ä»¶ä¸­æ¯ä¸ªå­—çš„å‡ºç°æ¬¡æ•°ï¼Œè‡ªåŠ¨æ£€æµ‹ç¼–ç """
    print("\næ­£åœ¨æ£€æµ‹æ–‡ä»¶ç¼–ç ...")

    # å…ˆæ£€æµ‹ç¼–ç 
    detected_encoding = detect_encoding(file_path)

    if detected_encoding is None:
        print(f"âœ— æ— æ³•è¯†åˆ«æ–‡ä»¶ç¼–ç ï¼Œå°è¯•ä½¿ç”¨utf-8å¼ºåˆ¶è¯»å–")
        detected_encoding = 'utf-8'
    else:
        print(f"âœ“ æ£€æµ‹å®Œæˆ: {detected_encoding.upper()}")

    try:
        with open(file_path, 'r', encoding=detected_encoding, errors='ignore') as f:
            content = f.read()

        # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦ï¼ˆåŒ…æ‹¬åŸºæœ¬æ±‰å­—å’ŒCJKæ‰©å±•åŒºï¼‰
        # åŸºæœ¬æ±‰å­—åŒº: U+4E00-U+9FFF
        # CJKæ‰©å±•AåŒº: U+3400-U+4DBF
        # CJKæ‰©å±•B-FåŒº: U+20000-U+2EBEF
        chinese_chars = [
            char for char in content
            if ('\u4e00' <= char <= '\u9fff') or  # åŸºæœ¬æ±‰å­—
               ('\u3400' <= char <= '\u4dbf') or  # æ‰©å±•AåŒº
               ('\U00020000' <= char <= '\U0002ebef')  # æ‰©å±•B-FåŒº
        ]
        return Counter(chinese_chars), detected_encoding
    except Exception as e:
        print(f"âœ— è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return Counter(), None


def load_common_chars(reference_chars=None, char_order=None):
    """
    åŠ è½½å¸¸ç”¨å­—è¡¨ï¼ˆå‰3500ä¸ªå­—ï¼‰
    - å‰1500å­—ï¼šä¼˜å…ˆä½¿ç”¨å‰1500.txtï¼ˆå¦‚æœå¯ç”¨ï¼‰
    - 1500-3500å­—ï¼šä½¿ç”¨dict_simple.txtæŒ‰å­—åºè¡¥å……
    """
    common_chars = set()

    if reference_chars and len(reference_chars) > 0:
        # å‰1500å­—ä½¿ç”¨å‰1500.txt
        common_chars = set(reference_chars)

        # è¡¥å……1500-3500å­—ï¼ˆä»dict_simple.txtï¼ŒæŒ‰å­—åºï¼Œæ’é™¤å‰1500ï¼‰
        reference_chars_set = set(reference_chars)
        remaining_needed = 3500 - len(reference_chars)

        if char_order and remaining_needed > 0:
            added_count = 0
            for char, order in sorted(char_order.items(), key=lambda x: x[1]):
                if char not in reference_chars_set:
                    common_chars.add(char)
                    added_count += 1
                    if added_count >= remaining_needed:
                        break
    else:
        # å›é€€æ–¹æ¡ˆï¼šä»dict_simple.txtè¯»å–å‰3500ä¸ªå­—
        dict_file = get_resource_path('dict_simple.txt')
        encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'gb18030']

        for encoding in encodings:
            try:
                with open(dict_file, 'r', encoding=encoding) as f:
                    for i, line in enumerate(f, 1):
                        if i > 3500:
                            break
                        char = line.strip()
                        if char:
                            common_chars.add(char)

                if len(common_chars) > 0:
                    return common_chars
            except (UnicodeDecodeError, UnicodeError, FileNotFoundError):
                continue

        print(f"åŠ è½½å¸¸ç”¨å­—è¡¨å¤±è´¥ï¼ˆå°è¯•äº†{len(encodings)}ç§ç¼–ç ï¼‰")

    return common_chars


def analyze_rare_chars(char_counter, common_chars):
    """
    åˆ†æç”Ÿåƒ»å­—æƒ…å†µ
    è¿”å›å­—å…¸åŒ…å«ï¼š
    - rare_chars: æ‰€æœ‰ç”Ÿåƒ»å­—åˆ—è¡¨ [(å­—, æ¬¡æ•°)]
    - rare_char_count: ç”Ÿåƒ»å­—å‡ºç°æ€»æ¬¡æ•°
    - rare_char_ratio: ç”Ÿåƒ»å­—å æ–‡æœ¬æ¯”ä¾‹
    - rare_type_count: ç”Ÿåƒ»å­—å­—ç§æ•°
    - rare_type_ratio: ç”Ÿåƒ»å­—å­—ç§å æ¯”
    """
    rare_chars = []  # (å­—, æ¬¡æ•°)
    common_char_count = 0
    rare_char_count = 0

    for char, count in char_counter.items():
        if char in common_chars:
            common_char_count += count
        else:
            rare_char_count += count
            rare_chars.append((char, count))

    # æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åº
    rare_chars.sort(key=lambda x: x[1], reverse=True)

    total_chars = common_char_count + rare_char_count
    rare_char_ratio = rare_char_count / total_chars if total_chars > 0 else 0
    rare_type_ratio = len(rare_chars) / len(char_counter) if len(char_counter) > 0 else 0

    return {
        'rare_chars': rare_chars,           # æ‰€æœ‰ç”Ÿåƒ»å­—åˆ—è¡¨
        'rare_char_count': rare_char_count, # ç”Ÿåƒ»å­—å‡ºç°æ€»æ¬¡æ•°
        'rare_char_ratio': rare_char_ratio, # ç”Ÿåƒ»å­—å æ–‡æœ¬æ¯”ä¾‹
        'rare_type_count': len(rare_chars), # ç”Ÿåƒ»å­—å­—ç§æ•°
        'rare_type_ratio': rare_type_ratio  # ç”Ÿåƒ»å­—å­—ç§å æ¯”
    }


def calculate_difficulty_rating(char_counter, total_chars, coverage_stats, cumulative_coverage, avg_order_95, avg_order_99, extra_char_types):
    """
    è®¡ç®—ä¹¦ç±éš¾åº¦ï¼ˆâ­-â­â­â­â­â­ï¼‰
    è¿”å›ï¼š(æ˜Ÿçº§å­—ç¬¦ä¸², åˆ†æ•°0-100, æè¿°)

    æ‰€æœ‰è¯„åˆ†å‚æ•°å¯åœ¨æ–‡ä»¶å¼€å¤´çš„é…ç½®åŒºåŸŸè°ƒæ•´ï¼š
    - æƒé‡åˆ†é…ï¼šè¦†ç›–ç‡46% + å­—æ•°25% + å­—åº20% + å­—ç§9%
    - è¯„åˆ†åŒºé—´ï¼šå­—æ•°ã€å­—åºã€å­—ç§æ•°çš„ä¸Šä¸‹é™
    - æ˜Ÿçº§åˆ’åˆ†ï¼šäº”ä¸ªæ˜Ÿçº§çš„åˆ†æ•°é˜ˆå€¼
    - è¦†ç›–ç‡æ¨¡å¼ï¼šçº¿æ€§æ¨¡å¼(0-100%)æˆ–åŒºé—´æ¨¡å¼
    """

    # æå–å…³é”®æŒ‡æ ‡
    coverage_500 = coverage_stats.get(500, {}).get('coverage', 0)
    coverage_1000 = coverage_stats.get(1000, {}).get('coverage', 0)
    coverage_1500 = coverage_stats.get(1500, {}).get('coverage', 0)

    # ä»cumulative_coverageè·å–95%å’Œ99%æ‰€éœ€å­—æ•°
    chars_for_95 = 0
    chars_for_99 = 0
    for target_pct, char_count, _ in cumulative_coverage:
        if target_pct == 95:
            chars_for_95 = char_count
        if target_pct == 99:
            chars_for_99 = char_count

    # å­—ç§æ•°
    char_type_count = len(char_counter)

    # ä½¿ç”¨é…ç½®å‚æ•°è®¡ç®—éš¾åº¦åˆ†æ•°ï¼ˆ0-100ï¼Œè¶Šé«˜è¶Šéš¾ï¼‰

    # 1-3. è¦†ç›–ç‡è¯„åˆ†ï¼ˆåº”ç”¨éçº¿æ€§åŠ é€Ÿï¼‰
    if COVERAGE_LINEAR_MODE:
        # çº¿æ€§æ¨¡å¼ï¼š0%â†’æ»¡åˆ†ï¼ˆæœ€éš¾ï¼‰ï¼Œ100%â†’0åˆ†ï¼ˆæœ€ç®€å•ï¼‰
        # åº”ç”¨åŠ é€Ÿç³»æ•°ï¼š((100-coverage)/100)^COVERAGE_ACCELERATION
        score_500 = WEIGHT_COVERAGE_500 * (((100 - coverage_500) / 100) ** COVERAGE_ACCELERATION)
        score_1000 = WEIGHT_COVERAGE_1000 * (((100 - coverage_1000) / 100) ** COVERAGE_ACCELERATION)
        score_1500 = WEIGHT_COVERAGE_1500 * (((100 - coverage_1500) / 100) ** COVERAGE_ACCELERATION)
    else:
        # åŒºé—´æ¨¡å¼ï¼šä½¿ç”¨é…ç½®çš„åŒºé—´èŒƒå›´
        if coverage_500 >= COVERAGE_500_MAX:
            score_500 = 0
        elif coverage_500 <= COVERAGE_500_MIN:
            score_500 = WEIGHT_COVERAGE_500
        else:
            ratio = (COVERAGE_500_MAX - coverage_500) / (COVERAGE_500_MAX - COVERAGE_500_MIN)
            score_500 = WEIGHT_COVERAGE_500 * (ratio ** COVERAGE_ACCELERATION)

        if coverage_1000 >= COVERAGE_1000_MAX:
            score_1000 = 0
        elif coverage_1000 <= COVERAGE_1000_MIN:
            score_1000 = WEIGHT_COVERAGE_1000
        else:
            ratio = (COVERAGE_1000_MAX - coverage_1000) / (COVERAGE_1000_MAX - COVERAGE_1000_MIN)
            score_1000 = WEIGHT_COVERAGE_1000 * (ratio ** COVERAGE_ACCELERATION)

        if coverage_1500 >= COVERAGE_1500_MAX:
            score_1500 = 0
        elif coverage_1500 <= COVERAGE_1500_MIN:
            score_1500 = WEIGHT_COVERAGE_1500
        else:
            ratio = (COVERAGE_1500_MAX - coverage_1500) / (COVERAGE_1500_MAX - COVERAGE_1500_MIN)
            score_1500 = WEIGHT_COVERAGE_1500 * (ratio ** COVERAGE_ACCELERATION)

    # 4. 95%è¦†ç›–æ‰€éœ€å­—æ•°è¯„åˆ†
    if chars_for_95 <= CHARS_95_MIN:
        score_95_chars = 0
    elif chars_for_95 >= CHARS_95_MAX:
        score_95_chars = WEIGHT_CHARS_95
    else:
        score_95_chars = WEIGHT_CHARS_95 * (chars_for_95 - CHARS_95_MIN) / (CHARS_95_MAX - CHARS_95_MIN)

    # 5. 99%è¦†ç›–æ‰€éœ€å­—æ•°è¯„åˆ†
    if chars_for_99 <= CHARS_99_MIN:
        score_99_chars = 0
    elif chars_for_99 >= CHARS_99_MAX:
        score_99_chars = WEIGHT_CHARS_99
    else:
        score_99_chars = WEIGHT_CHARS_99 * (chars_for_99 - CHARS_99_MIN) / (CHARS_99_MAX - CHARS_99_MIN)

    # 6. 95%å¹³å‡å­—åºè¯„åˆ†ï¼ˆåº”ç”¨éçº¿æ€§åŠ é€Ÿï¼‰
    if avg_order_95 is None:
        score_95_order = WEIGHT_ORDER_95 / 2  # é»˜è®¤ä¸­ç­‰éš¾åº¦
    elif avg_order_95 <= ORDER_95_MIN:
        score_95_order = 0
    elif avg_order_95 >= ORDER_95_MAX:
        score_95_order = WEIGHT_ORDER_95
    else:
        ratio = (avg_order_95 - ORDER_95_MIN) / (ORDER_95_MAX - ORDER_95_MIN)
        score_95_order = WEIGHT_ORDER_95 * (ratio ** ORDER_ACCELERATION)

    # 7. 99%å¹³å‡å­—åºè¯„åˆ†ï¼ˆåº”ç”¨éçº¿æ€§åŠ é€Ÿï¼‰
    if avg_order_99 is None:
        score_99_order = WEIGHT_ORDER_99 / 2  # é»˜è®¤ä¸­ç­‰éš¾åº¦
    elif avg_order_99 <= ORDER_99_MIN:
        score_99_order = 0
    elif avg_order_99 >= ORDER_99_MAX:
        score_99_order = WEIGHT_ORDER_99
    else:
        ratio = (avg_order_99 - ORDER_99_MIN) / (ORDER_99_MAX - ORDER_99_MIN)
        score_99_order = WEIGHT_ORDER_99 * (ratio ** ORDER_ACCELERATION)

    # 8. å­—ç§æ•°è¯„åˆ†ï¼ˆä½¿ç”¨ä¼ å…¥çš„è¶…å‡ºå‰1500.txtçš„å­—ç§æ•°ï¼‰
    if extra_char_types <= CHAR_TYPES_MIN:
        score_char_types = 0
    elif extra_char_types >= CHAR_TYPES_MAX:
        score_char_types = WEIGHT_CHAR_TYPES
    else:
        score_char_types = WEIGHT_CHAR_TYPES * (extra_char_types - CHAR_TYPES_MIN) / (CHAR_TYPES_MAX - CHAR_TYPES_MIN)

    # ç»¼åˆéš¾åº¦åˆ†æ•°ï¼ˆåŸå§‹åˆ†æ•°ï¼‰
    raw_score = (score_500 + score_1000 + score_1500 +
                 score_95_chars + score_99_chars +
                 score_95_order + score_99_order + score_char_types)

    # è®¡ç®—æ€»æƒé‡
    total_weight = (WEIGHT_COVERAGE_500 + WEIGHT_COVERAGE_1000 + WEIGHT_COVERAGE_1500 +
                   WEIGHT_CHARS_95 + WEIGHT_CHARS_99 +
                   WEIGHT_ORDER_95 + WEIGHT_ORDER_99 +
                   WEIGHT_CHAR_TYPES)

    # å½’ä¸€åŒ–åˆ°0-100ï¼ˆæ— è®ºæƒé‡å¦‚ä½•è®¾ç½®ï¼Œæœ€ç»ˆéƒ½æ˜¯0-100çš„æ ‡å‡†åˆ†æ•°ï¼‰
    if total_weight > 0:
        difficulty_score = (raw_score / total_weight) * 100
    else:
        difficulty_score = 0

    # è½¬æ¢ä¸ºæ˜Ÿçº§ï¼ˆ20æ˜Ÿåˆ¶ï¼šæ¯5åˆ†ä¸€ä¸ªç©ºå¿ƒæ˜Ÿâ˜†ï¼Œæ¯10åˆ†ä¸€ä¸ªå®å¿ƒæ˜Ÿâ˜…ï¼‰
    stars = difficulty_score_to_star_display(difficulty_score)

    # è¿”å›è¯¦ç»†ä¿¡æ¯
    score_details = {
        'coverage_500': (score_500, WEIGHT_COVERAGE_500, coverage_500),
        'coverage_1000': (score_1000, WEIGHT_COVERAGE_1000, coverage_1000),
        'coverage_1500': (score_1500, WEIGHT_COVERAGE_1500, coverage_1500),
        'chars_95': (score_95_chars, WEIGHT_CHARS_95, chars_for_95),
        'chars_99': (score_99_chars, WEIGHT_CHARS_99, chars_for_99),
        'order_95': (score_95_order, WEIGHT_ORDER_95, avg_order_95),
        'order_99': (score_99_order, WEIGHT_ORDER_99, avg_order_99),
        'char_types': (score_char_types, WEIGHT_CHAR_TYPES, extra_char_types),
        'raw_score': raw_score,
        'total_weight': total_weight
    }

    return stars, difficulty_score, score_details


def calculate_avg_char_order(chars_list, char_order):
    """
    è®¡ç®—ä¸€ç»„å­—åœ¨å­—å…¸ä¸­çš„å¹³å‡åºå·
    ç”¨äºè¯„ä¼°è¿™äº›å­—æ˜¯å¦æ˜¯å¸¸ç”¨å­—ï¼ˆåºå·é å‰=æ›´å¸¸ç”¨ï¼‰

    å‚æ•°ï¼š
    - chars_list: å­—ç¬¦åˆ—è¡¨ [(char, count), ...]
    - char_order: å­—å…¸åºå·æ˜ å°„ {char: order}

    è¿”å›ï¼šå¹³å‡åºå·ï¼ˆä¸åœ¨å­—å…¸ä¸­çš„å­—ä¸è®¡å…¥ï¼‰
    """
    orders = []
    for char, _ in chars_list:
        if char in char_order:
            orders.append(char_order[char])

    if orders:
        return sum(orders) / len(orders)
    else:
        return None


def print_main_menu():
    """æ‰“å°ä¸»èœå•"""
    print("\n" + "=" * 70)
    print("ã€å­—é¢‘ç»Ÿè®¡ä¸é€‰ä¹¦ç³»ç»Ÿã€‘")
    print("=" * 70)
    print("\nè¯·é€‰æ‹©åŠŸèƒ½ï¼š")
    print("  1. å¤æ‚åº¦è®¡ç®— - ç»Ÿè®¡txtä¹¦ç±çš„å­—é¢‘å’Œéš¾åº¦")
    print("  2. æŒ‰åˆ†æ•°ç­›é€‰ - æ ¹æ®éš¾åº¦åˆ†æ•°ç­›é€‰åˆé€‚çš„ä¹¦ç±")
    print("  3. æœä¹¦åŠŸèƒ½ - æ ¹æ®ä¹¦åæ¨¡ç³Šæœç´¢ä¹¦ç±")
    print("  4. éš¾åº¦æ’è¡Œæ¦œ - æŸ¥çœ‹æ•°æ®åº“ä¸­æ‰€æœ‰ä¹¦ç±çš„éš¾åº¦æ’è¡Œ")
    print("  5. 95%å­—ç§æ•°æ’è¡Œæ¦œ - æŸ¥çœ‹95%è¦†ç›–æ‰€éœ€å­—æ•°æ’è¡Œ")
    print("  6. 99%å­—ç§æ•°æ’è¡Œæ¦œ - æŸ¥çœ‹99%è¦†ç›–æ‰€éœ€å­—æ•°æ’è¡Œ")
    print("  7. 95%å¹³å‡å­—åºæ’è¡Œæ¦œ - å­—åºè¶Šå°è¶Šå¸¸ç”¨")
    print("  8. 99%å¹³å‡å­—åºæ’è¡Œæ¦œ - å­—åºè¶Šå°è¶Šå¸¸ç”¨")
    print("  9. æ€»å­—ç§æ•°æ’è¡Œæ¦œ - æŸ¥çœ‹ä¹¦ç±æ€»å­—ç§æ•°æ’è¡Œ")
    print("  0. é€€å‡ºç¨‹åº")
    print("=" * 70)


def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    if not DB_UPLOAD_AVAILABLE:
        print("æ•°æ®åº“åŠŸèƒ½ä¸å¯ç”¨ï¼ˆæœªå®‰è£…pymysqlæˆ–db_uploaderæ¨¡å—ï¼‰")
        return None

    try:
        from db_uploader import load_db_config, check_db_connection, is_db_config_valid
        db_config = load_db_config()
        if not db_config:
            print("æ•°æ®åº“é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æˆ–è¯»å–å¤±è´¥")
            return None

        if not is_db_config_valid(db_config):
            print("æ•°æ®åº“é…ç½®æœªå¡«å†™æˆ–ä»ä¸ºæ¨¡æ¿å ä½ç¬¦")
            return None

        success, db_conn = check_db_connection(db_config)
        if not success:
            print("æ•°æ®åº“è¿æ¥å¤±è´¥")
            return None

        return db_conn
    except Exception as e:
        print(f"æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
        return None


def difficulty_score_to_star_display(score):
    """å°†éš¾åº¦åˆ†æ•°è½¬æ¢ä¸ºæ˜Ÿçº§æ˜¾ç¤ºï¼ˆ20çº§åˆ¶ï¼šæ¯5åˆ†ä¸€ä¸ªç©ºå¿ƒæ˜Ÿâ˜†ï¼Œæ¯10åˆ†ä¸€ä¸ªå®å¿ƒæ˜Ÿâ˜…ï¼‰"""
    # è®¡ç®—æœ‰å¤šå°‘ä¸ª5åˆ†å•ä½
    units = int(score / 5)
    # æ¯2ä¸ªå•ä½åˆå¹¶æˆ1ä¸ªå®å¿ƒæ˜Ÿï¼Œä½™æ•°æ˜¯ç©ºå¿ƒæ˜Ÿ
    full_stars = units // 2  # å®å¿ƒæ˜Ÿæ•°é‡
    half_star = units % 2    # ç©ºå¿ƒæ˜Ÿæ•°é‡ï¼ˆ0æˆ–1ï¼‰

    # æœ€å¤š10ä¸ªå®å¿ƒæ˜Ÿ
    full_stars = min(full_stars, 10)

    # æ„å»ºæ˜Ÿçº§å­—ç¬¦ä¸²
    result = "â˜…" * full_stars
    if half_star and full_stars < 10:  # åªæœ‰åœ¨æœªæ»¡10ä¸ªå®å¿ƒæ˜Ÿæ—¶æ‰åŠ ç©ºå¿ƒæ˜Ÿ
        result += "â˜†"

    # å¦‚æœä»€ä¹ˆéƒ½æ²¡æœ‰ï¼Œè‡³å°‘æ˜¾ç¤ºä¸€ä¸ªç©ºå¿ƒæ˜Ÿ
    if not result:
        result = "â˜†"

    return result


def feature_generic_ranking(field_name, field_display_name, title, asc_desc, desc_desc,
                            show_difficulty=False, value_formatter=None):
    """
    é€šç”¨æ’è¡Œæ¦œåŠŸèƒ½ï¼ˆä½¿ç”¨æ¸¸æ ‡åˆ†é¡µï¼‰

    Args:
        field_name: æ•°æ®åº“å­—æ®µåï¼ˆå¦‚ 'chars_95', 'difficulty_score'ï¼‰
        field_display_name: æ˜¾ç¤ºåç§°ï¼ˆå¦‚ '95%å­—æ•°', 'éš¾åº¦åˆ†å€¼'ï¼‰
        title: æ’è¡Œæ¦œæ ‡é¢˜ï¼ˆå¦‚ '95%å­—ç§æ•°æ’è¡Œæ¦œ'ï¼‰
        asc_desc: æ­£åºè¯´æ˜ï¼ˆå¦‚ 'ä»å°‘åˆ°å¤šï¼Œå­—æ•°è¶Šå°‘è¶Šç®€å•'ï¼‰
        desc_desc: å€’åºè¯´æ˜ï¼ˆå¦‚ 'ä»å¤šåˆ°å°‘ï¼Œå­—æ•°è¶Šå¤šè¶Šéš¾'ï¼‰
        show_difficulty: æ˜¯å¦åŒæ—¶æ˜¾ç¤ºéš¾åº¦æ˜Ÿçº§ï¼ˆé»˜è®¤Falseï¼‰
        value_formatter: å€¼æ ¼å¼åŒ–å‡½æ•°ï¼ˆå¦‚ lambda x: f"{x:.1f}"ï¼‰ï¼Œé»˜è®¤ä¸ºstr
    """
    print("\n" + "=" * 70)
    print(f"ã€{title}ã€‘")
    print("=" * 70)

    # è·å–æ•°æ®åº“è¿æ¥
    conn = get_db_connection()
    if not conn:
        input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
        return

    try:
        # é€‰æ‹©æ’åºæ–¹å¼
        print("\nè¯·é€‰æ‹©æ’åºæ–¹å¼ï¼š")
        print(f"  1. æ­£åºï¼ˆ{asc_desc}ï¼‰")
        print(f"  2. å€’åºï¼ˆ{desc_desc}ï¼‰[é»˜è®¤]")

        while True:
            order_choice = input("è¯·é€‰æ‹© (1-2ï¼Œç›´æ¥å›è½¦é»˜è®¤å€’åº): ").strip()
            if order_choice == '':
                order_choice = '2'  # é»˜è®¤å€’åº
            if order_choice in ['1', '2']:
                break
            print("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥1æˆ–2")

        is_ascending = (order_choice == '1')

        # è·å–æ€»è®°å½•æ•°
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM book_difficulty")
        total_count = cursor.fetchone()[0]
        cursor.close()

        if total_count == 0:
            print("\næš‚æ— æ•°æ®ï¼")
            input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
            return

        # åˆ†é¡µå‚æ•°
        page_size = 20
        current_page = 0
        page_cache = []  # ç¼“å­˜æ‰€æœ‰é¡µé¢æ•°æ®ï¼Œæ”¯æŒåŒå‘ç¿»é¡µ

        def load_page(page_num):
            """åŠ è½½æŒ‡å®šé¡µç çš„æ•°æ®"""
            # å¦‚æœå·²ç»ç¼“å­˜ï¼Œç›´æ¥è¿”å›
            if page_num < len(page_cache):
                return page_cache[page_num]

            # éœ€è¦ä»æ•°æ®åº“åŠ è½½æ–°é¡µ
            cursor = conn.cursor()

            # æ„å»ºSQLæŸ¥è¯¢
            select_fields = f"id, book_name, author, {field_name}"
            if show_difficulty:
                select_fields += ", difficulty_score, star_level"

            if page_num == 0:
                # ç¬¬ä¸€é¡µ
                if is_ascending:
                    sql = f"""
                        SELECT {select_fields}
                        FROM book_difficulty
                        ORDER BY {field_name} ASC, id ASC
                        LIMIT %s
                    """
                else:
                    sql = f"""
                        SELECT {select_fields}
                        FROM book_difficulty
                        ORDER BY {field_name} DESC, id DESC
                        LIMIT %s
                    """
                cursor.execute(sql, (page_size,))
            else:
                # åç»­é¡µï¼šä½¿ç”¨ä¸Šä¸€é¡µæœ€åä¸€æ¡è®°å½•çš„æ¸¸æ ‡
                prev_page = page_cache[page_num - 1]
                if not prev_page:
                    return None
                last_row = prev_page[-1]
                last_id = last_row[0]
                last_value = last_row[3]

                if is_ascending:
                    sql = f"""
                        SELECT {select_fields}
                        FROM book_difficulty
                        WHERE {field_name} > %s OR ({field_name} = %s AND id > %s)
                        ORDER BY {field_name} ASC, id ASC
                        LIMIT %s
                    """
                else:
                    sql = f"""
                        SELECT {select_fields}
                        FROM book_difficulty
                        WHERE {field_name} < %s OR ({field_name} = %s AND id < %s)
                        ORDER BY {field_name} DESC, id DESC
                        LIMIT %s
                    """
                cursor.execute(sql, (last_value, last_value, last_id, page_size))

            results = cursor.fetchall()
            cursor.close()

            # ç¼“å­˜ç»“æœ
            page_cache.append(results if results else None)
            return results

        while True:
            # åŠ è½½å½“å‰é¡µæ•°æ®
            results = load_page(current_page)

            if not results:
                if current_page == 0:
                    print("\næš‚æ— æ•°æ®ï¼")
                    break
                else:
                    print("\nå·²ç»æ˜¯æœ€åä¸€é¡µäº†ï¼")
                    current_page -= 1  # å›é€€åˆ°ä¸Šä¸€é¡µ
                    continue

            # æ˜¾ç¤ºç»“æœ - ä½¿ç”¨è¡¨æ ¼å®¹å™¨ç¡®ä¿å®Œç¾å¯¹é½
            # è®¡ç®—å·²æ˜¾ç¤ºçš„æ¡æ•°å’Œå‰©ä½™æ¡æ•°
            shown_count = (current_page * page_size) + len(results)
            remaining_count = total_count - shown_count

            print("\n" + "=" * 70)
            print(f"ç¬¬ {current_page + 1} é¡µï¼ˆæœ¬é¡µ {len(results)} æ¡ | æ€» {total_count} æ¡ | å‰©ä½™ {remaining_count} æ¡ï¼‰")
            print("=" * 70)

            # æ ¹æ®æ˜¯å¦æ˜¾ç¤ºéš¾åº¦è°ƒæ•´è¡¨æ ¼åˆ—
            if show_difficulty:
                # å¦‚æœæ˜¯éš¾åº¦æ’è¡Œæ¦œï¼Œåˆ—é¡ºåºä¸ºï¼šåºå· | ä¹¦å | éš¾åº¦æ˜Ÿçº§ | éš¾åº¦åˆ†å€¼
                if field_name == 'difficulty_score':
                    # åºå·6 + ä¹¦å48 + éš¾åº¦æ˜Ÿçº§24 + éš¾åº¦åˆ†å€¼10
                    headers = ['åºå·', 'ä¹¦å', 'éš¾åº¦æ˜Ÿçº§', field_display_name]
                    col_widths = [6, 48, 24, 10]
                else:
                    # å…¶ä»–æ’è¡Œæ¦œï¼šåºå· | ä¹¦å | å­—æ®µå€¼ | éš¾åº¦æ˜Ÿçº§
                    # åºå·6 + ä¹¦å40 + å­—æ®µå€¼12 + éš¾åº¦æ˜Ÿçº§24
                    headers = ['åºå·', 'ä¹¦å', field_display_name, 'éš¾åº¦æ˜Ÿçº§']
                    col_widths = [6, 40, 12, 24]
            else:
                # åºå·6 + ä¹¦å52 + å­—æ®µå€¼20
                headers = ['åºå·', 'ä¹¦å', field_display_name]
                col_widths = [6, 52, 20]

            table = TableFormatter(headers, col_widths)

            for idx, row in enumerate(results, start=1):
                book_id, book_name, author, field_value = row[:4]

                # æ ¼å¼åŒ–å­—æ®µå€¼
                if value_formatter:
                    formatted_value = value_formatter(field_value)
                else:
                    formatted_value = str(field_value) if field_value is not None else 'N/A'

                if show_difficulty:
                    score, stars = row[4], row[5]
                    # è½¬æ¢æ˜Ÿçº§æ˜¾ç¤ºï¼ˆå¦‚æœæ•°æ®åº“å­˜çš„æ˜¯æ—§æ ¼å¼emojiâ­ï¼Œé‡æ–°è®¡ç®—ï¼‰
                    if 'â­' in stars:
                        stars = difficulty_score_to_star_display(score)

                    # æ ¹æ®field_nameè°ƒæ•´åˆ—é¡ºåº
                    if field_name == 'difficulty_score':
                        # éš¾åº¦æ’è¡Œæ¦œï¼šåºå· | ä¹¦å | éš¾åº¦æ˜Ÿçº§ | éš¾åº¦åˆ†å€¼
                        table.add_row(str(idx), book_name, stars, formatted_value)
                    else:
                        # å…¶ä»–æ’è¡Œæ¦œï¼šåºå· | ä¹¦å | å­—æ®µå€¼ | éš¾åº¦æ˜Ÿçº§
                        table.add_row(str(idx), book_name, formatted_value, stars)
                else:
                    table.add_row(str(idx), book_name, formatted_value)

            # æ ¼å¼åŒ–å¹¶è¾“å‡ºè¡¨æ ¼
            print(table.format())

            # ç¿»é¡µæç¤º
            total_width = sum(table.col_widths) + len(table.col_widths) - 1
            print("-" * total_width)

            # æ„å»ºæç¤ºä¿¡æ¯
            tips = []
            if current_page > 0:
                tips.append("- ä¸Šä¸€é¡µ")

            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µï¼ˆå°è¯•é¢„åŠ è½½ï¼‰
            if current_page + 1 < len(page_cache):
                # å·²ç¼“å­˜ä¸‹ä¸€é¡µ
                if page_cache[current_page + 1]:
                    tips.append("= ä¸‹ä¸€é¡µ")
            elif len(results) == page_size:
                # å½“å‰é¡µæ»¡ï¼Œå¯èƒ½æœ‰ä¸‹ä¸€é¡µ
                tips.append("= ä¸‹ä¸€é¡µ")

            if tips:
                print("  " + " | ".join(tips) + " | å›è½¦è¿”å›")
                choice = input("è¯·é€‰æ‹©: ").strip()
            else:
                choice = input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")

            if choice == '-' and current_page > 0:
                current_page -= 1
            elif choice == '=':
                current_page += 1
            else:
                break

    except Exception as e:
        print(f"\næŸ¥è¯¢å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        conn.close()


# ============================================================================
# å„ç§æ’è¡Œæ¦œåŠŸèƒ½ï¼ˆä½¿ç”¨é€šç”¨æ’è¡Œæ¦œæ¡†æ¶ï¼‰
# ============================================================================

def feature_select_by_star():
    """åŠŸèƒ½2: æŒ‰åˆ†æ•°ç­›é€‰ä¹¦ç±"""
    feature_generic_ranking(
        field_name='difficulty_score',
        field_display_name='éš¾åº¦åˆ†å€¼',
        title='æŒ‰åˆ†æ•°ç­›é€‰ä¹¦ç±',
        asc_desc='ä»ç®€å•åˆ°å›°éš¾',
        desc_desc='ä»å›°éš¾åˆ°ç®€å•',
        show_difficulty=True,
        value_formatter=lambda x: f"{x:.1f}"
    )


def feature_difficulty_ranking():
    """åŠŸèƒ½3: éš¾åº¦æ’è¡Œæ¦œ"""
    feature_generic_ranking(
        field_name='difficulty_score',
        field_display_name='éš¾åº¦åˆ†å€¼',
        title='éš¾åº¦æ’è¡Œæ¦œ',
        asc_desc='ä»ç®€å•åˆ°å›°éš¾',
        desc_desc='ä»å›°éš¾åˆ°ç®€å•',
        show_difficulty=True,
        value_formatter=lambda x: f"{x:.1f}"
    )


def feature_chars_95_ranking():
    """åŠŸèƒ½4: 95%å­—ç§æ•°æ’è¡Œæ¦œ"""
    feature_generic_ranking(
        field_name='chars_95',
        field_display_name='95%å­—æ•°',
        title='95%å­—ç§æ•°æ’è¡Œæ¦œ',
        asc_desc='ä»å°‘åˆ°å¤šï¼Œå­—æ•°è¶Šå°‘è¶Šç®€å•',
        desc_desc='ä»å¤šåˆ°å°‘ï¼Œå­—æ•°è¶Šå¤šè¶Šéš¾',
        show_difficulty=False,
        value_formatter=lambda x: str(int(x)) if x is not None else 'N/A'
    )


def feature_chars_99_ranking():
    """åŠŸèƒ½5: 99%å­—ç§æ•°æ’è¡Œæ¦œ"""
    feature_generic_ranking(
        field_name='chars_99',
        field_display_name='99%å­—æ•°',
        title='99%å­—ç§æ•°æ’è¡Œæ¦œ',
        asc_desc='ä»å°‘åˆ°å¤šï¼Œå­—æ•°è¶Šå°‘è¶Šç®€å•',
        desc_desc='ä»å¤šåˆ°å°‘ï¼Œå­—æ•°è¶Šå¤šè¶Šéš¾',
        show_difficulty=False,
        value_formatter=lambda x: str(int(x)) if x is not None else 'N/A'
    )


def feature_avg_order_95_ranking():
    """åŠŸèƒ½6: 95%å¹³å‡å­—åºæ’è¡Œæ¦œ"""
    feature_generic_ranking(
        field_name='avg_order_95',
        field_display_name='95%å¹³å‡å­—åº',
        title='95%å¹³å‡å­—åºæ’è¡Œæ¦œ',
        asc_desc='ä»å°åˆ°å¤§ï¼Œå­—åºè¶Šå°è¶Šå¸¸ç”¨',
        desc_desc='ä»å¤§åˆ°å°ï¼Œå­—åºè¶Šå¤§è¶Šç”Ÿåƒ»',
        show_difficulty=False,
        value_formatter=lambda x: f"{x:.1f}" if x is not None else 'N/A'
    )


def feature_avg_order_99_ranking():
    """åŠŸèƒ½7: 99%å¹³å‡å­—åºæ’è¡Œæ¦œ"""
    feature_generic_ranking(
        field_name='avg_order_99',
        field_display_name='99%å¹³å‡å­—åº',
        title='99%å¹³å‡å­—åºæ’è¡Œæ¦œ',
        asc_desc='ä»å°åˆ°å¤§ï¼Œå­—åºè¶Šå°è¶Šå¸¸ç”¨',
        desc_desc='ä»å¤§åˆ°å°ï¼Œå­—åºè¶Šå¤§è¶Šç”Ÿåƒ»',
        show_difficulty=False,
        value_formatter=lambda x: f"{x:.1f}" if x is not None else 'N/A'
    )


def feature_char_types_ranking():
    """åŠŸèƒ½8: æ€»å­—ç§æ•°æ’è¡Œæ¦œ"""
    feature_generic_ranking(
        field_name='char_types',
        field_display_name='æ€»å­—ç§æ•°',
        title='æ€»å­—ç§æ•°æ’è¡Œæ¦œ',
        asc_desc='ä»å°‘åˆ°å¤šï¼Œå­—ç§æ•°è¶Šå°‘å­—è¶Šç®€å•',
        desc_desc='ä»å¤šåˆ°å°‘ï¼Œå­—ç§æ•°è¶Šå¤šè¶Šå¤æ‚',
        show_difficulty=False,
        value_formatter=lambda x: str(int(x)) if x is not None else 'N/A'
    )


def feature_search_book():
    """åŠŸèƒ½3: æœä¹¦åŠŸèƒ½ï¼ˆæ¨¡ç³Šæœç´¢ï¼‰"""
    print("\n" + "=" * 70)
    print("ã€æœä¹¦åŠŸèƒ½ã€‘")
    print("=" * 70)

    # è·å–æ•°æ®åº“è¿æ¥
    conn = get_db_connection()
    if not conn:
        input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
        return

    try:
        # ç”¨æˆ·è¾“å…¥æœç´¢å…³é”®è¯
        keyword = input("\nè¯·è¾“å…¥ä¹¦åå…³é”®è¯ï¼ˆæ”¯æŒæ¨¡ç³Šæœç´¢ï¼‰: ").strip()

        if not keyword:
            print("å…³é”®è¯ä¸èƒ½ä¸ºç©ºï¼")
            input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
            return

        # æ¨¡ç³Šæœç´¢
        cursor = conn.cursor()
        sql = """
            SELECT id, book_name, author, difficulty_score, star_level,
                   chars_95, chars_99, avg_order_95, avg_order_99, char_types
            FROM book_difficulty
            WHERE book_name LIKE %s
            ORDER BY difficulty_score ASC
        """
        cursor.execute(sql, (f'%{keyword}%',))
        results = cursor.fetchall()
        cursor.close()

        if not results:
            print(f"\næœªæ‰¾åˆ°åŒ…å« '{keyword}' çš„ä¹¦ç±ï¼")
            input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
            return

        # æ˜¾ç¤ºæœç´¢ç»“æœ
        print("\n" + "=" * 70)
        print(f"æœç´¢åˆ° {len(results)} æœ¬ä¹¦ç±ï¼ˆå…³é”®è¯ï¼š{keyword}ï¼‰")
        print("=" * 70 + "\n")

        for idx, row in enumerate(results, start=1):
            book_id, book_name, author, score, stars, chars_95, chars_99, avg_order_95, avg_order_99, char_types = row

            # è½¬æ¢æ˜Ÿçº§æ˜¾ç¤ºï¼ˆå¦‚æœæ•°æ®åº“å­˜çš„æ˜¯æ—§æ ¼å¼emojiâ­ï¼Œé‡æ–°è®¡ç®—ï¼‰
            if 'â­' in stars:
                stars = difficulty_score_to_star_display(score)

            print(f"{idx}. {book_name}")
            if author:
                print(f"   ä½œè€…: {author}")
            print(f"   éš¾åº¦: {stars}  ({score:.1f}åˆ†)")
            print(f"   95%å­—æ•°: {chars_95}  |  99%å­—æ•°: {chars_99}  |  å­—ç§æ•°: {char_types}")

            # æ˜¾ç¤ºå¹³å‡å­—åºï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
            order_info = []
            if avg_order_95 is not None:
                order_info.append(f"95%å­—åº: {avg_order_95:.1f}")
            if avg_order_99 is not None:
                order_info.append(f"99%å­—åº: {avg_order_99:.1f}")
            if order_info:
                print(f"   {' | '.join(order_info)}")

            print(f"   å­—ç§æ•°: {char_types}")
            print()

        input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")

    except Exception as e:
        print(f"\næœç´¢å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
    finally:
        conn.close()


# ============================================================================
# ä¹¦ç±ç»Ÿè®¡åŠŸèƒ½
# ============================================================================

def feature_book_statistics():
    """åŠŸèƒ½1: ä¹¦ç±å¤æ‚åº¦è®¡ç®—ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰"""
    print("\n" + "=" * 70)
    print("ã€ä¹¦ç±å¤æ‚åº¦è®¡ç®—ã€‘")
    print("=" * 70)

    # 1. æ‰¾å‡ºæ‰€æœ‰txtæ–‡ä»¶
    txt_files = find_txt_files()

    if not txt_files:
        print("\n" + "=" * 70)
        print("âš  booksç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°txtæ–‡ä»¶ï¼")
        print("=" * 70)
        print("\nã€ä½¿ç”¨è¯´æ˜ã€‘\n")
        print("æœ¬å·¥å…·ç”¨äºç»Ÿè®¡txtæ–‡ä»¶ä¸­çš„ä¸­æ–‡å­—ç¬¦é¢‘ç‡ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„ç»Ÿè®¡æŠ¥å‘Šã€‚\n")
        print("ğŸ“‹ ä½¿ç”¨æ­¥éª¤ï¼š")
        print("  1. å°†txtä¹¦ç±æ–‡ä»¶æ”¾å…¥ books ç›®å½•")
        print("  2. åŒå‡»è¿è¡Œæœ¬ç¨‹åº")
        print("  3. æ ¹æ®æç¤ºé€‰æ‹©è¦ç»Ÿè®¡çš„txtæ–‡ä»¶ï¼ˆè¾“å…¥åºå·ï¼‰")
        print("  4. ç­‰å¾…ç»Ÿè®¡å®Œæˆ")
        print("  5. ç»Ÿè®¡ç»“æœä¼šè‡ªåŠ¨ä¿å­˜åˆ° å­—é¢‘ç»Ÿè®¡ç»“æœ ç›®å½•\n")
        print("ğŸ“Š ç»Ÿè®¡å†…å®¹åŒ…æ‹¬ï¼š")
        print("  â€¢ å­—ç§ä¸°å¯Œåº¦ - è¡¡é‡ç”¨å­—å¤šæ ·æ€§")
        print("  â€¢ ç”¨å­—å‡åŒ€åº¦ - è¡¡é‡å„å­—ä½¿ç”¨æ˜¯å¦å¹³å‡")
        print("  â€¢ å­—é¢‘é›†ä¸­åº¦ - è¡¡é‡å¯¹å¸¸ç”¨å­—çš„ä¾èµ–ç¨‹åº¦")
        print("  â€¢ é«˜é¢‘å­—è¦†ç›–ç‡ - å‰Nä¸ªå­—è¦†ç›–å¤šå°‘æ–‡æœ¬")
        print("  â€¢ ç´¯ç§¯è¦†ç›–ç‡ - è¦†ç›–X%æ–‡æœ¬éœ€è¦å¤šå°‘å­—")
        print("  â€¢ è¯¦ç»†å­—é¢‘è¡¨ - æ¯ä¸ªå­—çš„æ¬¡æ•°ã€å æ¯”ã€é¡ºåº\n")
        print("ğŸ”§ æ”¯æŒçš„ç¼–ç æ ¼å¼ï¼š")
        print("  â€¢ UTF-8")
        print("  â€¢ GBK / GB2312 / GB18030ï¼ˆç®€ä½“ä¸­æ–‡ï¼‰")
        print("  â€¢ Big5ï¼ˆç¹ä½“ä¸­æ–‡ï¼‰")
        print("  ç¨‹åºä¼šè‡ªåŠ¨è¯†åˆ«ç¼–ç ï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½®\n")
        print("ğŸ’¡ æç¤ºï¼š")
        print("  â€¢ åªç»Ÿè®¡ä¸­æ–‡å­—ç¬¦ï¼ˆæ±‰å­—ï¼‰ï¼Œæ ‡ç‚¹ç¬¦å·å’Œè‹±æ–‡ä¸è®¡å…¥")
        print("  â€¢ ç»Ÿè®¡å¤§æ–‡ä»¶ï¼ˆ>10MBï¼‰å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
        print("  â€¢ ç”Ÿæˆçš„ç»Ÿè®¡æ–‡ä»¶å¯ç”¨ä»»ä½•æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€æŸ¥çœ‹\n")
        print("=" * 70)
        print("\nè¯·å°†txtæ–‡ä»¶æ”¾åˆ° books ç›®å½•åï¼Œé‡æ–°è¿è¡Œç¨‹åºï¼\n")
        input("æŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
        return

    # 2. å¯¹æ–‡ä»¶åˆ—è¡¨æ’åºï¼šæœªç»Ÿè®¡çš„æ’åœ¨å‰é¢
    txt_files_sorted = sorted(txt_files, key=lambda f: (check_result_exists(f), os.path.basename(f)))

    # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨ä¾›ç”¨æˆ·é€‰æ‹©
    print("\næ‰¾åˆ°ä»¥ä¸‹txtæ–‡ä»¶ï¼ˆbooksç›®å½•ï¼‰ï¼š")
    has_existing_results = False
    for idx, file_path in enumerate(txt_files_sorted, start=1):
        file_size = os.path.getsize(file_path) / 1024  # KB
        # åªæ˜¾ç¤ºæ–‡ä»¶åï¼Œä¸æ˜¾ç¤ºè·¯å¾„
        display_name = os.path.basename(file_path)
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç»“æœ
        if check_result_exists(file_path):
            print(f"{idx}. {display_name} ({file_size:.2f} KB) [å·²æœ‰ç»“æœ]")
            has_existing_results = True
        else:
            print(f"{idx}. {display_name} ({file_size:.2f} KB)")

    if has_existing_results:
        print("\nğŸ’¡ æç¤ºï¼šæ ‡è®°ä¸º[å·²æœ‰ç»“æœ]çš„æ–‡ä»¶åœ¨æ‰¹é‡æ‰«ææ—¶å°†è‡ªåŠ¨è·³è¿‡")

    # 3. ç”¨æˆ·é€‰æ‹©
    while True:
        try:
            choice = input(f"\nè¯·é€‰æ‹©è¦ç»Ÿè®¡çš„æ–‡ä»¶ (1-{len(txt_files_sorted)}ï¼Œè¾“å…¥'all'æ‰«ææ‰€æœ‰ï¼Œè¾“å…¥0è¿”å›): ")
            if choice == '0':
                return

            # å¤„ç†"all"é€‰é¡¹ - æ‰«ææ‰€æœ‰txtæ–‡ä»¶
            if choice.lower() == 'all':
                print("\n" + "=" * 70)
                print("å¼€å§‹æ‰¹é‡æ‰«ææ‰€æœ‰txtæ–‡ä»¶...")
                print("=" * 70)

                # è¿‡æ»¤æ‰å·²æœ‰ç»“æœçš„æ–‡ä»¶
                files_to_process = [f for f in txt_files_sorted if not check_result_exists(f)]
                skipped_count = len(txt_files_sorted) - len(files_to_process)

                if skipped_count > 0:
                    print(f"è·³è¿‡ {skipped_count} ä¸ªå·²æœ‰ç»“æœçš„æ–‡ä»¶")

                if not files_to_process:
                    print("æ‰€æœ‰æ–‡ä»¶éƒ½å·²æœ‰ç»Ÿè®¡ç»“æœï¼Œæ— éœ€é‡å¤è®¡ç®—ï¼")
                    input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                    return

                print(f"æ‰¾åˆ° {len(files_to_process)} ä¸ªæ–‡ä»¶éœ€è¦ç»Ÿè®¡\n")

                # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰
                db_conn = None
                db_config = None
                if DB_UPLOAD_AVAILABLE:
                    try:
                        from db_uploader import load_db_config, check_db_connection, is_db_config_valid
                        db_config = load_db_config()
                        if db_config and is_db_config_valid(db_config):
                            success, db_conn = check_db_connection(db_config)
                            if success:
                                print("âœ“ æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œæ‰¹é‡ä¸Šä¼ æ¨¡å¼å·²å¯ç”¨\n")
                            else:
                                print("âš  æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œå°†è·³è¿‡æ•°æ®åº“ä¸Šä¼ \n")
                        else:
                            print("âš  æ•°æ®åº“é…ç½®æœªå¡«å†™ï¼Œå°†è·³è¿‡æ•°æ®åº“ä¸Šä¼ \n")
                    except Exception as e:
                        print(f"âš  æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†è·³è¿‡æ•°æ®åº“ä¸Šä¼ \n")

                # å­˜å‚¨æ‰€æœ‰ä¹¦ç±çš„ç»Ÿè®¡ç»“æœç”¨äºæ±‡æ€»
                summary_results = []
                upload_success_count = 0
                upload_skip_count = 0

                for idx, file_path in enumerate(files_to_process, start=1):
                    display_name = os.path.basename(file_path)
                    print(f"\n{'='*70}")
                    print(f"[{idx}/{len(files_to_process)}] æ­£åœ¨å¤„ç†: {display_name}")
                    print("-" * 70)
                    result = process_file(file_path, batch_mode=True, db_conn=db_conn, db_config=db_config)
                    if result:
                        summary_results.append(result)
                        # æ›´æ–°æ•°æ®åº“è¿æ¥ï¼ˆå¯èƒ½åœ¨process_fileä¸­è¢«æ›´æ–°ï¼‰
                        if 'db_conn' in result and result['db_conn'] is not None:
                            db_conn = result['db_conn']
                        # ç»Ÿè®¡ä¸Šä¼ æƒ…å†µ
                        upload_status = ""
                        if 'upload_success' in result:
                            if result['upload_success']:
                                upload_success_count += 1
                                upload_status = " | å·²ä¸Šä¼ æ•°æ®åº“"
                            else:
                                upload_skip_count += 1
                                upload_status = " | æœªä¸Šä¼ æ•°æ®åº“"

                        # æ‰“å°å®Œæˆä¿¡æ¯
                        print(f"âœ“ [{idx}/{len(files_to_process)}] å®Œæˆ: {display_name} (å­—ç§æ•°: {result['char_type_count']}, éš¾åº¦: {result['difficulty_score']:.1f}åˆ†{upload_status})")
                    else:
                        print(f"âœ— [{idx}/{len(files_to_process)}] å¤±è´¥: {display_name}")
                    print("="*70)

                # å…³é—­æ•°æ®åº“è¿æ¥
                if db_conn:
                    try:
                        db_conn.close()
                        print("\nâœ“ æ•°æ®åº“è¿æ¥å·²å…³é—­")
                    except:
                        pass

                # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
                if summary_results:
                    generate_summary_report(summary_results)

                print("\n" + "=" * 70)
                print("æ‰¹é‡æ‰«æå®Œæˆï¼")
                print("=" * 70)
                print(f"ç»Ÿè®¡ä¹¦ç±: {len(summary_results)} æœ¬")
                # å¦‚æœæ•°æ®åº“è¿æ¥æˆåŠŸè¿‡ï¼Œæ˜¾ç¤ºä¸Šä¼ ç»Ÿè®¡
                if DB_UPLOAD_AVAILABLE and (upload_success_count > 0 or upload_skip_count > 0):
                    print(f"æ•°æ®åº“ä¸Šä¼ : æˆåŠŸ {upload_success_count} ä¸ªï¼Œè·³è¿‡ {upload_skip_count} ä¸ª")
                print("=" * 70)
                input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                return

            choice_idx = int(choice) - 1
            if 0 <= choice_idx < len(txt_files_sorted):
                selected_file = txt_files_sorted[choice_idx]
                break
            else:
                print("è¾“å…¥çš„æ•°å­—è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°è¾“å…¥ï¼")
        except ValueError:
            print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ•°å­—æˆ–'all'ï¼")

    # æ‰§è¡Œç»Ÿè®¡
    process_file(selected_file)
    input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")


def main():
    print("=" * 50)
    print("å­—é¢‘ç»Ÿè®¡å·¥å…·")
    print("=" * 50)

    # 0. ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹å­˜åœ¨
    ensure_output_folder()

    # æ£€æŸ¥ç¼–ç æ£€æµ‹åº“
    try:
        import chardet
        print("\nâœ“ å·²å®‰è£… chardet åº“ï¼Œå°†ä½¿ç”¨é«˜ç²¾åº¦ç¼–ç æ£€æµ‹")
    except ImportError:
        print("\nâš  æœªå®‰è£… chardet åº“ï¼Œå°†ä½¿ç”¨åŸºç¡€ç¼–ç æ£€æµ‹")
        print("  å»ºè®®å®‰è£…ä»¥æé«˜ç¼–ç æ£€æµ‹å‡†ç¡®ç‡: pip install chardet")

    # ä¸»å¾ªç¯ï¼šæ˜¾ç¤ºåŠŸèƒ½èœå•
    while True:
        print_main_menu()

        choice = input("\nè¯·é€‰æ‹©åŠŸèƒ½ (0-9): ").strip()

        if choice == '0':
            print("\næ„Ÿè°¢ä½¿ç”¨ï¼")
            break
        elif choice == '1':
            # ä¹¦ç±å¤æ‚åº¦è®¡ç®—
            feature_book_statistics()
        elif choice == '2':
            # æŒ‰åˆ†æ•°ç­›é€‰ä¹¦ç±
            feature_select_by_star()
        elif choice == '3':
            # æœä¹¦åŠŸèƒ½
            feature_search_book()
        elif choice == '4':
            # éš¾åº¦æ’è¡Œæ¦œ
            feature_difficulty_ranking()
        elif choice == '5':
            # 95%å­—ç§æ•°æ’è¡Œæ¦œ
            feature_chars_95_ranking()
        elif choice == '6':
            # 99%å­—ç§æ•°æ’è¡Œæ¦œ
            feature_chars_99_ranking()
        elif choice == '7':
            # 95%å¹³å‡å­—åºæ’è¡Œæ¦œ
            feature_avg_order_95_ranking()
        elif choice == '8':
            # 99%å¹³å‡å­—åºæ’è¡Œæ¦œ
            feature_avg_order_99_ranking()
        elif choice == '9':
            # æ€»å­—ç§æ•°æ’è¡Œæ¦œ
            feature_char_types_ranking()
        else:
            print("\næ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥0-9ä¹‹é—´çš„æ•°å­—")


def process_file(selected_file, batch_mode=False, db_conn=None, db_config=None):
    """å¤„ç†å•ä¸ªæ–‡ä»¶çš„ç»Ÿè®¡

    Args:
        selected_file: æ–‡ä»¶å
        batch_mode: æ˜¯å¦æ‰¹é‡æ¨¡å¼ï¼ˆTrueæ—¶è‡ªåŠ¨ä¸Šä¼ ï¼Œä¸è¯¢é—®ç¡®è®¤ï¼‰
        db_conn: å¤ç”¨çš„æ•°æ®åº“è¿æ¥ï¼ˆæ‰¹é‡æ¨¡å¼ç”¨ï¼‰
        db_config: æ•°æ®åº“é…ç½®ï¼ˆæ‰¹é‡æ¨¡å¼ç”¨ï¼‰
    """
    print(f"\næ­£åœ¨ç»Ÿè®¡æ–‡ä»¶: {selected_file}")

    # 4. ç»Ÿè®¡å­—é¢‘
    char_counter, file_encoding = count_chars(selected_file)
    total_chars = sum(char_counter.values())

    if total_chars == 0:
        print("æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—ç¬¦ï¼")
        return

    print(f"å…±ç»Ÿè®¡åˆ° {total_chars} ä¸ªä¸­æ–‡å­—ç¬¦")
    print(f"ä¸é‡å¤å­—ç¬¦æ•°: {len(char_counter)}")

    # 5. åŠ è½½å‚è€ƒå­—è¡¨å’Œå­—åº
    print("\næ­£åœ¨åŠ è½½å‚è€ƒå­—è¡¨ï¼ˆå‰1500.txtï¼‰...")
    reference_chars = load_reference_chars()
    if reference_chars:
        print(f"åŠ è½½äº†å‚è€ƒå­—è¡¨ï¼Œå…± {len(reference_chars)} ä¸ªå­—")
    else:
        print("ä½¿ç”¨dict_simple.txtä½œä¸ºæ›¿ä»£")

    print("æ­£åœ¨åŠ è½½dict.yaml...")
    char_order = load_dict_order()
    print(f"åŠ è½½äº† {len(char_order)} ä¸ªå­—çš„é¡ºåº")

    # 6. æ’åºï¼šæŒ‰ç…§dict.yamlçš„é¡ºåºæ’åº
    # åœ¨dict.yamlä¸­çš„å­—æŒ‰é¡ºåºæ’åˆ—ï¼Œä¸åœ¨çš„å­—æ”¾åœ¨æœ€åæŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åˆ—
    chars_in_dict = []
    chars_not_in_dict = []

    for char, count in char_counter.items():
        if char in char_order:
            chars_in_dict.append((char, count, char_order[char]))
        else:
            chars_not_in_dict.append((char, count))

    # åœ¨å­—å…¸ä¸­çš„å­—æŒ‰å­—åºæ’åº
    chars_in_dict.sort(key=lambda x: x[2])
    # ä¸åœ¨å­—å…¸ä¸­çš„å­—æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åº
    chars_not_in_dict.sort(key=lambda x: x[1], reverse=True)

    # 6.5 è®¡ç®—æ–‡å­—æ•£åˆ—åº¦æŒ‡æ ‡
    # æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åˆ—æ‰€æœ‰å­—ç¬¦ï¼ˆç”¨äºè®¡ç®—ç´¯ç§¯è¦†ç›–ç‡ï¼‰
    all_chars_by_freq = sorted(char_counter.items(), key=lambda x: x[1], reverse=True)

    def calculate_coverage_stats(top_n):
        """
        è®¡ç®—å‚è€ƒå­—è¡¨å‰Nä¸ªå­—çš„è¦†ç›–ç‡
        - å‰1500å­—ï¼šä¼˜å…ˆä½¿ç”¨å‰1500.txt
        - è¶…è¿‡1500çš„éƒ¨åˆ†ï¼šä½¿ç”¨dict_simple.txtæŒ‰å­—åºè¡¥å……
        """
        ref_top_chars = set()

        if reference_chars and len(reference_chars) > 0:
            # å‰1500å­—ä½¿ç”¨å‰1500.txt
            if top_n <= len(reference_chars):
                ref_top_chars = set(reference_chars[:top_n])
            else:
                # è¶…è¿‡1500ï¼šå‰1500ç”¨reference_charsï¼Œå‰©ä½™ç”¨dict_simple.txtè¡¥å……
                ref_top_chars = set(reference_chars)  # å…ˆæ·»åŠ å…¨éƒ¨1500ä¸ª
                reference_chars_set = set(reference_chars)

                # ä»dict_simple.txtè¡¥å……å‰©ä½™çš„å­—ï¼ˆæŒ‰å­—åºï¼Œæ’é™¤å·²åœ¨å‰1500ä¸­çš„å­—ï¼‰
                remaining_needed = top_n - len(reference_chars)
                added_count = 0
                for char, order in sorted(char_order.items(), key=lambda x: x[1]):
                    if char not in reference_chars_set:
                        ref_top_chars.add(char)
                        added_count += 1
                        if added_count >= remaining_needed:
                            break
        else:
            # å›é€€æ–¹æ¡ˆï¼šå…¨éƒ¨ä½¿ç”¨dict_simple.txtçš„å­—åº
            for char, order in char_order.items():
                if order <= top_n:
                    ref_top_chars.add(char)

        # è®¡ç®—è¿™äº›å­—åœ¨æ–‡æœ¬ä¸­çš„å‡ºç°æ¬¡æ•°
        top_count = 0
        for char in ref_top_chars:
            if char in char_counter:
                top_count += char_counter[char]

        coverage = (top_count / total_chars) * 100 if total_chars > 0 else 0
        avg_count = top_count / len(ref_top_chars) if len(ref_top_chars) > 0 else 0

        return {
            'actual_n': len(ref_top_chars),
            'coverage': coverage,
            'avg_count': avg_count,
            'total_count': top_count
        }

    # è®¡ç®—ä¸åŒåŒºé—´çš„ç»Ÿè®¡
    stats_ranges = [10, 50, 100, 500, 1000, 1500, 2000, 3000, 5000]
    coverage_stats = {}
    for n in stats_ranges:
        coverage_stats[n] = calculate_coverage_stats(n)

    # è®¡ç®—ç´¯ç§¯è¦†ç›–ç‡ï¼ˆè¦†ç›–X%çš„æ–‡æœ¬éœ€è¦å¤šå°‘å­—ï¼‰
    cumulative_coverage = []
    cumulative_count = 0
    for idx, (char, count) in enumerate(all_chars_by_freq, start=1):
        cumulative_count += count
        coverage_pct = (cumulative_count / total_chars) * 100
        if coverage_pct >= 50 and not any(c[0] == 50 for c in cumulative_coverage):
            cumulative_coverage.append((50, idx, coverage_pct))
        if coverage_pct >= 80 and not any(c[0] == 80 for c in cumulative_coverage):
            cumulative_coverage.append((80, idx, coverage_pct))
        if coverage_pct >= 90 and not any(c[0] == 90 for c in cumulative_coverage):
            cumulative_coverage.append((90, idx, coverage_pct))
        if coverage_pct >= 95 and not any(c[0] == 95 for c in cumulative_coverage):
            cumulative_coverage.append((95, idx, coverage_pct))
        if coverage_pct >= 99 and not any(c[0] == 99 for c in cumulative_coverage):
            cumulative_coverage.append((99, idx, coverage_pct))

    # 100%è¦†ç›–å°±æ˜¯æ‰€æœ‰å­—ç§æ•°
    cumulative_coverage.append((100, len(char_counter), 100.0))

    # 6.6 å½¢ç ç”¨æˆ·ä¸“å±åˆ†æ
    print("\næ­£åœ¨åŠ è½½å¸¸ç”¨å­—è¡¨...")
    common_chars = load_common_chars(reference_chars, char_order)
    print(f"åŠ è½½äº† {len(common_chars)} ä¸ªå¸¸ç”¨å­—")

    print("æ­£åœ¨åˆ†æç”Ÿåƒ»å­—...")
    rare_analysis = analyze_rare_chars(char_counter, common_chars)

    # è®¡ç®—95%å’Œ99%è¦†ç›–çš„å¹³å‡å­—åº
    print("æ­£åœ¨è®¡ç®—å¹³å‡å­—åº...")
    chars_for_95_pct = 0
    chars_for_99_pct = 0
    for target_pct, char_count, _ in cumulative_coverage:
        if target_pct == 95:
            chars_for_95_pct = char_count
        if target_pct == 99:
            chars_for_99_pct = char_count

    # è·å–è¾¾åˆ°95%å’Œ99%æ‰€éœ€çš„å­—
    chars_for_95_list = all_chars_by_freq[:chars_for_95_pct] if chars_for_95_pct > 0 else []
    chars_for_99_list = all_chars_by_freq[:chars_for_99_pct] if chars_for_99_pct > 0 else []

    # è®¡ç®—å¹³å‡å­—åº
    avg_order_95 = calculate_avg_char_order(chars_for_95_list, char_order)
    avg_order_99 = calculate_avg_char_order(chars_for_99_list, char_order)

    # è®¡ç®—è¶…å‡ºå‰1500.txtçš„å­—ç§æ•°
    print("æ­£åœ¨è®¡ç®—è¶…å‡ºå‰1500çš„å­—ç§æ•°...")
    if reference_chars:
        reference_chars_set = set(reference_chars)
        extra_char_types = sum(1 for char in char_counter.keys() if char not in reference_chars_set)

        # è®¡ç®—95%å’Œ99%è¦†ç›–å­—æ•°ä¸­å‰1500å†…å¤–çš„åˆ†å¸ƒ
        chars_95_in_ref = sum(1 for char, _ in chars_for_95_list if char in reference_chars_set)
        chars_95_out_ref = len(chars_for_95_list) - chars_95_in_ref
        chars_99_in_ref = sum(1 for char, _ in chars_for_99_list if char in reference_chars_set)
        chars_99_out_ref = len(chars_for_99_list) - chars_99_in_ref
    else:
        # å¦‚æœæ²¡æœ‰å‰1500.txtï¼Œä½¿ç”¨CHAR_TYPES_BASELINEä½œä¸ºåŸºå‡†
        extra_char_types = max(0, len(char_counter) - CHAR_TYPES_BASELINE)
        chars_95_in_ref = 0
        chars_95_out_ref = 0
        chars_99_in_ref = 0
        chars_99_out_ref = 0

    print("æ­£åœ¨è®¡ç®—ä¹¦ç±éš¾åº¦...")
    stars, difficulty_score, score_details = calculate_difficulty_rating(
        char_counter, total_chars, coverage_stats, cumulative_coverage, avg_order_95, avg_order_99, extra_char_types
    )

    # 7. è¾“å‡ºç»“æœåˆ°æ–‡ä»¶ï¼ˆåªä½¿ç”¨æ–‡ä»¶åï¼Œä¸åŒ…å«è·¯å¾„ï¼‰
    base_filename = os.path.basename(selected_file)  # å»æ‰è·¯å¾„ï¼Œåªä¿ç•™æ–‡ä»¶å
    output_filename = f"{os.path.splitext(base_filename)[0]}_å­—é¢‘ç»Ÿè®¡_éš¾åº¦{difficulty_score:.1f}.txt"
    output_file = os.path.join(OUTPUT_FOLDER, output_filename)

    with open(output_file, 'w', encoding='utf-8') as f:
        # å†™å…¥è¡¨å¤´
        f.write("=" * 80 + "\n")
        f.write("ã€ä¹¦ç±éš¾åº¦åˆ†ææŠ¥å‘Šã€‘\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"æ–‡ä»¶å: {base_filename}\n")
        f.write(f"æ–‡ä»¶ç¼–ç : {file_encoding.upper() if file_encoding else 'æœªçŸ¥'}\n")
        f.write(f"æ€»å­—ç¬¦æ•°: {total_chars}\n")
        f.write(f"å­—ç§æ•°: {len(char_counter)} ä¸ªï¼ˆå…¶ä¸­å‰1500å†…: {len(char_counter) - extra_char_types} ä¸ªï¼Œå‰1500å¤–: {extra_char_types} ä¸ªï¼‰\n")
        f.write("=" * 80 + "\n\n")

        # ========== æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡ï¼ˆå½¢ç ç”¨æˆ·æœ€å…³å¿ƒï¼‰ ==========
        f.write("ã€æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡ã€‘\n")
        f.write("=" * 80 + "\n\n")

        # 1. ä¹¦ç±éš¾åº¦è¯„çº§
        f.write(f"1. ä¹¦ç±éš¾åº¦è¯„çº§\n")
        f.write(f"   {stars}  ï¼ˆéš¾åº¦åˆ†æ•°ï¼š{difficulty_score:.1f}/100ï¼‰\n\n")
        f.write(f"   è¯„ä¼°ç»´åº¦ï¼š\n")

        # åªæ˜¾ç¤ºæƒé‡>0çš„ç»´åº¦
        if WEIGHT_CHAR_TYPES > 0:
            f.write(f"     â€¢ å­—ç§æ•°ï¼š{len(char_counter)} ä¸ªï¼ˆå‰1500å†…: {len(char_counter) - extra_char_types} ä¸ªï¼Œå‰1500å¤–: {extra_char_types} ä¸ªï¼‰\n")

        if WEIGHT_COVERAGE_500 > 0:
            f.write(f"     â€¢ å‰500å­—è¦†ç›–ç‡ï¼š{coverage_stats[500]['coverage']:.2f}%\n")
        if WEIGHT_COVERAGE_1000 > 0:
            f.write(f"     â€¢ å‰1000å­—è¦†ç›–ç‡ï¼š{coverage_stats[1000]['coverage']:.2f}%\n")
        if WEIGHT_COVERAGE_1500 > 0:
            f.write(f"     â€¢ å‰1500å­—è¦†ç›–ç‡ï¼š{coverage_stats[1500]['coverage']:.2f}%\n")

        # æ‰¾å‡º95%å’Œ99%æ‰€éœ€å­—æ•°
        chars_95, chars_99 = 0, 0
        for target_pct, char_count, _ in cumulative_coverage:
            if target_pct == 95:
                chars_95 = char_count
            if target_pct == 99:
                chars_99 = char_count

        if WEIGHT_CHARS_95 > 0:
            f.write(f"     â€¢ 95%è¦†ç›–æ‰€éœ€å­—æ•°ï¼š{chars_95} ä¸ªï¼ˆå‰{CHAR_TYPES_BASELINE}å†…: {chars_95_in_ref}ï¼Œå‰{CHAR_TYPES_BASELINE}å¤–: {chars_95_out_ref}ï¼‰\n")
        if WEIGHT_CHARS_99 > 0:
            f.write(f"     â€¢ 99%è¦†ç›–æ‰€éœ€å­—æ•°ï¼š{chars_99} ä¸ªï¼ˆå‰{CHAR_TYPES_BASELINE}å†…: {chars_99_in_ref}ï¼Œå‰{CHAR_TYPES_BASELINE}å¤–: {chars_99_out_ref}ï¼‰\n")

        # æ·»åŠ å¹³å‡å­—åº
        if WEIGHT_ORDER_95 > 0:
            if avg_order_95 is not None:
                f.write(f"     â€¢ 95%å¹³å‡å­—åºï¼š{avg_order_95:.1f}  ï¼ˆå­—åºè¶Šå°=è¶Šå¸¸ç”¨ï¼‰\n")
            else:
                f.write(f"     â€¢ 95%å¹³å‡å­—åºï¼šæ— æ•°æ®\n")

        if WEIGHT_ORDER_99 > 0:
            if avg_order_99 is not None:
                f.write(f"     â€¢ 99%å¹³å‡å­—åºï¼š{avg_order_99:.1f}  ï¼ˆå­—åºè¶Šå°=è¶Šå¸¸ç”¨ï¼‰\n")
            else:
                f.write(f"     â€¢ 99%å¹³å‡å­—åºï¼šæ— æ•°æ®\n")
        f.write("\n")
        f.write(f"   ğŸ’¡ è¯´æ˜ï¼š\n")
        # åŠ¨æ€è®¡ç®—æƒé‡åˆ†é…ï¼ˆåªæ˜¾ç¤ºé0æƒé‡ï¼‰
        total_weight = score_details['total_weight']
        if total_weight > 0:
            weight_parts = []
            coverage_weight = WEIGHT_COVERAGE_500 + WEIGHT_COVERAGE_1000 + WEIGHT_COVERAGE_1500
            if coverage_weight > 0:
                coverage_pct = coverage_weight / total_weight * 100
                weight_parts.append(f"è¦†ç›–ç‡{coverage_pct:.0f}%")

            chars_weight = WEIGHT_CHARS_95 + WEIGHT_CHARS_99
            if chars_weight > 0:
                chars_pct = chars_weight / total_weight * 100
                weight_parts.append(f"å­—æ•°{chars_pct:.0f}%")

            order_weight = WEIGHT_ORDER_95 + WEIGHT_ORDER_99
            if order_weight > 0:
                order_pct = order_weight / total_weight * 100
                weight_parts.append(f"å­—åº{order_pct:.0f}%")

            if WEIGHT_CHAR_TYPES > 0:
                types_pct = WEIGHT_CHAR_TYPES / total_weight * 100
                weight_parts.append(f"å­—ç§{types_pct:.0f}%")

            f.write(f"     - æƒé‡åˆ†é…ï¼š{' + '.join(weight_parts)}\n")
        else:
            f.write(f"     - æƒé‡åˆ†é…ï¼šæœªè®¾ç½®\n")
        f.write("\n")

        # 2. ç”Ÿåƒ»å­—åˆ†æ
        f.write(f"2. ç”Ÿåƒ»å­—åˆ†æ\n")
        f.write(f"   ç”Ÿåƒ»å­—å­—ç§æ•°ï¼š{rare_analysis['rare_type_count']} ä¸ªï¼ˆå å­—ç§{rare_analysis['rare_type_ratio']*100:.2f}%ï¼‰\n")
        f.write(f"   ç”Ÿåƒ»å­—å‡ºç°æ¬¡æ•°ï¼š{rare_analysis['rare_char_count']} æ¬¡ï¼ˆå æ–‡æœ¬{rare_analysis['rare_char_ratio']*100:.2f}%ï¼‰\n")
        f.write(f"   è¯´æ˜ï¼šç”Ÿåƒ»å­—æŒ‡ä¸åœ¨å¸¸ç”¨3500å­—å†…çš„å­—ï¼Œæ‰“å­—æ—¶å¯èƒ½éœ€è¦æŸ¥ç¼–ç \n")

        # æ˜¾ç¤ºå‰20ä¸ªæœ€å¸¸è§çš„ç”Ÿåƒ»å­—
        if rare_analysis['rare_chars']:
            f.write(f"\n   æœ€å¸¸è§çš„ç”Ÿåƒ»å­—ï¼ˆå‰20ä¸ªï¼‰ï¼š\n")
            top_rare = rare_analysis['rare_chars'][:20]
            for i in range(0, len(top_rare), 10):
                chars_line = "ã€".join([f"{char}({count})" for char, count in top_rare[i:i+10]])
                f.write(f"   {chars_line}\n")

        f.write("\n" + "=" * 80 + "\n\n")

        # é«˜é¢‘å­—è¦†ç›–ç‡åˆ†æ - ä½¿ç”¨TableFormatter
        f.write("ã€é«˜é¢‘å­—è¦†ç›–ç‡åˆ†æã€‘\n")
        coverage_table = TableFormatter(
            ['åŒºé—´', 'ç´¯è®¡æ¬¡æ•°', 'è¦†ç›–ç‡', 'å¹³å‡å‡ºç°æ¬¡æ•°'],
            [12, 15, 15, 15]
        )
        for n in stats_ranges:
            stats = coverage_stats[n]
            coverage_table.add_row(
                f"å‰{n}",
                str(stats['total_count']),
                f"{stats['coverage']:.2f}%",
                f"{stats['avg_count']:.1f}"
            )

        # è¾“å‡ºè¡¨æ ¼ï¼Œæ¯è¡Œå‰é¢åŠ 3ä¸ªç©ºæ ¼ç¼©è¿›
        for line in coverage_table.format().split('\n'):
            f.write(f"   {line}\n")

        # 1. ç´¯ç§¯è¦†ç›–ç‡åˆ†æ - ä½¿ç”¨TableFormatter
        f.write(f"\n1. ç´¯ç§¯è¦†ç›–ç‡åˆ†æ\n")
        cumulative_table = TableFormatter(['è¦†ç›–ç‡', 'æ‰€éœ€å­—æ•°'], [15, 15])
        for target_pct, char_count, actual_pct in cumulative_coverage:
            cumulative_table.add_row(f"{actual_pct:.2f}%", str(char_count))

        # è¾“å‡ºè¡¨æ ¼ï¼Œæ¯è¡Œå‰é¢åŠ 3ä¸ªç©ºæ ¼ç¼©è¿›
        for line in cumulative_table.format().split('\n'):
            f.write(f"   {line}\n")

        # 2. æœ€é«˜é¢‘å­—åˆ†æ
        f.write(f"\n2. æœ€é«˜é¢‘å­—åˆ†æ\n")
        top_char, top_count = all_chars_by_freq[0]
        top_pct = (top_count / total_chars) * 100
        f.write(f"   æœ€é«˜é¢‘å­—: '{top_char}' å‡ºç° {top_count} æ¬¡ï¼Œå æ¯” {top_pct:.2f}%\n")

        if len(all_chars_by_freq) >= 3:
            top3_count = sum(count for char, count in all_chars_by_freq[:3])
            top3_pct = (top3_count / total_chars) * 100
            top3_chars = 'ã€'.join([char for char, count in all_chars_by_freq[:3]])
            f.write(f"   å‰3ä¸ªå­—: {top3_chars}ï¼Œç´¯è®¡å æ¯” {top3_pct:.2f}%\n")

        if len(all_chars_by_freq) >= 10:
            top10_count = sum(count for char, count in all_chars_by_freq[:10])
            top10_pct = (top10_count / total_chars) * 100
            f.write(f"   å‰10ä¸ªå­—: ç´¯è®¡å æ¯” {top10_pct:.2f}%\n")

        # 3. ä½é¢‘å­—åˆ†æ
        f.write(f"\n3. ä½é¢‘å­—åˆ†æ\n")
        once_chars = [char for char, count in char_counter.items() if count == 1]
        twice_chars = [char for char, count in char_counter.items() if count == 2]
        low_freq_chars = [char for char, count in char_counter.items() if count <= 5]

        f.write(f"   ä»…å‡ºç°1æ¬¡çš„å­—: {len(once_chars)} ä¸ª ({len(once_chars)/len(char_counter)*100:.2f}%)\n")
        f.write(f"   ä»…å‡ºç°2æ¬¡çš„å­—: {len(twice_chars)} ä¸ª ({len(twice_chars)/len(char_counter)*100:.2f}%)\n")
        f.write(f"   å‡ºç°â‰¤5æ¬¡çš„å­—: {len(low_freq_chars)} ä¸ª ({len(low_freq_chars)/len(char_counter)*100:.2f}%)\n")

        f.write("\n" + "=" * 80 + "\n\n")

        # æ·»åŠ è¯¦ç»†ç®—å¼å±•ç¤ºï¼ˆåªæ˜¾ç¤ºæƒé‡>0çš„ç»´åº¦ï¼‰
        f.write(f"   ğŸ“Š éš¾åº¦è®¡ç®—è¯¦æƒ…ï¼š\n")
        f.write(f"   ------------------------------------------------------------------\n")

        # è¦†ç›–ç‡ç»´åº¦
        coverage_weight = WEIGHT_COVERAGE_500 + WEIGHT_COVERAGE_1000 + WEIGHT_COVERAGE_1500
        if coverage_weight > 0:
            score_500, weight_500, val_500 = score_details['coverage_500']
            score_1000, weight_1000, val_1000 = score_details['coverage_1000']
            score_1500, weight_1500, val_1500 = score_details['coverage_1500']
            coverage_total = score_500 + score_1000 + score_1500
            coverage_pct = coverage_weight / total_weight * 100 if total_weight > 0 else 0

            f.write(f"   ã€è¦†ç›–ç‡ç»´åº¦ã€‘ (æƒé‡ {coverage_pct:.0f}%)\n")
            if COVERAGE_LINEAR_MODE:
                f.write(f"     è¯„åˆ†æ ‡å‡†: 0%â†’æ»¡åˆ† (æœ€éš¾), 100%â†’0åˆ† (æœ€ç®€å•), åŠ é€Ÿç³»æ•°={COVERAGE_ACCELERATION}\n")
            else:
                f.write(f"     è¯„åˆ†æ ‡å‡†: åŒºé—´æ¨¡å¼, 500å­—({COVERAGE_500_MIN}%-{COVERAGE_500_MAX}%), ")
                f.write(f"1000å­—({COVERAGE_1000_MIN}%-{COVERAGE_1000_MAX}%), ")
                f.write(f"1500å­—({COVERAGE_1500_MIN}%-{COVERAGE_1500_MAX}%)\n")

            if weight_500 > 0:
                f.write(f"     å‰500å­—è¦†ç›–: {val_500:.1f}% â†’ å¾—åˆ† {score_500:.2f}/{weight_500}\n")
            if weight_1000 > 0:
                f.write(f"     å‰1000å­—è¦†ç›–: {val_1000:.1f}% â†’ å¾—åˆ† {score_1000:.2f}/{weight_1000}\n")
            if weight_1500 > 0:
                f.write(f"     å‰1500å­—è¦†ç›–: {val_1500:.1f}% â†’ å¾—åˆ† {score_1500:.2f}/{weight_1500}\n")
            f.write(f"     å°è®¡: {coverage_total:.2f}\n\n")

        # å­—æ•°ç»´åº¦
        chars_weight = WEIGHT_CHARS_95 + WEIGHT_CHARS_99
        if chars_weight > 0:
            score_95c, weight_95c, val_95c = score_details['chars_95']
            score_99c, weight_99c, val_99c = score_details['chars_99']
            chars_total = score_95c + score_99c
            chars_pct = chars_weight / total_weight * 100 if total_weight > 0 else 0

            f.write(f"   ã€å­—æ•°ç»´åº¦ã€‘ (æƒé‡ {chars_pct:.0f}%)\n")
            f.write(f"     è¯„åˆ†æ ‡å‡†: 95%åŒºé—´[{CHARS_95_MIN}-{CHARS_95_MAX}å­—], 99%åŒºé—´[{CHARS_99_MIN}-{CHARS_99_MAX}å­—]\n")
            if weight_95c > 0:
                f.write(f"     95%è¦†ç›–å­—æ•°: {val_95c} ä¸ª â†’ å¾—åˆ† {score_95c:.2f}/{weight_95c}\n")
            if weight_99c > 0:
                f.write(f"     99%è¦†ç›–å­—æ•°: {val_99c} ä¸ª â†’ å¾—åˆ† {score_99c:.2f}/{weight_99c}\n")
            f.write(f"     å°è®¡: {chars_total:.2f}\n\n")

        # å­—åºç»´åº¦
        order_weight = WEIGHT_ORDER_95 + WEIGHT_ORDER_99
        if order_weight > 0:
            score_95o, weight_95o, val_95o = score_details['order_95']
            score_99o, weight_99o, val_99o = score_details['order_99']
            order_total = score_95o + score_99o
            order_pct = order_weight / total_weight * 100 if total_weight > 0 else 0

            f.write(f"   ã€å­—åºç»´åº¦ã€‘ (æƒé‡ {order_pct:.0f}%)\n")
            f.write(f"     è¯„åˆ†æ ‡å‡†: 95%åŒºé—´[{ORDER_95_MIN}-{ORDER_95_MAX}], 99%åŒºé—´[{ORDER_99_MIN}-{ORDER_99_MAX}], åŠ é€Ÿç³»æ•°={ORDER_ACCELERATION}\n")
            if weight_95o > 0:
                if val_95o is not None:
                    f.write(f"     95%å¹³å‡å­—åº: {val_95o:.1f} â†’ å¾—åˆ† {score_95o:.2f}/{weight_95o}\n")
                else:
                    f.write(f"     95%å¹³å‡å­—åº: æ— æ•°æ® â†’ å¾—åˆ† {score_95o:.2f}/{weight_95o}\n")
            if weight_99o > 0:
                if val_99o is not None:
                    f.write(f"     99%å¹³å‡å­—åº: {val_99o:.1f} â†’ å¾—åˆ† {score_99o:.2f}/{weight_99o}\n")
                else:
                    f.write(f"     99%å¹³å‡å­—åº: æ— æ•°æ® â†’ å¾—åˆ† {score_99o:.2f}/{weight_99o}\n")
            f.write(f"     å°è®¡: {order_total:.2f}\n\n")

        # å­—ç§ç»´åº¦
        if WEIGHT_CHAR_TYPES > 0:
            score_types, weight_types, val_types = score_details['char_types']
            types_pct = WEIGHT_CHAR_TYPES / total_weight * 100 if total_weight > 0 else 0

            f.write(f"   ã€å­—ç§ç»´åº¦ã€‘ (æƒé‡ {types_pct:.0f}%)\n")
            f.write(f"     è¯„åˆ†æ ‡å‡†: å‰{CHAR_TYPES_BASELINE}å­—å¤–çš„å­—ç§æ•°, åŒºé—´[{CHAR_TYPES_MIN}-{CHAR_TYPES_MAX}ä¸ª]\n")
            f.write(f"     å‰1500å¤–å­—ç§: {val_types} ä¸ª â†’ å¾—åˆ† {score_types:.2f}/{weight_types}\n")
            f.write(f"     å°è®¡: {score_types:.2f}\n\n")

        # æ€»åˆ†è®¡ç®—
        raw_score = score_details['raw_score']
        f.write(f"   ã€æ€»åˆ†è®¡ç®—ã€‘\n")
        f.write(f"     åŸå§‹å¾—åˆ†: {raw_score:.2f}\n")
        f.write(f"     æ€»æƒé‡: {total_weight:.2f}\n")
        f.write(f"     å½’ä¸€åŒ–å…¬å¼: (åŸå§‹å¾—åˆ† / æ€»æƒé‡) Ã— 100\n")
        f.write(f"     æœ€ç»ˆéš¾åº¦: ({raw_score:.2f} / {total_weight:.2f}) Ã— 100 = {difficulty_score:.1f} åˆ†\n")
        f.write(f"   ------------------------------------------------------------------\n")
        f.write("\n")

        # å†™å…¥è¯¦ç»†å­—é¢‘è¡¨
        f.write("ã€è¯¦ç»†å­—é¢‘ç»Ÿè®¡è¡¨ã€‘\n")
        f.write("=" * 80 + "\n")
        f.write(f"{'å­—':<5}{'æ¬¡æ•°':<10}{'æ¯”ä¾‹(%)':<12}{'åŸæ¬¡åº':<10}\n")
        f.write("=" * 80 + "\n")

        # å†™å…¥åœ¨dict.yamlä¸­çš„å­—
        for char, count, order in chars_in_dict:
            percentage = (count / total_chars) * 100
            f.write(f"{char:<5}{count:<10}{percentage:<12.2f}{order:<10}\n")

        # å†™å…¥ä¸åœ¨dict.yamlä¸­çš„å­—
        if chars_not_in_dict:
            f.write("\n" + "-" * 80 + "\n")
            f.write("ä»¥ä¸‹å­—ç¬¦ä¸åœ¨dict.yamlä¸­ï¼ˆæŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åˆ—ï¼‰:\n")
            f.write("-" * 80 + "\n")
            for char, count in chars_not_in_dict:
                percentage = (count / total_chars) * 100
                f.write(f"{char:<5}{count:<10}{percentage:<12.2f}{'N/A':<10}\n")

        # å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒºï¼Œç¡®ä¿æ•°æ®ç«‹å³å†™å…¥ç£ç›˜
        f.flush()
        os.fsync(f.fileno())

    print(f"\nç»Ÿè®¡å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    # æ˜¾ç¤ºæ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡
    print("\n" + "=" * 70)
    print("ã€æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡ã€‘")
    print("=" * 70)
    print(f"æ–‡ä»¶: {base_filename}")
    print(f"ä¹¦ç±éš¾åº¦: {stars}  ({difficulty_score:.1f}/100)")
    print(f"å­—ç§æ•°: {len(char_counter)} ä¸ªï¼ˆå‰1500å†…: {len(char_counter) - extra_char_types}ï¼Œå‰1500å¤–: {extra_char_types}ï¼‰")
    print(f"ç”Ÿåƒ»å­—: {rare_analysis['rare_type_count']} ä¸ªï¼ˆ{rare_analysis['rare_type_ratio']*100:.1f}%ï¼‰")
    print(f"\nè¦†ç›–ç‡åˆ†æ:")
    print(f"  å‰500å­—:  {coverage_stats[500]['coverage']:.1f}%")
    print(f"  å‰1000å­—: {coverage_stats[1000]['coverage']:.1f}%")
    print(f"  å‰1500å­—: {coverage_stats[1500]['coverage']:.1f}%")

    # æ‰¾å‡º95%å’Œ99%çš„æ•°æ®
    chars_95, chars_99 = 0, 0
    for target_pct, char_count, _ in cumulative_coverage:
        if target_pct == 95:
            chars_95 = char_count
        if target_pct == 99:
            chars_99 = char_count

    print(f"\nç´¯ç§¯è¦†ç›–:")
    print(f"  95%: {chars_95}ä¸ªå­—", end="")
    if avg_order_95:
        print(f" (å¹³å‡å­—åº {avg_order_95:.0f})")
    else:
        print()
    print(f"  99%: {chars_99}ä¸ªå­—", end="")
    if avg_order_99:
        print(f" (å¹³å‡å­—åº {avg_order_99:.0f})")
    else:
        print()

    print("\n" + "=" * 70)

    # æ•°æ®åº“ä¸Šä¼ ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
    upload_success = False
    if DB_UPLOAD_AVAILABLE:
        try:
            success, returned_conn = handle_database_upload(
                base_filename, total_chars, char_counter, coverage_stats,
                avg_order_95, avg_order_99, chars_95, chars_99,
                chars_95_in_ref, chars_95_out_ref, chars_99_in_ref, chars_99_out_ref,
                extra_char_types, difficulty_score, stars, rare_analysis,
                batch_mode=batch_mode,
                db_conn=db_conn,
                db_config=db_config
            )
            upload_success = success
            # æ‰¹é‡æ¨¡å¼ä¸‹ï¼Œè¿”å›æ›´æ–°åçš„è¿æ¥
            if batch_mode and returned_conn is not None:
                db_conn = returned_conn

            # è¿”å›æ•°æ®åº“è¿æ¥ä¾›æ‰¹é‡æ¨¡å¼å¤ç”¨
            return {
                'filename': base_filename,
                'total_chars': total_chars,
                'char_type_count': len(char_counter),
                'extra_char_types': extra_char_types,
                'rare_type_count': rare_analysis['rare_type_count'],
                'rare_type_ratio': rare_analysis['rare_type_ratio'],
                'coverage_500': coverage_stats[500]['coverage'],
                'coverage_1000': coverage_stats[1000]['coverage'],
                'coverage_1500': coverage_stats[1500]['coverage'],
                'chars_95': chars_95,
                'chars_99': chars_99,
                'avg_order_95': avg_order_95,
                'avg_order_99': avg_order_99,
                'difficulty_score': difficulty_score,
                'stars': stars,
                'db_conn': db_conn,
                'db_config': db_config,
                'upload_success': upload_success
            }
        except Exception as e:
            print(f"\næ•°æ®åº“ä¸Šä¼ å‡ºé”™ï¼ˆå·²è·³è¿‡ï¼‰: {e}")

    # è¿”å›ç»Ÿè®¡ç»“æœç”¨äºæ±‡æ€»æŠ¥å‘Š
    return {
        'filename': base_filename,
        'total_chars': total_chars,
        'char_type_count': len(char_counter),
        'extra_char_types': extra_char_types,  # è¶…å‡ºå‰1500çš„å­—ç§æ•°
        'rare_type_count': rare_analysis['rare_type_count'],
        'rare_type_ratio': rare_analysis['rare_type_ratio'],
        'coverage_500': coverage_stats[500]['coverage'],
        'coverage_1000': coverage_stats[1000]['coverage'],
        'coverage_1500': coverage_stats[1500]['coverage'],
        'chars_95': chars_95,
        'chars_99': chars_99,
        'avg_order_95': avg_order_95,
        'avg_order_99': avg_order_99,
        'difficulty_score': difficulty_score,
        'stars': stars,
        'upload_success': upload_success
    }


def generate_summary_report(results):
    """ç”Ÿæˆæ‰€æœ‰ä¹¦ç±çš„æ±‡æ€»æŠ¥å‘Š"""
    output_file = os.path.join(OUTPUT_FOLDER, "ã€æ±‡æ€»æŠ¥å‘Šã€‘æ‰€æœ‰ä¹¦ç±éš¾åº¦å¯¹æ¯”.txt")

    # æŒ‰éš¾åº¦åˆ†æ•°æ’åº
    results_sorted = sorted(results, key=lambda x: x['difficulty_score'])

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("ã€æ‰€æœ‰ä¹¦ç±éš¾åº¦æ±‡æ€»æŠ¥å‘Šã€‘\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"ç»Ÿè®¡æ—¶é—´: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"ç»Ÿè®¡ä¹¦ç±æ•°: {len(results)} æœ¬\n")
        f.write("=" * 80 + "\n\n")

        # æŒ‰éš¾åº¦æ’åºçš„è¡¨æ ¼
        f.write("ã€æŒ‰éš¾åº¦æ’åºã€‘\n")
        f.write("-" * 80 + "\n")
        f.write(f"{'æ’å':<6}{'ä¹¦å':<30}{'éš¾åº¦':<8}{'åˆ†æ•°':<10}{'å­—ç§æ•°':<10}{'ç”Ÿåƒ»å­—':<10}\n")
        f.write("-" * 80 + "\n")

        for idx, r in enumerate(results_sorted, start=1):
            # æˆªæ–­è¿‡é•¿çš„æ–‡ä»¶å
            filename = r['filename'][:28] + '..' if len(r['filename']) > 30 else r['filename']
            f.write(f"{idx:<6}{filename:<30}{r['stars']:<8}{r['difficulty_score']:<10.1f}"
                   f"{r['char_type_count']:<10}{r['rare_type_count']:<10}\n")

        f.write("\n" + "=" * 80 + "\n\n")

        # è¯¦ç»†å¯¹æ¯”è¡¨
        f.write("ã€è¯¦ç»†æ•°æ®å¯¹æ¯”ã€‘\n")
        f.write("-" * 80 + "\n")

        for r in results_sorted:
            f.write(f"\nğŸ“– {r['filename']}\n")
            f.write(f"   éš¾åº¦: {r['stars']}  ({r['difficulty_score']:.1f}/100)\n")
            f.write(f"   å­—ç§æ•°: {r['char_type_count']} ä¸ªï¼ˆå‰1500å†…: {r['char_type_count'] - r['extra_char_types']}ï¼Œå‰1500å¤–: {r['extra_char_types']}ï¼‰\n")
            f.write(f"   ç”Ÿåƒ»å­—: {r['rare_type_count']} ä¸ª ({r['rare_type_ratio']*100:.1f}%)\n")
            f.write(f"   è¦†ç›–ç‡: å‰500å­—={r['coverage_500']:.1f}% | "
                   f"å‰1000å­—={r['coverage_1000']:.1f}% | "
                   f"å‰1500å­—={r['coverage_1500']:.1f}%\n")
            f.write(f"   ç´¯ç§¯è¦†ç›–: 95%éœ€{r['chars_95']}å­— | 99%éœ€{r['chars_99']}å­—\n")
            if r['avg_order_95'] and r['avg_order_99']:
                f.write(f"   å¹³å‡å­—åº: 95%={r['avg_order_95']:.0f} | 99%={r['avg_order_99']:.0f}\n")
            f.write("\n")

        f.write("=" * 80 + "\n\n")

        # ç»Ÿè®¡åˆ†æ
        f.write("ã€ç»Ÿè®¡åˆ†æã€‘\n")
        f.write("-" * 80 + "\n")

        scores = [r['difficulty_score'] for r in results]
        f.write(f"å¹³å‡éš¾åº¦: {sum(scores)/len(scores):.1f}åˆ†\n")
        f.write(f"æœ€ç®€å•: {results_sorted[0]['filename']} ({results_sorted[0]['difficulty_score']:.1f}åˆ†)\n")
        f.write(f"æœ€å›°éš¾: {results_sorted[-1]['filename']} ({results_sorted[-1]['difficulty_score']:.1f}åˆ†)\n")
        f.write(f"éš¾åº¦è·¨åº¦: {results_sorted[-1]['difficulty_score'] - results_sorted[0]['difficulty_score']:.1f}åˆ†\n")

        f.write("\n" + "=" * 80 + "\n")
        f.write("ğŸ’¡ è¯´æ˜ï¼šéš¾åº¦è¯„åˆ†ç»¼åˆè€ƒè™‘å­—ç§æ•°ã€è¦†ç›–ç‡ã€å­—æ•°éœ€æ±‚ã€å­—åºç­‰å¤šä¸ªç»´åº¦\n")
        f.write("=" * 80 + "\n")

    print(f"\næ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
    print(f"å…±ç»Ÿè®¡ {len(results)} æœ¬ä¹¦ç±")


if __name__ == '__main__':
    try:
        main()
    except Exception as e:
        print("\n" + "=" * 70)
        print("ç¨‹åºå‡ºç°é”™è¯¯ï¼š")
        print("=" * 70)
        import traceback
        traceback.print_exc()
        print("\n" + "=" * 70)
        input("\næŒ‰å›è½¦é”®é€€å‡º...")
