#!/usr/bin/env python
# -*- coding: utf-8 -*-
# author: è™ç æ–°æ‰‹2ç¾¤-ä¹Ÿæ— é£é›¨ä¹Ÿæ— æ™´
"""
å­—é¢‘ç»Ÿè®¡è„šæœ¬
åŠŸèƒ½ï¼šç»Ÿè®¡txtæ–‡ä»¶ä¸­æ¯ä¸ªå­—çš„å‡ºç°æ¬¡æ•°ï¼Œå¹¶æŒ‰ç…§dictå­—åºæ’åº
"""

import os
import sys
import io
import unicodedata
from collections import Counter

# å°è¯•å¯¼å…¥æ•°æ®åº“ä¸Šä¼ æ¨¡å—ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
try:
    from db_uploader import handle_database_upload
    DB_UPLOAD_AVAILABLE = True
except ImportError:
    DB_UPLOAD_AVAILABLE = False

# ä¿®å¤Windowsæ§åˆ¶å°UTF-8æ˜¾ç¤ºé—®é¢˜
if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    except:
        pass


# ============================================================================
# ã€éš¾åº¦è¯„åˆ†é…ç½®å‚æ•°ã€‘ - å¯ä»¥åœ¨è¿™é‡Œè°ƒæ•´æ‰€æœ‰è¯„åˆ†å‚æ•°
# ============================================================================

# 1. è¦†ç›–ç‡è¯„åˆ†æƒé‡
WEIGHT_COVERAGE_500 = 10      # å‰500å­—è¦†ç›–ç‡æƒé‡
WEIGHT_COVERAGE_1000 = 10     # å‰1000å­—è¦†ç›–ç‡æƒé‡
WEIGHT_COVERAGE_1500 = 20     # å‰1500å­—è¦†ç›–ç‡æƒé‡

# 2. å­—æ•°éœ€æ±‚è¯„åˆ†æƒé‡
WEIGHT_CHARS_95 = 0          # 95%è¦†ç›–æ‰€éœ€å­—æ•°æƒé‡
WEIGHT_CHARS_99 = 0          # 99%è¦†ç›–æ‰€éœ€å­—æ•°æƒé‡

# 3. å­—åºè¯„åˆ†æƒé‡
WEIGHT_ORDER_95 = 50          # 95%å¹³å‡å­—åºæƒé‡
WEIGHT_ORDER_99 = 30          # 99%å¹³å‡å­—åºæƒé‡

# 4. å­—ç§æ•°è¯„åˆ†æƒé‡
WEIGHT_CHAR_TYPES = 10         # å­—ç§æ•°æƒé‡

# ===========================åŒºé—´=================================================
# 5. å­—æ•°éœ€æ±‚è¯„åˆ†åŒºé—´
CHARS_95_MIN = 300            # 95%è¦†ç›–å­—æ•°ä¸‹é™ï¼ˆâ‰¤æ­¤å€¼å¾—0åˆ†ï¼‰
CHARS_95_MAX = 2500           # 95%è¦†ç›–å­—æ•°ä¸Šé™ï¼ˆâ‰¥æ­¤å€¼å¾—æ»¡åˆ†ï¼‰
CHARS_99_MIN = 400           # 99%è¦†ç›–å­—æ•°ä¸‹é™
CHARS_99_MAX = 4000           # 99%è¦†ç›–å­—æ•°ä¸Šé™

# 6. å­—åºè¯„åˆ†åŒºé—´
ORDER_95_MIN = 400            # 95%å¹³å‡å­—åºä¸‹é™ï¼ˆâ‰¤æ­¤å€¼å¾—0åˆ†ï¼Œè¡¨ç¤ºå¾ˆå¸¸ç”¨ï¼‰
ORDER_95_MAX = 2000           # 95%å¹³å‡å­—åºä¸Šé™ï¼ˆâ‰¥æ­¤å€¼å¾—æ»¡åˆ†ï¼Œè¡¨ç¤ºå¾ˆç”Ÿåƒ»ï¼‰
ORDER_99_MIN = 500            # 99%å¹³å‡å­—åºä¸‹é™
ORDER_99_MAX = 3000           # 99%å¹³å‡å­—åºä¸Šé™

# 7. å­—ç§æ•°è¯„åˆ†åŒºé—´
CHAR_TYPES_BASELINE = 1500    # å­—ç§æ•°åŸºå‡†ï¼ˆå¸¸ç”¨å­—æ•°é‡ï¼Œè¶…å‡ºæ­¤åŸºå‡†çš„æ‰ç®—éš¾åº¦ï¼‰
                              # æ­¤å‚æ•°åŒæ—¶ç”¨äºï¼š
                              # 1. å­—ç§æ•°è¯„åˆ†åŸºå‡†
                              # 2. 95%/99%è¦†ç›–å­—æ•°çš„å‰Nå­—åˆ¤æ–­ï¼ˆä½¿ç”¨å‰1500.txtï¼‰
CHAR_TYPES_MIN = 0            # è¶…å‡ºåŸºå‡†çš„å­—ç§æ•°ä¸‹é™ï¼ˆâ‰¤æ­¤å€¼å¾—0åˆ†ï¼‰
CHAR_TYPES_MAX = 4500         # è¶…å‡ºåŸºå‡†çš„å­—ç§æ•°ä¸Šé™ï¼ˆâ‰¥æ­¤å€¼å¾—æ»¡åˆ†ï¼‰

# 8. æ˜Ÿçº§åˆ’åˆ†åŒºé—´
STAR_THRESHOLD_1 = 20         # <20åˆ†ä¸ºâ­
STAR_THRESHOLD_2 = 40         # <40åˆ†ä¸ºâ­â­
STAR_THRESHOLD_3 = 60         # <60åˆ†ä¸ºâ­â­â­
STAR_THRESHOLD_4 = 80         # <80åˆ†ä¸ºâ­â­â­â­ï¼Œâ‰¥80ä¸ºâ­â­â­â­â­

# 9. è¦†ç›–ç‡è¯„åˆ†æ–¹å¼
# True=ç›´æ¥çº¿æ€§æ˜ å°„(0-100%), False=ä½¿ç”¨åŒºé—´æ˜ å°„
COVERAGE_LINEAR_MODE = True

# å¦‚æœä½¿ç”¨åŒºé—´æ˜ å°„æ¨¡å¼ï¼Œè®¾ç½®ä»¥ä¸‹å‚æ•°ï¼ˆå½“COVERAGE_LINEAR_MODE=Falseæ—¶ç”Ÿæ•ˆï¼‰
COVERAGE_500_MIN = 65         # å‰500å­—è¦†ç›–ç‡ä¸‹é™
COVERAGE_500_MAX = 92         # å‰500å­—è¦†ç›–ç‡ä¸Šé™
COVERAGE_1000_MIN = 80        # å‰1000å­—è¦†ç›–ç‡ä¸‹é™
COVERAGE_1000_MAX = 98        # å‰1000å­—è¦†ç›–ç‡ä¸Šé™
COVERAGE_1500_MIN = 88        # å‰1500å­—è¦†ç›–ç‡ä¸‹é™
COVERAGE_1500_MAX = 99.5      # å‰1500å­—è¦†ç›–ç‡ä¸Šé™

# 10. éçº¿æ€§åŠ é€Ÿç³»æ•°ï¼ˆå¹‚å‡½æ•°æŒ‡æ•°ï¼‰
# è¯´æ˜ï¼š
#   - åŠ é€Ÿç³»æ•° = 1.0 æ—¶ä¸ºçº¿æ€§
#   - åŠ é€Ÿç³»æ•° > 1.0 æ—¶ä¸ºå‡é€Ÿå¢é•¿
#   - åŠ é€Ÿç³»æ•° < 1.0 æ—¶ä¸ºåŠ é€Ÿå¢é•¿ï¼ˆæ¨è1.5-3.0ï¼‰ï¼Œæ•°å€¼è¶Šå¤§å¢é•¿è¶Šå¿«
#   - è¦†ç›–ç‡ï¼šä½è¦†ç›–ç‡çš„ä¹¦éš¾åº¦åˆ†æ•°ä¼šåŠ é€Ÿå¢é•¿
#   - å­—åºï¼šé«˜å­—åºï¼ˆç”Ÿåƒ»å­—ï¼‰çš„ä¹¦éš¾åº¦åˆ†æ•°ä¼šåŠ é€Ÿå¢é•¿
COVERAGE_ACCELERATION = 0.8   # è¦†ç›–ç‡åŠ é€Ÿç³»æ•°ï¼ˆæ¨è1.5-3.0ï¼‰
ORDER_ACCELERATION = 0.7      # å­—åºåŠ é€Ÿç³»æ•°ï¼ˆæ¨è1.5-3.0ï¼‰

# ============================================================================
# ä»¥ä¸‹æ˜¯ç¨‹åºä»£ç ï¼Œä¸€èˆ¬ä¸éœ€è¦ä¿®æ”¹
# ============================================================================

# è¾“å‡ºæ–‡ä»¶å¤¹åç§°
OUTPUT_FOLDER = "å­—é¢‘ç»Ÿè®¡ç»“æœ"


def display_width(text):
    """
    è®¡ç®—å­—ç¬¦ä¸²çš„æ˜¾ç¤ºå®½åº¦ï¼ˆä½¿ç”¨East Asian Widthæ ‡å‡†ï¼‰
    - å…¨è§’/å®½å­—ç¬¦ï¼šå®½åº¦ä¸º2
    - åŠè§’/çª„å­—ç¬¦ï¼šå®½åº¦ä¸º1
    """
    width = 0
    for char in text:
        # è·å–å­—ç¬¦çš„East Asian Widthå±æ€§
        ea_width = unicodedata.east_asian_width(char)

        # F=Fullwidth, W=Wide: å®½åº¦ä¸º2
        if ea_width in ('F', 'W'):
            width += 2
        # A=Ambiguous: åœ¨CJKç¯å¢ƒä¸­é€šå¸¸ä¸º2ï¼Œä½†è¿™é‡Œä¿å®ˆæŒ‰1ç®—
        # H=Halfwidth, Na=Narrow, N=Neutral: å®½åº¦ä¸º1
        else:
            width += 1

    return width


class TableFormatter:
    """
    è¡¨æ ¼æ ¼å¼åŒ–å™¨ - ä½¿ç”¨å›ºå®šåˆ—å®½ç¡®ä¿å®Œç¾å¯¹é½
    """
    def __init__(self, headers, col_widths):
        """
        Args:
            headers: è¡¨å¤´åˆ—è¡¨ï¼Œå¦‚ ['åºå·', 'ä¹¦å', 'éš¾åº¦', 'åˆ†æ•°']
            col_widths: å›ºå®šåˆ—å®½åˆ—è¡¨ï¼Œå¦‚ [6, 50, 20, 10]
        """
        self.headers = headers
        self.rows = []
        self.col_widths = col_widths

    def add_row(self, *cols):
        """æ·»åŠ ä¸€è¡Œæ•°æ®"""
        row = [str(col) for col in cols]
        self.rows.append(row)

    def _format_cell(self, text, target_width):
        """
        æ ¼å¼åŒ–å•å…ƒæ ¼ï¼šæˆªæ–­æˆ–å¡«å……åˆ°å›ºå®šå®½åº¦
        """
        text = str(text)
        current_width = display_width(text)

        # å¦‚æœè¶…å‡ºå®½åº¦ï¼Œæˆªæ–­
        if current_width > target_width:
            truncated = ""
            w = 0
            for ch in text:
                ea = unicodedata.east_asian_width(ch)
                ch_w = 2 if ea in ('F', 'W') else 1
                if w + ch_w > target_width:
                    break
                truncated += ch
                w += ch_w
            return truncated

        # å¦‚æœä¸è¶³å®½åº¦ï¼Œå¡«å……ç©ºæ ¼
        spaces_needed = target_width - current_width
        return text + ' ' * spaces_needed

    def format(self):
        """æ ¼å¼åŒ–è¾“å‡ºæ•´ä¸ªè¡¨æ ¼"""
        lines = []
        total_width = sum(self.col_widths) + len(self.col_widths) - 1  # åŠ ä¸Šåˆ—é—´ç©ºæ ¼

        # è¡¨å¤´
        header_parts = []
        for i, header in enumerate(self.headers):
            header_parts.append(self._format_cell(header, self.col_widths[i]))
        lines.append(' '.join(header_parts))

        # åˆ†éš”çº¿
        lines.append('-' * total_width)

        # æ•°æ®è¡Œ
        for row in self.rows:
            row_parts = []
            for i, col in enumerate(row):
                if i < len(self.col_widths):
                    row_parts.append(self._format_cell(col, self.col_widths[i]))
            lines.append(' '.join(row_parts))

        return '\n'.join(lines)


def format_row(col1, col2, col3, col4, width1=6, width2=52, width3=22, width4=10):
    """
    æ ¼å¼åŒ–ä¸€è¡Œæ•°æ®ï¼Œç¡®ä¿æ¯åˆ—å¯¹é½

    Args:
        col1-col4: å„åˆ—å†…å®¹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        width1-width4: å„åˆ—çš„ç›®æ ‡æ˜¾ç¤ºå®½åº¦

    Returns:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    parts = []

    for col, target_width in [(col1, width1), (col2, width2), (col3, width3), (col4, width4)]:
        col_str = str(col)
        current_width = display_width(col_str)

        # å¦‚æœè¶…å‡ºå®½åº¦ï¼Œæˆªæ–­
        if current_width > target_width:
            truncated = ""
            w = 0
            for ch in col_str:
                ea = unicodedata.east_asian_width(ch)
                ch_w = 2 if ea in ('F', 'W') else 1
                if w + ch_w > target_width:
                    break
                truncated += ch
                w += ch_w
            col_str = truncated
            current_width = w

        # è®¡ç®—éœ€è¦å¡«å……å¤šå°‘ç©ºæ ¼
        spaces_needed = target_width - current_width
        parts.append(col_str + ' ' * spaces_needed)

    return ''.join(parts)


def ensure_output_folder():
    """ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    if not os.path.exists(OUTPUT_FOLDER):
        os.makedirs(OUTPUT_FOLDER)
        print(f"åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹: {OUTPUT_FOLDER}")
    return OUTPUT_FOLDER


def get_resource_path(relative_path):
    """è·å–èµ„æºæ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œæ”¯æŒæ‰“åŒ…åçš„exe"""
    try:
        # PyInstalleråˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹ï¼Œè·¯å¾„å­˜å‚¨åœ¨_MEIPASSä¸­
        base_path = sys._MEIPASS
    except AttributeError:
        # æ²¡æœ‰æ‰“åŒ…ï¼Œä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•
        base_path = os.path.dirname(os.path.abspath(__file__))

    return os.path.join(base_path, relative_path)


def find_txt_files(directory='books'):
    """
    æ‰¾å‡ºæŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰txtæ–‡ä»¶ï¼ˆæ’é™¤è¾…åŠ©æ–‡ä»¶å’Œç»Ÿè®¡ç»“æœï¼‰

    Args:
        directory: è¦æœç´¢çš„ç›®å½•ï¼Œé»˜è®¤ä¸º 'books'

    Returns:
        list: txtæ–‡ä»¶åˆ—è¡¨
    """
    # ç¡®ä¿ books ç›®å½•å­˜åœ¨
    if not os.path.exists(directory):
        try:
            os.makedirs(directory)
            print(f"\nå·²åˆ›å»º {directory} ç›®å½•")
            print(f"è¯·å°†è¦ç»Ÿè®¡çš„txtä¹¦ç±æ–‡ä»¶æ”¾å…¥ {directory} ç›®å½•ä¸­")
            print("=" * 70)
            return []
        except Exception as e:
            print(f"æ— æ³•åˆ›å»º {directory} ç›®å½•: {e}")
            return []

    txt_files = []
    # éœ€è¦æ’é™¤çš„æ–‡ä»¶åï¼ˆè¾…åŠ©æ–‡ä»¶ï¼‰
    excluded_files = {'dict_simple.txt', 'å‰1500.txt', 'dict.txt'}

    try:
        for file in os.listdir(directory):
            if file.endswith('.txt'):
                # æ’é™¤è¾…åŠ©æ–‡ä»¶ã€å·²ç”Ÿæˆçš„ç»Ÿè®¡æ–‡ä»¶
                if (file not in excluded_files and
                    '_å­—é¢‘ç»Ÿè®¡_éš¾åº¦' not in file and
                    not file.endswith('_å­—é¢‘ç»Ÿè®¡.txt')):
                    # è¿”å›ç›¸å¯¹äºbooksç›®å½•çš„æ–‡ä»¶è·¯å¾„
                    txt_files.append(os.path.join(directory, file))
        return txt_files
    except Exception as e:
        print(f"è¯»å– {directory} ç›®å½•å¤±è´¥: {e}")
        return []


def load_reference_chars():
    """
    åŠ è½½å‚è€ƒå­—è¡¨ï¼ˆä»å‰1500.txtï¼‰
    è¿”å›æŒ‰é¡ºåºæ’åˆ—çš„1500ä¸ªå­—çš„åˆ—è¡¨
    """
    ref_file = get_resource_path('å‰1500.txt')

    # å°è¯•å¤šç§ç¼–ç 
    encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'gb18030']

    for encoding in encodings:
        try:
            with open(ref_file, 'r', encoding=encoding) as f:
                content = f.read()

            # æå–æ‰€æœ‰ä¸­æ–‡å­—ç¬¦ï¼ˆä¿æŒé¡ºåºï¼‰
            chars = [char for char in content if '\u4e00' <= char <= '\u9fff']
            if len(chars) > 0:
                print(f"  ä½¿ç”¨ç¼–ç : {encoding}")
                return chars
        except (UnicodeDecodeError, UnicodeError, FileNotFoundError):
            continue

    print(f"âš  è­¦å‘Šï¼šæ— æ³•åŠ è½½å‰1500.txtï¼ˆå°è¯•äº†{len(encodings)}ç§ç¼–ç ï¼‰")
    print(f"   å°†ä½¿ç”¨dict_simple.txtçš„å‰1500ä¸ªå­—ä½œä¸ºæ›¿ä»£æ–¹æ¡ˆ")
    return None


def load_dict_order():
    """åŠ è½½dictå­—åº"""
    dict_file = get_resource_path('dict_simple.txt')

    # å°è¯•å¤šç§ç¼–ç 
    encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'gb18030']

    for encoding in encodings:
        try:
            with open(dict_file, 'r', encoding=encoding) as f:
                lines = f.readlines()

            char_order = {}
            for idx, line in enumerate(lines, start=1):
                char = line.strip()
                if char:
                    char_order[char] = idx

            print(f"  dict_simple.txt ä½¿ç”¨ç¼–ç : {encoding}")
            return char_order
        except (UnicodeDecodeError, UnicodeError, FileNotFoundError):
            continue

    print(f"åŠ è½½dictå­—åºå¤±è´¥ï¼ˆå°è¯•äº†{len(encodings)}ç§ç¼–ç ï¼‰")
    print(f"å°è¯•çš„è·¯å¾„: {dict_file}")
    return {}


def detect_encoding(file_path):
    """è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç """
    # å¸¸è§çš„ä¸­æ–‡ç¼–ç åˆ—è¡¨ï¼ŒæŒ‰ä½¿ç”¨é¢‘ç‡æ’åº
    encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030', 'big5', 'utf-16', 'ascii']

    for encoding in encodings:
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                # å°è¯•è¯»å–éƒ¨åˆ†å†…å®¹æ¥éªŒè¯ç¼–ç 
                f.read(1024)
                return encoding
        except (UnicodeDecodeError, UnicodeError):
            continue

    # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œè¿”å›None
    return None


def count_chars(file_path):
    """ç»Ÿè®¡æ–‡ä»¶ä¸­æ¯ä¸ªå­—çš„å‡ºç°æ¬¡æ•°ï¼Œè‡ªåŠ¨æ£€æµ‹ç¼–ç """
    # å…ˆæ£€æµ‹ç¼–ç 
    detected_encoding = detect_encoding(file_path)

    if detected_encoding is None:
        print(f"æ— æ³•è¯†åˆ«æ–‡ä»¶ç¼–ç ï¼Œå°è¯•ä½¿ç”¨utf-8å¼ºåˆ¶è¯»å–")
        detected_encoding = 'utf-8'
    else:
        print(f"æ£€æµ‹åˆ°æ–‡ä»¶ç¼–ç : {detected_encoding.upper()}")

    try:
        with open(file_path, 'r', encoding=detected_encoding, errors='ignore') as f:
            content = f.read()

        # åªç»Ÿè®¡ä¸­æ–‡å­—ç¬¦
        chinese_chars = [char for char in content if '\u4e00' <= char <= '\u9fff']
        return Counter(chinese_chars), detected_encoding
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return Counter(), None


def load_common_chars(reference_chars=None, char_order=None):
    """
    åŠ è½½å¸¸ç”¨å­—è¡¨ï¼ˆå‰3500ä¸ªå­—ï¼‰
    - å‰1500å­—ï¼šä¼˜å…ˆä½¿ç”¨å‰1500.txtï¼ˆå¦‚æœå¯ç”¨ï¼‰
    - 1500-3500å­—ï¼šä½¿ç”¨dict_simple.txtæŒ‰å­—åºè¡¥å……
    """
    common_chars = set()

    if reference_chars and len(reference_chars) > 0:
        # å‰1500å­—ä½¿ç”¨å‰1500.txt
        common_chars = set(reference_chars)

        # è¡¥å……1500-3500å­—ï¼ˆä»dict_simple.txtï¼ŒæŒ‰å­—åºï¼Œæ’é™¤å‰1500ï¼‰
        reference_chars_set = set(reference_chars)
        remaining_needed = 3500 - len(reference_chars)

        if char_order and remaining_needed > 0:
            added_count = 0
            for char, order in sorted(char_order.items(), key=lambda x: x[1]):
                if char not in reference_chars_set:
                    common_chars.add(char)
                    added_count += 1
                    if added_count >= remaining_needed:
                        break
    else:
        # å›é€€æ–¹æ¡ˆï¼šä»dict_simple.txtè¯»å–å‰3500ä¸ªå­—
        dict_file = get_resource_path('dict_simple.txt')
        encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'gb18030']

        for encoding in encodings:
            try:
                with open(dict_file, 'r', encoding=encoding) as f:
                    for i, line in enumerate(f, 1):
                        if i > 3500:
                            break
                        char = line.strip()
                        if char:
                            common_chars.add(char)

                if len(common_chars) > 0:
                    return common_chars
            except (UnicodeDecodeError, UnicodeError, FileNotFoundError):
                continue

        print(f"åŠ è½½å¸¸ç”¨å­—è¡¨å¤±è´¥ï¼ˆå°è¯•äº†{len(encodings)}ç§ç¼–ç ï¼‰")

    return common_chars


def analyze_rare_chars(char_counter, common_chars):
    """
    åˆ†æç”Ÿåƒ»å­—æƒ…å†µ
    è¿”å›å­—å…¸åŒ…å«ï¼š
    - rare_chars: æ‰€æœ‰ç”Ÿåƒ»å­—åˆ—è¡¨ [(å­—, æ¬¡æ•°)]
    - rare_char_count: ç”Ÿåƒ»å­—å‡ºç°æ€»æ¬¡æ•°
    - rare_char_ratio: ç”Ÿåƒ»å­—å æ–‡æœ¬æ¯”ä¾‹
    - rare_type_count: ç”Ÿåƒ»å­—å­—ç§æ•°
    - rare_type_ratio: ç”Ÿåƒ»å­—å­—ç§å æ¯”
    """
    rare_chars = []  # (å­—, æ¬¡æ•°)
    common_char_count = 0
    rare_char_count = 0

    for char, count in char_counter.items():
        if char in common_chars:
            common_char_count += count
        else:
            rare_char_count += count
            rare_chars.append((char, count))

    # æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åº
    rare_chars.sort(key=lambda x: x[1], reverse=True)

    total_chars = common_char_count + rare_char_count
    rare_char_ratio = rare_char_count / total_chars if total_chars > 0 else 0
    rare_type_ratio = len(rare_chars) / len(char_counter) if len(char_counter) > 0 else 0

    return {
        'rare_chars': rare_chars,           # æ‰€æœ‰ç”Ÿåƒ»å­—åˆ—è¡¨
        'rare_char_count': rare_char_count, # ç”Ÿåƒ»å­—å‡ºç°æ€»æ¬¡æ•°
        'rare_char_ratio': rare_char_ratio, # ç”Ÿåƒ»å­—å æ–‡æœ¬æ¯”ä¾‹
        'rare_type_count': len(rare_chars), # ç”Ÿåƒ»å­—å­—ç§æ•°
        'rare_type_ratio': rare_type_ratio  # ç”Ÿåƒ»å­—å­—ç§å æ¯”
    }


def calculate_difficulty_rating(char_counter, total_chars, coverage_stats, cumulative_coverage, avg_order_95, avg_order_99, extra_char_types):
    """
    è®¡ç®—ä¹¦ç±éš¾åº¦ï¼ˆâ­-â­â­â­â­â­ï¼‰
    è¿”å›ï¼š(æ˜Ÿçº§å­—ç¬¦ä¸², åˆ†æ•°0-100, æè¿°)

    æ‰€æœ‰è¯„åˆ†å‚æ•°å¯åœ¨æ–‡ä»¶å¼€å¤´çš„é…ç½®åŒºåŸŸè°ƒæ•´ï¼š
    - æƒé‡åˆ†é…ï¼šè¦†ç›–ç‡46% + å­—æ•°25% + å­—åº20% + å­—ç§9%
    - è¯„åˆ†åŒºé—´ï¼šå­—æ•°ã€å­—åºã€å­—ç§æ•°çš„ä¸Šä¸‹é™
    - æ˜Ÿçº§åˆ’åˆ†ï¼šäº”ä¸ªæ˜Ÿçº§çš„åˆ†æ•°é˜ˆå€¼
    - è¦†ç›–ç‡æ¨¡å¼ï¼šçº¿æ€§æ¨¡å¼(0-100%)æˆ–åŒºé—´æ¨¡å¼
    """

    # æå–å…³é”®æŒ‡æ ‡
    coverage_500 = coverage_stats.get(500, {}).get('coverage', 0)
    coverage_1000 = coverage_stats.get(1000, {}).get('coverage', 0)
    coverage_1500 = coverage_stats.get(1500, {}).get('coverage', 0)

    # ä»cumulative_coverageè·å–95%å’Œ99%æ‰€éœ€å­—æ•°
    chars_for_95 = 0
    chars_for_99 = 0
    for target_pct, char_count, _ in cumulative_coverage:
        if target_pct == 95:
            chars_for_95 = char_count
        if target_pct == 99:
            chars_for_99 = char_count

    # å­—ç§æ•°
    char_type_count = len(char_counter)

    # ä½¿ç”¨é…ç½®å‚æ•°è®¡ç®—éš¾åº¦åˆ†æ•°ï¼ˆ0-100ï¼Œè¶Šé«˜è¶Šéš¾ï¼‰

    # 1-3. è¦†ç›–ç‡è¯„åˆ†ï¼ˆåº”ç”¨éçº¿æ€§åŠ é€Ÿï¼‰
    if COVERAGE_LINEAR_MODE:
        # çº¿æ€§æ¨¡å¼ï¼š0%â†’æ»¡åˆ†ï¼ˆæœ€éš¾ï¼‰ï¼Œ100%â†’0åˆ†ï¼ˆæœ€ç®€å•ï¼‰
        # åº”ç”¨åŠ é€Ÿç³»æ•°ï¼š((100-coverage)/100)^COVERAGE_ACCELERATION
        score_500 = WEIGHT_COVERAGE_500 * (((100 - coverage_500) / 100) ** COVERAGE_ACCELERATION)
        score_1000 = WEIGHT_COVERAGE_1000 * (((100 - coverage_1000) / 100) ** COVERAGE_ACCELERATION)
        score_1500 = WEIGHT_COVERAGE_1500 * (((100 - coverage_1500) / 100) ** COVERAGE_ACCELERATION)
    else:
        # åŒºé—´æ¨¡å¼ï¼šä½¿ç”¨é…ç½®çš„åŒºé—´èŒƒå›´
        if coverage_500 >= COVERAGE_500_MAX:
            score_500 = 0
        elif coverage_500 <= COVERAGE_500_MIN:
            score_500 = WEIGHT_COVERAGE_500
        else:
            ratio = (COVERAGE_500_MAX - coverage_500) / (COVERAGE_500_MAX - COVERAGE_500_MIN)
            score_500 = WEIGHT_COVERAGE_500 * (ratio ** COVERAGE_ACCELERATION)

        if coverage_1000 >= COVERAGE_1000_MAX:
            score_1000 = 0
        elif coverage_1000 <= COVERAGE_1000_MIN:
            score_1000 = WEIGHT_COVERAGE_1000
        else:
            ratio = (COVERAGE_1000_MAX - coverage_1000) / (COVERAGE_1000_MAX - COVERAGE_1000_MIN)
            score_1000 = WEIGHT_COVERAGE_1000 * (ratio ** COVERAGE_ACCELERATION)

        if coverage_1500 >= COVERAGE_1500_MAX:
            score_1500 = 0
        elif coverage_1500 <= COVERAGE_1500_MIN:
            score_1500 = WEIGHT_COVERAGE_1500
        else:
            ratio = (COVERAGE_1500_MAX - coverage_1500) / (COVERAGE_1500_MAX - COVERAGE_1500_MIN)
            score_1500 = WEIGHT_COVERAGE_1500 * (ratio ** COVERAGE_ACCELERATION)

    # 4. 95%è¦†ç›–æ‰€éœ€å­—æ•°è¯„åˆ†
    if chars_for_95 <= CHARS_95_MIN:
        score_95_chars = 0
    elif chars_for_95 >= CHARS_95_MAX:
        score_95_chars = WEIGHT_CHARS_95
    else:
        score_95_chars = WEIGHT_CHARS_95 * (chars_for_95 - CHARS_95_MIN) / (CHARS_95_MAX - CHARS_95_MIN)

    # 5. 99%è¦†ç›–æ‰€éœ€å­—æ•°è¯„åˆ†
    if chars_for_99 <= CHARS_99_MIN:
        score_99_chars = 0
    elif chars_for_99 >= CHARS_99_MAX:
        score_99_chars = WEIGHT_CHARS_99
    else:
        score_99_chars = WEIGHT_CHARS_99 * (chars_for_99 - CHARS_99_MIN) / (CHARS_99_MAX - CHARS_99_MIN)

    # 6. 95%å¹³å‡å­—åºè¯„åˆ†ï¼ˆåº”ç”¨éçº¿æ€§åŠ é€Ÿï¼‰
    if avg_order_95 is None:
        score_95_order = WEIGHT_ORDER_95 / 2  # é»˜è®¤ä¸­ç­‰éš¾åº¦
    elif avg_order_95 <= ORDER_95_MIN:
        score_95_order = 0
    elif avg_order_95 >= ORDER_95_MAX:
        score_95_order = WEIGHT_ORDER_95
    else:
        ratio = (avg_order_95 - ORDER_95_MIN) / (ORDER_95_MAX - ORDER_95_MIN)
        score_95_order = WEIGHT_ORDER_95 * (ratio ** ORDER_ACCELERATION)

    # 7. 99%å¹³å‡å­—åºè¯„åˆ†ï¼ˆåº”ç”¨éçº¿æ€§åŠ é€Ÿï¼‰
    if avg_order_99 is None:
        score_99_order = WEIGHT_ORDER_99 / 2  # é»˜è®¤ä¸­ç­‰éš¾åº¦
    elif avg_order_99 <= ORDER_99_MIN:
        score_99_order = 0
    elif avg_order_99 >= ORDER_99_MAX:
        score_99_order = WEIGHT_ORDER_99
    else:
        ratio = (avg_order_99 - ORDER_99_MIN) / (ORDER_99_MAX - ORDER_99_MIN)
        score_99_order = WEIGHT_ORDER_99 * (ratio ** ORDER_ACCELERATION)

    # 8. å­—ç§æ•°è¯„åˆ†ï¼ˆä½¿ç”¨ä¼ å…¥çš„è¶…å‡ºå‰1500.txtçš„å­—ç§æ•°ï¼‰
    if extra_char_types <= CHAR_TYPES_MIN:
        score_char_types = 0
    elif extra_char_types >= CHAR_TYPES_MAX:
        score_char_types = WEIGHT_CHAR_TYPES
    else:
        score_char_types = WEIGHT_CHAR_TYPES * (extra_char_types - CHAR_TYPES_MIN) / (CHAR_TYPES_MAX - CHAR_TYPES_MIN)

    # ç»¼åˆéš¾åº¦åˆ†æ•°ï¼ˆåŸå§‹åˆ†æ•°ï¼‰
    raw_score = (score_500 + score_1000 + score_1500 +
                 score_95_chars + score_99_chars +
                 score_95_order + score_99_order + score_char_types)

    # è®¡ç®—æ€»æƒé‡
    total_weight = (WEIGHT_COVERAGE_500 + WEIGHT_COVERAGE_1000 + WEIGHT_COVERAGE_1500 +
                   WEIGHT_CHARS_95 + WEIGHT_CHARS_99 +
                   WEIGHT_ORDER_95 + WEIGHT_ORDER_99 +
                   WEIGHT_CHAR_TYPES)

    # å½’ä¸€åŒ–åˆ°0-100ï¼ˆæ— è®ºæƒé‡å¦‚ä½•è®¾ç½®ï¼Œæœ€ç»ˆéƒ½æ˜¯0-100çš„æ ‡å‡†åˆ†æ•°ï¼‰
    if total_weight > 0:
        difficulty_score = (raw_score / total_weight) * 100
    else:
        difficulty_score = 0

    # è½¬æ¢ä¸ºæ˜Ÿçº§ï¼ˆ10æ˜Ÿåˆ¶ï¼šæ¯10åˆ†ä¸º1æ˜Ÿï¼‰
    # 0-9.99åˆ†=1æ˜Ÿ, 10-19.99åˆ†=2æ˜Ÿ, ..., 90-100åˆ†=10æ˜Ÿ
    star_count = max(1, min(10, int(difficulty_score / 10) + 1))
    if difficulty_score >= 100:
        star_count = 10
    stars = "â­" * star_count

    # è¿”å›è¯¦ç»†ä¿¡æ¯
    score_details = {
        'coverage_500': (score_500, WEIGHT_COVERAGE_500, coverage_500),
        'coverage_1000': (score_1000, WEIGHT_COVERAGE_1000, coverage_1000),
        'coverage_1500': (score_1500, WEIGHT_COVERAGE_1500, coverage_1500),
        'chars_95': (score_95_chars, WEIGHT_CHARS_95, chars_for_95),
        'chars_99': (score_99_chars, WEIGHT_CHARS_99, chars_for_99),
        'order_95': (score_95_order, WEIGHT_ORDER_95, avg_order_95),
        'order_99': (score_99_order, WEIGHT_ORDER_99, avg_order_99),
        'char_types': (score_char_types, WEIGHT_CHAR_TYPES, extra_char_types),
        'raw_score': raw_score,
        'total_weight': total_weight
    }

    return stars, difficulty_score, score_details


def calculate_avg_char_order(chars_list, char_order):
    """
    è®¡ç®—ä¸€ç»„å­—åœ¨å­—å…¸ä¸­çš„å¹³å‡åºå·
    ç”¨äºè¯„ä¼°è¿™äº›å­—æ˜¯å¦æ˜¯å¸¸ç”¨å­—ï¼ˆåºå·é å‰=æ›´å¸¸ç”¨ï¼‰

    å‚æ•°ï¼š
    - chars_list: å­—ç¬¦åˆ—è¡¨ [(char, count), ...]
    - char_order: å­—å…¸åºå·æ˜ å°„ {char: order}

    è¿”å›ï¼šå¹³å‡åºå·ï¼ˆä¸åœ¨å­—å…¸ä¸­çš„å­—ä¸è®¡å…¥ï¼‰
    """
    orders = []
    for char, _ in chars_list:
        if char in char_order:
            orders.append(char_order[char])

    if orders:
        return sum(orders) / len(orders)
    else:
        return None


def print_main_menu():
    """æ‰“å°ä¸»èœå•"""
    print("\n" + "=" * 70)
    print("ã€å­—é¢‘ç»Ÿè®¡ä¸é€‰ä¹¦ç³»ç»Ÿã€‘")
    print("=" * 70)
    print("\nè¯·é€‰æ‹©åŠŸèƒ½ï¼š")
    print("  1. å¤æ‚åº¦è®¡ç®— - ç»Ÿè®¡txtä¹¦ç±çš„å­—é¢‘å’Œéš¾åº¦")
    print("  2. æŸ¥çœ‹æ’è¡Œæ¦œ - æŸ¥çœ‹æ•°æ®åº“ä¸­æ‰€æœ‰ä¹¦ç±çš„éš¾åº¦æ’è¡Œ")
    print("  3. æŒ‰åˆ†æ•°ç­›é€‰ - æ ¹æ®éš¾åº¦åˆ†æ•°ç­›é€‰åˆé€‚çš„ä¹¦ç±")
    print("  0. é€€å‡ºç¨‹åº")
    print("=" * 70)


def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    if not DB_UPLOAD_AVAILABLE:
        print("æ•°æ®åº“åŠŸèƒ½ä¸å¯ç”¨ï¼ˆæœªå®‰è£…pymysqlæˆ–db_uploaderæ¨¡å—ï¼‰")
        return None

    try:
        from db_uploader import load_db_config, check_db_connection, is_db_config_valid
        db_config = load_db_config()
        if not db_config:
            print("æ•°æ®åº“é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æˆ–è¯»å–å¤±è´¥")
            return None

        if not is_db_config_valid(db_config):
            print("æ•°æ®åº“é…ç½®æœªå¡«å†™æˆ–ä»ä¸ºæ¨¡æ¿å ä½ç¬¦")
            return None

        success, db_conn = check_db_connection(db_config)
        if not success:
            print("æ•°æ®åº“è¿æ¥å¤±è´¥")
            return None

        return db_conn
    except Exception as e:
        print(f"æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
        return None


def difficulty_score_to_star_display(score):
    """å°†éš¾åº¦åˆ†æ•°è½¬æ¢ä¸ºæ˜Ÿçº§æ˜¾ç¤ºï¼ˆ10æ˜Ÿåˆ¶ï¼‰"""
    star_count = max(1, min(10, int(score / 10) + 1))
    if score >= 100:
        star_count = 10
    return "â­" * star_count


def feature_difficulty_ranking():
    """åŠŸèƒ½2: æŸ¥çœ‹éš¾åº¦æ’è¡Œæ¦œï¼ˆä½¿ç”¨æ¸¸æ ‡åˆ†é¡µï¼‰"""
    print("\n" + "=" * 70)
    print("ã€éš¾åº¦æ’è¡Œæ¦œã€‘")
    print("=" * 70)

    # è·å–æ•°æ®åº“è¿æ¥
    conn = get_db_connection()
    if not conn:
        input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
        return

    try:
        # é€‰æ‹©æ’åºæ–¹å¼
        print("\nè¯·é€‰æ‹©æ’åºæ–¹å¼ï¼š")
        print("  1. æ­£åºï¼ˆä»ç®€å•åˆ°å›°éš¾ï¼‰")
        print("  2. å€’åºï¼ˆä»å›°éš¾åˆ°ç®€å•ï¼‰")

        while True:
            order_choice = input("è¯·é€‰æ‹© (1-2): ").strip()
            if order_choice in ['1', '2']:
                break
            print("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥1æˆ–2")

        is_ascending = (order_choice == '1')

        # åˆ†é¡µå‚æ•°
        page_size = 20
        current_page = 0
        page_cache = []  # ç¼“å­˜æ‰€æœ‰é¡µé¢æ•°æ®ï¼Œæ”¯æŒåŒå‘ç¿»é¡µ

        def load_page(page_num):
            """åŠ è½½æŒ‡å®šé¡µç çš„æ•°æ®"""
            # å¦‚æœå·²ç»ç¼“å­˜ï¼Œç›´æ¥è¿”å›
            if page_num < len(page_cache):
                return page_cache[page_num]

            # éœ€è¦ä»æ•°æ®åº“åŠ è½½æ–°é¡µ
            cursor = conn.cursor()

            if page_num == 0:
                # ç¬¬ä¸€é¡µ
                if is_ascending:
                    sql = """
                        SELECT id, book_name, author, difficulty_score, star_level,
                               char_types, rare_char_types, coverage_1500
                        FROM book_difficulty
                        ORDER BY difficulty_score ASC, id ASC
                        LIMIT %s
                    """
                else:
                    sql = """
                        SELECT id, book_name, author, difficulty_score, star_level,
                               char_types, rare_char_types, coverage_1500
                        FROM book_difficulty
                        ORDER BY difficulty_score DESC, id DESC
                        LIMIT %s
                    """
                cursor.execute(sql, (page_size,))
            else:
                # åç»­é¡µï¼šä½¿ç”¨ä¸Šä¸€é¡µæœ€åä¸€æ¡è®°å½•çš„æ¸¸æ ‡
                prev_page = page_cache[page_num - 1]
                if not prev_page:
                    return None
                last_row = prev_page[-1]
                last_id = last_row[0]
                last_score = last_row[3]

                if is_ascending:
                    sql = """
                        SELECT id, book_name, author, difficulty_score, star_level,
                               char_types, rare_char_types, coverage_1500
                        FROM book_difficulty
                        WHERE difficulty_score > %s OR (difficulty_score = %s AND id > %s)
                        ORDER BY difficulty_score ASC, id ASC
                        LIMIT %s
                    """
                else:
                    sql = """
                        SELECT id, book_name, author, difficulty_score, star_level,
                               char_types, rare_char_types, coverage_1500
                        FROM book_difficulty
                        WHERE difficulty_score < %s OR (difficulty_score = %s AND id < %s)
                        ORDER BY difficulty_score DESC, id DESC
                        LIMIT %s
                    """
                cursor.execute(sql, (last_score, last_score, last_id, page_size))

            results = cursor.fetchall()
            cursor.close()

            # ç¼“å­˜ç»“æœ
            page_cache.append(results if results else None)
            return results

        while True:
            # åŠ è½½å½“å‰é¡µæ•°æ®
            results = load_page(current_page)

            if not results:
                if current_page == 0:
                    print("\næš‚æ— æ•°æ®ï¼")
                    break
                else:
                    print("\nå·²ç»æ˜¯æœ€åä¸€é¡µäº†ï¼")
                    current_page -= 1  # å›é€€åˆ°ä¸Šä¸€é¡µ
                    continue

            # æ˜¾ç¤ºç»“æœï¼ˆéš¾åº¦æ’è¡Œæ¦œï¼‰- ä½¿ç”¨è¡¨æ ¼å®¹å™¨ç¡®ä¿å®Œç¾å¯¹é½
            print("\n" + "=" * 70)
            print(f"ç¬¬ {current_page + 1} é¡µï¼ˆå…± {len(results)} æ¡ï¼‰")
            print("=" * 70)

            # åˆ›å»ºè¡¨æ ¼å®¹å™¨ï¼ˆå›ºå®šåˆ—å®½ï¼šåºå·6 + ä¹¦å50 + éš¾åº¦20 + åˆ†æ•°10ï¼‰
            table = TableFormatter(['åºå·', 'ä¹¦å', 'éš¾åº¦æ˜Ÿçº§', 'éš¾åº¦åˆ†å€¼'], [6, 50, 20, 10])

            for idx, row in enumerate(results, start=1):
                book_id, book_name, author, score, stars, char_types, rare_types, coverage = row

                # è½¬æ¢æ˜Ÿçº§æ˜¾ç¤ºï¼ˆå¦‚æœæ•°æ®åº“å­˜çš„æ˜¯æ—§æ ¼å¼ï¼Œé‡æ–°è®¡ç®—ï¼‰
                if len(stars) <= 5:  # æ—§çš„5æ˜Ÿåˆ¶
                    stars = difficulty_score_to_star_display(score)

                # æ·»åŠ åˆ°è¡¨æ ¼å®¹å™¨
                table.add_row(str(idx), book_name, stars, f"{score:.1f}")

            # æ ¼å¼åŒ–å¹¶è¾“å‡ºè¡¨æ ¼
            print(table.format())

            # ç¿»é¡µæç¤º
            total_width = sum(table.col_widths) + len(table.col_widths) - 1
            print("-" * total_width)

            # æ„å»ºæç¤ºä¿¡æ¯
            tips = []
            if current_page > 0:
                tips.append("- ä¸Šä¸€é¡µ")

            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µï¼ˆå°è¯•é¢„åŠ è½½ï¼‰
            if current_page + 1 < len(page_cache):
                # å·²ç¼“å­˜ä¸‹ä¸€é¡µ
                if page_cache[current_page + 1]:
                    tips.append("= ä¸‹ä¸€é¡µ")
            elif len(results) == page_size:
                # å½“å‰é¡µæ»¡ï¼Œå¯èƒ½æœ‰ä¸‹ä¸€é¡µ
                tips.append("= ä¸‹ä¸€é¡µ")

            if tips:
                print("  " + " | ".join(tips) + " | å›è½¦è¿”å›")
                choice = input("è¯·é€‰æ‹©: ").strip()
            else:
                choice = input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")

            if choice == '-' and current_page > 0:
                current_page -= 1
            elif choice == '=':
                current_page += 1
            else:
                break

    except Exception as e:
        print(f"\næŸ¥è¯¢å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        conn.close()


def feature_select_by_star():
    """åŠŸèƒ½3: æŒ‰åˆ†æ•°ç­›é€‰ä¹¦ç±ï¼ˆä½¿ç”¨æ¸¸æ ‡åˆ†é¡µï¼‰"""
    print("\n" + "=" * 70)
    print("ã€æŒ‰éš¾åº¦ç­›é€‰ä¹¦ç±ã€‘")
    print("=" * 70)

    # è·å–æ•°æ®åº“è¿æ¥
    conn = get_db_connection()
    if not conn:
        input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
        return

    try:
        # ç”¨æˆ·è¾“å…¥åˆ†æ•°
        print("\nè¯·è¾“å…¥éš¾åº¦åˆ†æ•°ï¼ˆ0-100åˆ†ï¼‰ï¼š")
        print("  æç¤ºï¼šåˆ†æ•°è¶Šé«˜è¡¨ç¤ºä¹¦ç±è¶Šéš¾")

        while True:
            try:
                score_input = input("\nè¯·è¾“å…¥åˆ†æ•° (0-100): ").strip()
                threshold_score = float(score_input)
                if 0 <= threshold_score <= 100:
                    break
                print("è¾“å…¥è¶…å‡ºèŒƒå›´ï¼Œè¯·è¾“å…¥0-100ä¹‹é—´çš„æ•°å­—")
            except ValueError:
                print("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥æ•°å­—")

        # ç”¨æˆ·é€‰æ‹©å¤§äºè¿˜æ˜¯å°äº
        print("\nè¯·é€‰æ‹©ç­›é€‰æ¡ä»¶ï¼š")
        print("  1. å¤§äº {:.1f} åˆ†ï¼ˆæŸ¥çœ‹æ›´éš¾çš„ä¹¦ï¼‰".format(threshold_score))
        print("  2. å°äº {:.1f} åˆ†ï¼ˆæŸ¥çœ‹æ›´ç®€å•çš„ä¹¦ï¼‰".format(threshold_score))

        while True:
            condition_choice = input("\nè¯·é€‰æ‹© (1-2): ").strip()
            if condition_choice in ['1', '2']:
                break
            print("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥1æˆ–2")

        is_greater_than = (condition_choice == '1')

        if is_greater_than:
            print(f"\næ­£åœ¨æŸ¥è¯¢éš¾åº¦ > {threshold_score:.1f} åˆ†çš„ä¹¦ç±ï¼ˆæ­£åºæ’åˆ—ï¼Œä»ç®€å•åˆ°éš¾ï¼‰...")
        else:
            print(f"\næ­£åœ¨æŸ¥è¯¢éš¾åº¦ < {threshold_score:.1f} åˆ†çš„ä¹¦ç±ï¼ˆå€’åºæ’åˆ—ï¼Œä»éš¾åˆ°ç®€å•ï¼‰...")

        # åˆ†é¡µå‚æ•°
        page_size = 20
        current_page = 0
        page_cache = []  # ç¼“å­˜æ‰€æœ‰é¡µé¢æ•°æ®ï¼Œæ”¯æŒåŒå‘ç¿»é¡µ

        def load_page(page_num):
            """åŠ è½½æŒ‡å®šé¡µç çš„æ•°æ®"""
            # å¦‚æœå·²ç»ç¼“å­˜ï¼Œç›´æ¥è¿”å›
            if page_num < len(page_cache):
                return page_cache[page_num]

            # éœ€è¦ä»æ•°æ®åº“åŠ è½½æ–°é¡µ
            cursor = conn.cursor()

            if page_num == 0:
                # ç¬¬ä¸€é¡µ
                if is_greater_than:
                    sql = """
                        SELECT id, book_name, author, difficulty_score, star_level,
                               char_types, rare_char_types, coverage_1500
                        FROM book_difficulty
                        WHERE difficulty_score > %s
                        ORDER BY difficulty_score ASC, id ASC
                        LIMIT %s
                    """
                else:
                    sql = """
                        SELECT id, book_name, author, difficulty_score, star_level,
                               char_types, rare_char_types, coverage_1500
                        FROM book_difficulty
                        WHERE difficulty_score < %s
                        ORDER BY difficulty_score DESC, id DESC
                        LIMIT %s
                    """
                cursor.execute(sql, (threshold_score, page_size))
            else:
                # åç»­é¡µï¼šä½¿ç”¨ä¸Šä¸€é¡µæœ€åä¸€æ¡è®°å½•çš„æ¸¸æ ‡
                prev_page = page_cache[page_num - 1]
                if not prev_page:
                    return None
                last_row = prev_page[-1]
                last_id = last_row[0]
                last_score = last_row[3]

                if is_greater_than:
                    sql = """
                        SELECT id, book_name, author, difficulty_score, star_level,
                               char_types, rare_char_types, coverage_1500
                        FROM book_difficulty
                        WHERE difficulty_score > %s
                              AND (difficulty_score > %s OR (difficulty_score = %s AND id > %s))
                        ORDER BY difficulty_score ASC, id ASC
                        LIMIT %s
                    """
                    cursor.execute(sql, (threshold_score, last_score, last_score, last_id, page_size))
                else:
                    sql = """
                        SELECT id, book_name, author, difficulty_score, star_level,
                               char_types, rare_char_types, coverage_1500
                        FROM book_difficulty
                        WHERE difficulty_score < %s
                              AND (difficulty_score < %s OR (difficulty_score = %s AND id < %s))
                        ORDER BY difficulty_score DESC, id DESC
                        LIMIT %s
                    """
                    cursor.execute(sql, (threshold_score, last_score, last_score, last_id, page_size))

            results = cursor.fetchall()
            cursor.close()

            # ç¼“å­˜ç»“æœ
            page_cache.append(results if results else None)
            return results

        while True:
            # åŠ è½½å½“å‰é¡µæ•°æ®
            results = load_page(current_page)

            if not results:
                if current_page == 0:
                    if is_greater_than:
                        print(f"\næš‚æ— éš¾åº¦ > {threshold_score:.1f} åˆ†çš„ä¹¦ç±")
                    else:
                        print(f"\næš‚æ— éš¾åº¦ < {threshold_score:.1f} åˆ†çš„ä¹¦ç±")
                    break
                else:
                    print("\nå·²ç»æ˜¯æœ€åä¸€é¡µäº†ï¼")
                    current_page -= 1  # å›é€€åˆ°ä¸Šä¸€é¡µ
                    continue

            # æ˜¾ç¤ºç»“æœï¼ˆæŒ‰åˆ†æ•°ç­›é€‰ï¼‰- ä½¿ç”¨è¡¨æ ¼å®¹å™¨ç¡®ä¿å®Œç¾å¯¹é½
            print("\n" + "=" * 70)
            print(f"ç¬¬ {current_page + 1} é¡µï¼ˆå…± {len(results)} æ¡ï¼‰")
            print("=" * 70)

            # åˆ›å»ºè¡¨æ ¼å®¹å™¨ï¼ˆå›ºå®šåˆ—å®½ï¼šåºå·6 + ä¹¦å50 + éš¾åº¦20 + åˆ†æ•°10ï¼‰
            table = TableFormatter(['åºå·', 'ä¹¦å', 'éš¾åº¦æ˜Ÿçº§', 'éš¾åº¦åˆ†å€¼'], [6, 50, 20, 10])

            for idx, row in enumerate(results, start=1):
                book_id, book_name, author, score, stars, char_types, rare_types, coverage = row

                # è½¬æ¢æ˜Ÿçº§æ˜¾ç¤ºï¼ˆå¦‚æœæ•°æ®åº“å­˜çš„æ˜¯æ—§æ ¼å¼ï¼Œé‡æ–°è®¡ç®—ï¼‰
                if len(stars) <= 5:  # æ—§çš„5æ˜Ÿåˆ¶
                    stars = difficulty_score_to_star_display(score)

                # æ·»åŠ åˆ°è¡¨æ ¼å®¹å™¨
                table.add_row(str(idx), book_name, stars, f"{score:.1f}")

            # æ ¼å¼åŒ–å¹¶è¾“å‡ºè¡¨æ ¼
            print(table.format())

            # ç¿»é¡µæç¤º
            total_width = sum(table.col_widths) + len(table.col_widths) - 1
            print("-" * total_width)

            # æ„å»ºæç¤ºä¿¡æ¯
            tips = []
            if current_page > 0:
                tips.append("- ä¸Šä¸€é¡µ")

            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µï¼ˆå°è¯•é¢„åŠ è½½ï¼‰
            if current_page + 1 < len(page_cache):
                # å·²ç¼“å­˜ä¸‹ä¸€é¡µ
                if page_cache[current_page + 1]:
                    tips.append("= ä¸‹ä¸€é¡µ")
            elif len(results) == page_size:
                # å½“å‰é¡µæ»¡ï¼Œå¯èƒ½æœ‰ä¸‹ä¸€é¡µ
                tips.append("= ä¸‹ä¸€é¡µ")

            if tips:
                print("  " + " | ".join(tips) + " | å›è½¦è¿”å›")
                choice = input("è¯·é€‰æ‹©: ").strip()
            else:
                choice = input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")

            if choice == '-' and current_page > 0:
                current_page -= 1
            elif choice == '=':
                current_page += 1
            else:
                break

    except Exception as e:
        print(f"\næŸ¥è¯¢å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        conn.close()


def feature_book_statistics():
    """åŠŸèƒ½1: ä¹¦ç±å¤æ‚åº¦è®¡ç®—ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰"""
    print("\n" + "=" * 70)
    print("ã€ä¹¦ç±å¤æ‚åº¦è®¡ç®—ã€‘")
    print("=" * 70)

    # 1. æ‰¾å‡ºæ‰€æœ‰txtæ–‡ä»¶
    txt_files = find_txt_files()

    if not txt_files:
        print("\n" + "=" * 70)
        print("âš  booksç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°txtæ–‡ä»¶ï¼")
        print("=" * 70)
        print("\nã€ä½¿ç”¨è¯´æ˜ã€‘\n")
        print("æœ¬å·¥å…·ç”¨äºç»Ÿè®¡txtæ–‡ä»¶ä¸­çš„ä¸­æ–‡å­—ç¬¦é¢‘ç‡ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„ç»Ÿè®¡æŠ¥å‘Šã€‚\n")
        print("ğŸ“‹ ä½¿ç”¨æ­¥éª¤ï¼š")
        print("  1. å°†txtä¹¦ç±æ–‡ä»¶æ”¾å…¥ books ç›®å½•")
        print("  2. åŒå‡»è¿è¡Œæœ¬ç¨‹åº")
        print("  3. æ ¹æ®æç¤ºé€‰æ‹©è¦ç»Ÿè®¡çš„txtæ–‡ä»¶ï¼ˆè¾“å…¥åºå·ï¼‰")
        print("  4. ç­‰å¾…ç»Ÿè®¡å®Œæˆ")
        print("  5. ç»Ÿè®¡ç»“æœä¼šè‡ªåŠ¨ä¿å­˜åˆ° å­—é¢‘ç»Ÿè®¡ç»“æœ ç›®å½•\n")
        print("ğŸ“Š ç»Ÿè®¡å†…å®¹åŒ…æ‹¬ï¼š")
        print("  â€¢ å­—ç§ä¸°å¯Œåº¦ - è¡¡é‡ç”¨å­—å¤šæ ·æ€§")
        print("  â€¢ ç”¨å­—å‡åŒ€åº¦ - è¡¡é‡å„å­—ä½¿ç”¨æ˜¯å¦å¹³å‡")
        print("  â€¢ å­—é¢‘é›†ä¸­åº¦ - è¡¡é‡å¯¹å¸¸ç”¨å­—çš„ä¾èµ–ç¨‹åº¦")
        print("  â€¢ é«˜é¢‘å­—è¦†ç›–ç‡ - å‰Nä¸ªå­—è¦†ç›–å¤šå°‘æ–‡æœ¬")
        print("  â€¢ ç´¯ç§¯è¦†ç›–ç‡ - è¦†ç›–X%æ–‡æœ¬éœ€è¦å¤šå°‘å­—")
        print("  â€¢ è¯¦ç»†å­—é¢‘è¡¨ - æ¯ä¸ªå­—çš„æ¬¡æ•°ã€å æ¯”ã€é¡ºåº\n")
        print("ğŸ”§ æ”¯æŒçš„ç¼–ç æ ¼å¼ï¼š")
        print("  â€¢ UTF-8")
        print("  â€¢ GBK / GB2312 / GB18030ï¼ˆç®€ä½“ä¸­æ–‡ï¼‰")
        print("  â€¢ Big5ï¼ˆç¹ä½“ä¸­æ–‡ï¼‰")
        print("  ç¨‹åºä¼šè‡ªåŠ¨è¯†åˆ«ç¼–ç ï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½®\n")
        print("ğŸ’¡ æç¤ºï¼š")
        print("  â€¢ åªç»Ÿè®¡ä¸­æ–‡å­—ç¬¦ï¼ˆæ±‰å­—ï¼‰ï¼Œæ ‡ç‚¹ç¬¦å·å’Œè‹±æ–‡ä¸è®¡å…¥")
        print("  â€¢ ç»Ÿè®¡å¤§æ–‡ä»¶ï¼ˆ>10MBï¼‰å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
        print("  â€¢ ç”Ÿæˆçš„ç»Ÿè®¡æ–‡ä»¶å¯ç”¨ä»»ä½•æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€æŸ¥çœ‹\n")
        print("=" * 70)
        print("\nè¯·å°†txtæ–‡ä»¶æ”¾åˆ° books ç›®å½•åï¼Œé‡æ–°è¿è¡Œç¨‹åºï¼\n")
        input("æŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
        return

    # 2. æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨ä¾›ç”¨æˆ·é€‰æ‹©
    print("\næ‰¾åˆ°ä»¥ä¸‹txtæ–‡ä»¶ï¼ˆbooksç›®å½•ï¼‰ï¼š")
    for idx, file_path in enumerate(txt_files, start=1):
        file_size = os.path.getsize(file_path) / 1024  # KB
        # åªæ˜¾ç¤ºæ–‡ä»¶åï¼Œä¸æ˜¾ç¤ºè·¯å¾„
        display_name = os.path.basename(file_path)
        print(f"{idx}. {display_name} ({file_size:.2f} KB)")

    # 3. ç”¨æˆ·é€‰æ‹©
    while True:
        try:
            choice = input(f"\nè¯·é€‰æ‹©è¦ç»Ÿè®¡çš„æ–‡ä»¶ (1-{len(txt_files)}ï¼Œè¾“å…¥'all'æ‰«ææ‰€æœ‰ï¼Œè¾“å…¥0è¿”å›): ")
            if choice == '0':
                return

            # å¤„ç†"all"é€‰é¡¹ - æ‰«ææ‰€æœ‰txtæ–‡ä»¶
            if choice.lower() == 'all':
                print("\n" + "=" * 70)
                print("å¼€å§‹æ‰¹é‡æ‰«ææ‰€æœ‰txtæ–‡ä»¶...")
                print("=" * 70)

                # txt_fileså·²ç»è¿‡æ»¤äº†è¾…åŠ©æ–‡ä»¶å’Œç»Ÿè®¡ç»“æœï¼Œç›´æ¥ä½¿ç”¨
                files_to_process = txt_files

                if not files_to_process:
                    print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦ç»Ÿè®¡çš„txtæ–‡ä»¶ï¼")
                    continue

                print(f"æ‰¾åˆ° {len(files_to_process)} ä¸ªæ–‡ä»¶éœ€è¦ç»Ÿè®¡\n")

                # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰
                db_conn = None
                db_config = None
                if DB_UPLOAD_AVAILABLE:
                    try:
                        from db_uploader import load_db_config, check_db_connection, is_db_config_valid
                        db_config = load_db_config()
                        if db_config and is_db_config_valid(db_config):
                            success, db_conn = check_db_connection(db_config)
                            if success:
                                print("âœ“ æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œæ‰¹é‡ä¸Šä¼ æ¨¡å¼å·²å¯ç”¨\n")
                            else:
                                print("âš  æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œå°†è·³è¿‡æ•°æ®åº“ä¸Šä¼ \n")
                        else:
                            print("âš  æ•°æ®åº“é…ç½®æœªå¡«å†™ï¼Œå°†è·³è¿‡æ•°æ®åº“ä¸Šä¼ \n")
                    except Exception as e:
                        print(f"âš  æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†è·³è¿‡æ•°æ®åº“ä¸Šä¼ \n")

                # å­˜å‚¨æ‰€æœ‰ä¹¦ç±çš„ç»Ÿè®¡ç»“æœç”¨äºæ±‡æ€»
                summary_results = []
                upload_success_count = 0
                upload_skip_count = 0

                for idx, file_path in enumerate(files_to_process, start=1):
                    display_name = os.path.basename(file_path)
                    print(f"\n[{idx}/{len(files_to_process)}] æ­£åœ¨å¤„ç†: {display_name}")
                    print("-" * 70)
                    result = process_file(file_path, batch_mode=True, db_conn=db_conn, db_config=db_config)
                    if result:
                        summary_results.append(result)
                        # æ›´æ–°æ•°æ®åº“è¿æ¥ï¼ˆå¯èƒ½åœ¨process_fileä¸­è¢«æ›´æ–°ï¼‰
                        if 'db_conn' in result and result['db_conn'] is not None:
                            db_conn = result['db_conn']
                        # ç»Ÿè®¡ä¸Šä¼ æƒ…å†µ
                        if 'upload_success' in result:
                            if result['upload_success']:
                                upload_success_count += 1
                            else:
                                upload_skip_count += 1

                # å…³é—­æ•°æ®åº“è¿æ¥
                if db_conn:
                    try:
                        db_conn.close()
                        print("\nâœ“ æ•°æ®åº“è¿æ¥å·²å…³é—­")
                    except:
                        pass

                # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
                if summary_results:
                    generate_summary_report(summary_results)

                print("\n" + "=" * 70)
                print("æ‰¹é‡æ‰«æå®Œæˆï¼")
                # å¦‚æœæ•°æ®åº“è¿æ¥æˆåŠŸè¿‡ï¼Œæ˜¾ç¤ºä¸Šä¼ ç»Ÿè®¡
                if DB_UPLOAD_AVAILABLE and db_conn is not None:
                    print(f"æ•°æ®åº“ä¸Šä¼ : æˆåŠŸ {upload_success_count} ä¸ªï¼Œè·³è¿‡ {upload_skip_count} ä¸ª")
                print("=" * 70)
                input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
                return

            choice_idx = int(choice) - 1
            if 0 <= choice_idx < len(txt_files):
                selected_file = txt_files[choice_idx]
                break
            else:
                print("è¾“å…¥çš„æ•°å­—è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°è¾“å…¥ï¼")
        except ValueError:
            print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ•°å­—æˆ–'all'ï¼")

    # æ‰§è¡Œç»Ÿè®¡
    process_file(selected_file)
    input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")


def main():
    print("=" * 50)
    print("å­—é¢‘ç»Ÿè®¡å·¥å…·")
    print("=" * 50)

    # 0. ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹å­˜åœ¨
    ensure_output_folder()

    # ä¸»å¾ªç¯ï¼šæ˜¾ç¤ºåŠŸèƒ½èœå•
    while True:
        print_main_menu()

        choice = input("\nè¯·é€‰æ‹©åŠŸèƒ½ (0-3ï¼Œç›´æ¥å›è½¦é»˜è®¤é€‰1): ").strip()

        # ç©ºè¾“å…¥é»˜è®¤ä¸ºåŠŸèƒ½1
        if choice == '':
            choice = '1'

        if choice == '0':
            print("\næ„Ÿè°¢ä½¿ç”¨ï¼")
            break
        elif choice == '1':
            # ä¹¦ç±å¤æ‚åº¦è®¡ç®—
            feature_book_statistics()
        elif choice == '2':
            # éš¾åº¦æ’è¡Œæ¦œ
            feature_difficulty_ranking()
        elif choice == '3':
            # æŒ‰åˆ†æ•°ç­›é€‰ä¹¦ç±
            feature_select_by_star()
        else:
            print("\næ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥0-3ä¹‹é—´çš„æ•°å­—")


def process_file(selected_file, batch_mode=False, db_conn=None, db_config=None):
    """å¤„ç†å•ä¸ªæ–‡ä»¶çš„ç»Ÿè®¡

    Args:
        selected_file: æ–‡ä»¶å
        batch_mode: æ˜¯å¦æ‰¹é‡æ¨¡å¼ï¼ˆTrueæ—¶è‡ªåŠ¨ä¸Šä¼ ï¼Œä¸è¯¢é—®ç¡®è®¤ï¼‰
        db_conn: å¤ç”¨çš„æ•°æ®åº“è¿æ¥ï¼ˆæ‰¹é‡æ¨¡å¼ç”¨ï¼‰
        db_config: æ•°æ®åº“é…ç½®ï¼ˆæ‰¹é‡æ¨¡å¼ç”¨ï¼‰
    """
    print(f"\næ­£åœ¨ç»Ÿè®¡æ–‡ä»¶: {selected_file}")

    # 4. ç»Ÿè®¡å­—é¢‘
    char_counter, file_encoding = count_chars(selected_file)
    total_chars = sum(char_counter.values())

    if total_chars == 0:
        print("æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—ç¬¦ï¼")
        return

    print(f"å…±ç»Ÿè®¡åˆ° {total_chars} ä¸ªä¸­æ–‡å­—ç¬¦")
    print(f"ä¸é‡å¤å­—ç¬¦æ•°: {len(char_counter)}")

    # 5. åŠ è½½å‚è€ƒå­—è¡¨å’Œå­—åº
    print("\næ­£åœ¨åŠ è½½å‚è€ƒå­—è¡¨ï¼ˆå‰1500.txtï¼‰...")
    reference_chars = load_reference_chars()
    if reference_chars:
        print(f"åŠ è½½äº†å‚è€ƒå­—è¡¨ï¼Œå…± {len(reference_chars)} ä¸ªå­—")
    else:
        print("ä½¿ç”¨dict_simple.txtä½œä¸ºæ›¿ä»£")

    print("æ­£åœ¨åŠ è½½dict.yaml...")
    char_order = load_dict_order()
    print(f"åŠ è½½äº† {len(char_order)} ä¸ªå­—çš„é¡ºåº")

    # 6. æ’åºï¼šæŒ‰ç…§dict.yamlçš„é¡ºåºæ’åº
    # åœ¨dict.yamlä¸­çš„å­—æŒ‰é¡ºåºæ’åˆ—ï¼Œä¸åœ¨çš„å­—æ”¾åœ¨æœ€åæŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åˆ—
    chars_in_dict = []
    chars_not_in_dict = []

    for char, count in char_counter.items():
        if char in char_order:
            chars_in_dict.append((char, count, char_order[char]))
        else:
            chars_not_in_dict.append((char, count))

    # åœ¨å­—å…¸ä¸­çš„å­—æŒ‰å­—åºæ’åº
    chars_in_dict.sort(key=lambda x: x[2])
    # ä¸åœ¨å­—å…¸ä¸­çš„å­—æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åº
    chars_not_in_dict.sort(key=lambda x: x[1], reverse=True)

    # 6.5 è®¡ç®—æ–‡å­—æ•£åˆ—åº¦æŒ‡æ ‡
    # æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åˆ—æ‰€æœ‰å­—ç¬¦ï¼ˆç”¨äºè®¡ç®—ç´¯ç§¯è¦†ç›–ç‡ï¼‰
    all_chars_by_freq = sorted(char_counter.items(), key=lambda x: x[1], reverse=True)

    def calculate_coverage_stats(top_n):
        """
        è®¡ç®—å‚è€ƒå­—è¡¨å‰Nä¸ªå­—çš„è¦†ç›–ç‡
        - å‰1500å­—ï¼šä¼˜å…ˆä½¿ç”¨å‰1500.txt
        - è¶…è¿‡1500çš„éƒ¨åˆ†ï¼šä½¿ç”¨dict_simple.txtæŒ‰å­—åºè¡¥å……
        """
        ref_top_chars = set()

        if reference_chars and len(reference_chars) > 0:
            # å‰1500å­—ä½¿ç”¨å‰1500.txt
            if top_n <= len(reference_chars):
                ref_top_chars = set(reference_chars[:top_n])
            else:
                # è¶…è¿‡1500ï¼šå‰1500ç”¨reference_charsï¼Œå‰©ä½™ç”¨dict_simple.txtè¡¥å……
                ref_top_chars = set(reference_chars)  # å…ˆæ·»åŠ å…¨éƒ¨1500ä¸ª
                reference_chars_set = set(reference_chars)

                # ä»dict_simple.txtè¡¥å……å‰©ä½™çš„å­—ï¼ˆæŒ‰å­—åºï¼Œæ’é™¤å·²åœ¨å‰1500ä¸­çš„å­—ï¼‰
                remaining_needed = top_n - len(reference_chars)
                added_count = 0
                for char, order in sorted(char_order.items(), key=lambda x: x[1]):
                    if char not in reference_chars_set:
                        ref_top_chars.add(char)
                        added_count += 1
                        if added_count >= remaining_needed:
                            break
        else:
            # å›é€€æ–¹æ¡ˆï¼šå…¨éƒ¨ä½¿ç”¨dict_simple.txtçš„å­—åº
            for char, order in char_order.items():
                if order <= top_n:
                    ref_top_chars.add(char)

        # è®¡ç®—è¿™äº›å­—åœ¨æ–‡æœ¬ä¸­çš„å‡ºç°æ¬¡æ•°
        top_count = 0
        for char in ref_top_chars:
            if char in char_counter:
                top_count += char_counter[char]

        coverage = (top_count / total_chars) * 100 if total_chars > 0 else 0
        avg_count = top_count / len(ref_top_chars) if len(ref_top_chars) > 0 else 0

        return {
            'actual_n': len(ref_top_chars),
            'coverage': coverage,
            'avg_count': avg_count,
            'total_count': top_count
        }

    # è®¡ç®—ä¸åŒåŒºé—´çš„ç»Ÿè®¡
    stats_ranges = [10, 50, 100, 500, 1000, 1500, 2000, 3000, 5000]
    coverage_stats = {}
    for n in stats_ranges:
        coverage_stats[n] = calculate_coverage_stats(n)

    # è®¡ç®—ç´¯ç§¯è¦†ç›–ç‡ï¼ˆè¦†ç›–X%çš„æ–‡æœ¬éœ€è¦å¤šå°‘å­—ï¼‰
    cumulative_coverage = []
    cumulative_count = 0
    for idx, (char, count) in enumerate(all_chars_by_freq, start=1):
        cumulative_count += count
        coverage_pct = (cumulative_count / total_chars) * 100
        if coverage_pct >= 50 and not any(c[0] == 50 for c in cumulative_coverage):
            cumulative_coverage.append((50, idx, coverage_pct))
        if coverage_pct >= 80 and not any(c[0] == 80 for c in cumulative_coverage):
            cumulative_coverage.append((80, idx, coverage_pct))
        if coverage_pct >= 90 and not any(c[0] == 90 for c in cumulative_coverage):
            cumulative_coverage.append((90, idx, coverage_pct))
        if coverage_pct >= 95 and not any(c[0] == 95 for c in cumulative_coverage):
            cumulative_coverage.append((95, idx, coverage_pct))
        if coverage_pct >= 99 and not any(c[0] == 99 for c in cumulative_coverage):
            cumulative_coverage.append((99, idx, coverage_pct))

    # 100%è¦†ç›–å°±æ˜¯æ‰€æœ‰å­—ç§æ•°
    cumulative_coverage.append((100, len(char_counter), 100.0))

    # 6.6 å½¢ç ç”¨æˆ·ä¸“å±åˆ†æ
    print("\næ­£åœ¨åŠ è½½å¸¸ç”¨å­—è¡¨...")
    common_chars = load_common_chars(reference_chars, char_order)
    print(f"åŠ è½½äº† {len(common_chars)} ä¸ªå¸¸ç”¨å­—")

    print("æ­£åœ¨åˆ†æç”Ÿåƒ»å­—...")
    rare_analysis = analyze_rare_chars(char_counter, common_chars)

    # è®¡ç®—95%å’Œ99%è¦†ç›–çš„å¹³å‡å­—åº
    print("æ­£åœ¨è®¡ç®—å¹³å‡å­—åº...")
    chars_for_95_pct = 0
    chars_for_99_pct = 0
    for target_pct, char_count, _ in cumulative_coverage:
        if target_pct == 95:
            chars_for_95_pct = char_count
        if target_pct == 99:
            chars_for_99_pct = char_count

    # è·å–è¾¾åˆ°95%å’Œ99%æ‰€éœ€çš„å­—
    chars_for_95_list = all_chars_by_freq[:chars_for_95_pct] if chars_for_95_pct > 0 else []
    chars_for_99_list = all_chars_by_freq[:chars_for_99_pct] if chars_for_99_pct > 0 else []

    # è®¡ç®—å¹³å‡å­—åº
    avg_order_95 = calculate_avg_char_order(chars_for_95_list, char_order)
    avg_order_99 = calculate_avg_char_order(chars_for_99_list, char_order)

    # è®¡ç®—è¶…å‡ºå‰1500.txtçš„å­—ç§æ•°
    print("æ­£åœ¨è®¡ç®—è¶…å‡ºå‰1500çš„å­—ç§æ•°...")
    if reference_chars:
        reference_chars_set = set(reference_chars)
        extra_char_types = sum(1 for char in char_counter.keys() if char not in reference_chars_set)

        # è®¡ç®—95%å’Œ99%è¦†ç›–å­—æ•°ä¸­å‰1500å†…å¤–çš„åˆ†å¸ƒ
        chars_95_in_ref = sum(1 for char, _ in chars_for_95_list if char in reference_chars_set)
        chars_95_out_ref = len(chars_for_95_list) - chars_95_in_ref
        chars_99_in_ref = sum(1 for char, _ in chars_for_99_list if char in reference_chars_set)
        chars_99_out_ref = len(chars_for_99_list) - chars_99_in_ref
    else:
        # å¦‚æœæ²¡æœ‰å‰1500.txtï¼Œä½¿ç”¨CHAR_TYPES_BASELINEä½œä¸ºåŸºå‡†
        extra_char_types = max(0, len(char_counter) - CHAR_TYPES_BASELINE)
        chars_95_in_ref = 0
        chars_95_out_ref = 0
        chars_99_in_ref = 0
        chars_99_out_ref = 0

    print("æ­£åœ¨è®¡ç®—ä¹¦ç±éš¾åº¦...")
    stars, difficulty_score, score_details = calculate_difficulty_rating(
        char_counter, total_chars, coverage_stats, cumulative_coverage, avg_order_95, avg_order_99, extra_char_types
    )

    # 7. è¾“å‡ºç»“æœåˆ°æ–‡ä»¶ï¼ˆåªä½¿ç”¨æ–‡ä»¶åï¼Œä¸åŒ…å«è·¯å¾„ï¼‰
    base_filename = os.path.basename(selected_file)  # å»æ‰è·¯å¾„ï¼Œåªä¿ç•™æ–‡ä»¶å
    output_filename = f"{os.path.splitext(base_filename)[0]}_å­—é¢‘ç»Ÿè®¡_éš¾åº¦{difficulty_score:.1f}.txt"
    output_file = os.path.join(OUTPUT_FOLDER, output_filename)

    with open(output_file, 'w', encoding='utf-8') as f:
        # å†™å…¥è¡¨å¤´
        f.write("=" * 80 + "\n")
        f.write("ã€ä¹¦ç±éš¾åº¦åˆ†ææŠ¥å‘Šã€‘\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"æ–‡ä»¶å: {base_filename}\n")
        f.write(f"æ–‡ä»¶ç¼–ç : {file_encoding.upper() if file_encoding else 'æœªçŸ¥'}\n")
        f.write(f"æ€»å­—ç¬¦æ•°: {total_chars}\n")
        f.write(f"å­—ç§æ•°: {len(char_counter)} ä¸ªï¼ˆå…¶ä¸­å‰1500å†…: {len(char_counter) - extra_char_types} ä¸ªï¼Œå‰1500å¤–: {extra_char_types} ä¸ªï¼‰\n")
        f.write("=" * 80 + "\n\n")

        # ========== æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡ï¼ˆå½¢ç ç”¨æˆ·æœ€å…³å¿ƒï¼‰ ==========
        f.write("ã€æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡ã€‘\n")
        f.write("=" * 80 + "\n\n")

        # 1. ä¹¦ç±éš¾åº¦è¯„çº§
        f.write(f"1. ä¹¦ç±éš¾åº¦è¯„çº§\n")
        f.write(f"   {stars}  ï¼ˆéš¾åº¦åˆ†æ•°ï¼š{difficulty_score:.1f}/100ï¼‰\n\n")
        f.write(f"   è¯„ä¼°ç»´åº¦ï¼š\n")

        # åªæ˜¾ç¤ºæƒé‡>0çš„ç»´åº¦
        if WEIGHT_CHAR_TYPES > 0:
            f.write(f"     â€¢ å­—ç§æ•°ï¼š{len(char_counter)} ä¸ªï¼ˆå‰1500å†…: {len(char_counter) - extra_char_types} ä¸ªï¼Œå‰1500å¤–: {extra_char_types} ä¸ªï¼‰\n")

        if WEIGHT_COVERAGE_500 > 0:
            f.write(f"     â€¢ å‰500å­—è¦†ç›–ç‡ï¼š{coverage_stats[500]['coverage']:.2f}%\n")
        if WEIGHT_COVERAGE_1000 > 0:
            f.write(f"     â€¢ å‰1000å­—è¦†ç›–ç‡ï¼š{coverage_stats[1000]['coverage']:.2f}%\n")
        if WEIGHT_COVERAGE_1500 > 0:
            f.write(f"     â€¢ å‰1500å­—è¦†ç›–ç‡ï¼š{coverage_stats[1500]['coverage']:.2f}%\n")

        # æ‰¾å‡º95%å’Œ99%æ‰€éœ€å­—æ•°
        chars_95, chars_99 = 0, 0
        for target_pct, char_count, _ in cumulative_coverage:
            if target_pct == 95:
                chars_95 = char_count
            if target_pct == 99:
                chars_99 = char_count

        if WEIGHT_CHARS_95 > 0:
            f.write(f"     â€¢ 95%è¦†ç›–æ‰€éœ€å­—æ•°ï¼š{chars_95} ä¸ªï¼ˆå‰{CHAR_TYPES_BASELINE}å†…: {chars_95_in_ref}ï¼Œå‰{CHAR_TYPES_BASELINE}å¤–: {chars_95_out_ref}ï¼‰\n")
        if WEIGHT_CHARS_99 > 0:
            f.write(f"     â€¢ 99%è¦†ç›–æ‰€éœ€å­—æ•°ï¼š{chars_99} ä¸ªï¼ˆå‰{CHAR_TYPES_BASELINE}å†…: {chars_99_in_ref}ï¼Œå‰{CHAR_TYPES_BASELINE}å¤–: {chars_99_out_ref}ï¼‰\n")

        # æ·»åŠ å¹³å‡å­—åº
        if WEIGHT_ORDER_95 > 0:
            if avg_order_95 is not None:
                f.write(f"     â€¢ 95%å¹³å‡å­—åºï¼š{avg_order_95:.1f}  ï¼ˆå­—åºè¶Šå°=è¶Šå¸¸ç”¨ï¼‰\n")
            else:
                f.write(f"     â€¢ 95%å¹³å‡å­—åºï¼šæ— æ•°æ®\n")

        if WEIGHT_ORDER_99 > 0:
            if avg_order_99 is not None:
                f.write(f"     â€¢ 99%å¹³å‡å­—åºï¼š{avg_order_99:.1f}  ï¼ˆå­—åºè¶Šå°=è¶Šå¸¸ç”¨ï¼‰\n")
            else:
                f.write(f"     â€¢ 99%å¹³å‡å­—åºï¼šæ— æ•°æ®\n")
        f.write("\n")
        f.write(f"   ğŸ’¡ è¯´æ˜ï¼š\n")
        # åŠ¨æ€è®¡ç®—æƒé‡åˆ†é…ï¼ˆåªæ˜¾ç¤ºé0æƒé‡ï¼‰
        total_weight = score_details['total_weight']
        if total_weight > 0:
            weight_parts = []
            coverage_weight = WEIGHT_COVERAGE_500 + WEIGHT_COVERAGE_1000 + WEIGHT_COVERAGE_1500
            if coverage_weight > 0:
                coverage_pct = coverage_weight / total_weight * 100
                weight_parts.append(f"è¦†ç›–ç‡{coverage_pct:.0f}%")

            chars_weight = WEIGHT_CHARS_95 + WEIGHT_CHARS_99
            if chars_weight > 0:
                chars_pct = chars_weight / total_weight * 100
                weight_parts.append(f"å­—æ•°{chars_pct:.0f}%")

            order_weight = WEIGHT_ORDER_95 + WEIGHT_ORDER_99
            if order_weight > 0:
                order_pct = order_weight / total_weight * 100
                weight_parts.append(f"å­—åº{order_pct:.0f}%")

            if WEIGHT_CHAR_TYPES > 0:
                types_pct = WEIGHT_CHAR_TYPES / total_weight * 100
                weight_parts.append(f"å­—ç§{types_pct:.0f}%")

            f.write(f"     - æƒé‡åˆ†é…ï¼š{' + '.join(weight_parts)}\n")
        else:
            f.write(f"     - æƒé‡åˆ†é…ï¼šæœªè®¾ç½®\n")
        f.write("\n")

        # 2. ç”Ÿåƒ»å­—åˆ†æ
        f.write(f"2. ç”Ÿåƒ»å­—åˆ†æ\n")
        f.write(f"   ç”Ÿåƒ»å­—å­—ç§æ•°ï¼š{rare_analysis['rare_type_count']} ä¸ªï¼ˆå å­—ç§{rare_analysis['rare_type_ratio']*100:.2f}%ï¼‰\n")
        f.write(f"   ç”Ÿåƒ»å­—å‡ºç°æ¬¡æ•°ï¼š{rare_analysis['rare_char_count']} æ¬¡ï¼ˆå æ–‡æœ¬{rare_analysis['rare_char_ratio']*100:.2f}%ï¼‰\n")
        f.write(f"   è¯´æ˜ï¼šç”Ÿåƒ»å­—æŒ‡ä¸åœ¨å¸¸ç”¨3500å­—å†…çš„å­—ï¼Œæ‰“å­—æ—¶å¯èƒ½éœ€è¦æŸ¥ç¼–ç \n")

        # æ˜¾ç¤ºå‰20ä¸ªæœ€å¸¸è§çš„ç”Ÿåƒ»å­—
        if rare_analysis['rare_chars']:
            f.write(f"\n   æœ€å¸¸è§çš„ç”Ÿåƒ»å­—ï¼ˆå‰20ä¸ªï¼‰ï¼š\n")
            top_rare = rare_analysis['rare_chars'][:20]
            for i in range(0, len(top_rare), 10):
                chars_line = "ã€".join([f"{char}({count})" for char, count in top_rare[i:i+10]])
                f.write(f"   {chars_line}\n")

        f.write("\n" + "=" * 80 + "\n\n")

        # é«˜é¢‘å­—è¦†ç›–ç‡åˆ†æ
        f.write("ã€é«˜é¢‘å­—è¦†ç›–ç‡åˆ†æã€‘\n")
        f.write(f"   {'åŒºé—´':<12}{'å®é™…å­—æ•°':<12}{'ç´¯è®¡æ¬¡æ•°':<15}{'è¦†ç›–ç‡':<15}{'å¹³å‡å‡ºç°æ¬¡æ•°':<15}\n")
        f.write(f"   {'-'*70}\n")

        for n in stats_ranges:
            stats = coverage_stats[n]
            f.write(f"   å‰{n:<8}  {stats['actual_n']:<10}  "
                   f"{stats['total_count']:<13}  {stats['coverage']:.2f}%{'':<10}  "
                   f"{stats['avg_count']:<13.1f}\n")

        # 1. ç´¯ç§¯è¦†ç›–ç‡åˆ†æ
        f.write(f"\n1. ç´¯ç§¯è¦†ç›–ç‡åˆ†æ\n")
        f.write(f"   {'è¦†ç›–ç‡':<15}{'æ‰€éœ€å­—æ•°':<15}\n")
        f.write(f"   {'-'*30}\n")
        for target_pct, char_count, actual_pct in cumulative_coverage:
            f.write(f"   {actual_pct:.2f}%{'':<10}{char_count}\n")

        # 2. æœ€é«˜é¢‘å­—åˆ†æ
        f.write(f"\n2. æœ€é«˜é¢‘å­—åˆ†æ\n")
        top_char, top_count = all_chars_by_freq[0]
        top_pct = (top_count / total_chars) * 100
        f.write(f"   æœ€é«˜é¢‘å­—: '{top_char}' å‡ºç° {top_count} æ¬¡ï¼Œå æ¯” {top_pct:.2f}%\n")

        if len(all_chars_by_freq) >= 3:
            top3_count = sum(count for char, count in all_chars_by_freq[:3])
            top3_pct = (top3_count / total_chars) * 100
            top3_chars = 'ã€'.join([char for char, count in all_chars_by_freq[:3]])
            f.write(f"   å‰3ä¸ªå­—: {top3_chars}ï¼Œç´¯è®¡å æ¯” {top3_pct:.2f}%\n")

        if len(all_chars_by_freq) >= 10:
            top10_count = sum(count for char, count in all_chars_by_freq[:10])
            top10_pct = (top10_count / total_chars) * 100
            f.write(f"   å‰10ä¸ªå­—: ç´¯è®¡å æ¯” {top10_pct:.2f}%\n")

        # 3. ä½é¢‘å­—åˆ†æ
        f.write(f"\n3. ä½é¢‘å­—åˆ†æ\n")
        once_chars = [char for char, count in char_counter.items() if count == 1]
        twice_chars = [char for char, count in char_counter.items() if count == 2]
        low_freq_chars = [char for char, count in char_counter.items() if count <= 5]

        f.write(f"   ä»…å‡ºç°1æ¬¡çš„å­—: {len(once_chars)} ä¸ª ({len(once_chars)/len(char_counter)*100:.2f}%)\n")
        f.write(f"   ä»…å‡ºç°2æ¬¡çš„å­—: {len(twice_chars)} ä¸ª ({len(twice_chars)/len(char_counter)*100:.2f}%)\n")
        f.write(f"   å‡ºç°â‰¤5æ¬¡çš„å­—: {len(low_freq_chars)} ä¸ª ({len(low_freq_chars)/len(char_counter)*100:.2f}%)\n")

        f.write("\n" + "=" * 80 + "\n\n")

        # æ·»åŠ è¯¦ç»†ç®—å¼å±•ç¤ºï¼ˆåªæ˜¾ç¤ºæƒé‡>0çš„ç»´åº¦ï¼‰
        f.write(f"   ğŸ“Š éš¾åº¦è®¡ç®—è¯¦æƒ…ï¼š\n")
        f.write(f"   ------------------------------------------------------------------\n")

        # è¦†ç›–ç‡ç»´åº¦
        coverage_weight = WEIGHT_COVERAGE_500 + WEIGHT_COVERAGE_1000 + WEIGHT_COVERAGE_1500
        if coverage_weight > 0:
            score_500, weight_500, val_500 = score_details['coverage_500']
            score_1000, weight_1000, val_1000 = score_details['coverage_1000']
            score_1500, weight_1500, val_1500 = score_details['coverage_1500']
            coverage_total = score_500 + score_1000 + score_1500
            coverage_pct = coverage_weight / total_weight * 100 if total_weight > 0 else 0

            f.write(f"   ã€è¦†ç›–ç‡ç»´åº¦ã€‘ (æƒé‡ {coverage_pct:.0f}%)\n")
            if COVERAGE_LINEAR_MODE:
                f.write(f"     è¯„åˆ†æ ‡å‡†: 0%â†’æ»¡åˆ† (æœ€éš¾), 100%â†’0åˆ† (æœ€ç®€å•), åŠ é€Ÿç³»æ•°={COVERAGE_ACCELERATION}\n")
            else:
                f.write(f"     è¯„åˆ†æ ‡å‡†: åŒºé—´æ¨¡å¼, 500å­—({COVERAGE_500_MIN}%-{COVERAGE_500_MAX}%), ")
                f.write(f"1000å­—({COVERAGE_1000_MIN}%-{COVERAGE_1000_MAX}%), ")
                f.write(f"1500å­—({COVERAGE_1500_MIN}%-{COVERAGE_1500_MAX}%)\n")

            if weight_500 > 0:
                f.write(f"     å‰500å­—è¦†ç›–: {val_500:.1f}% â†’ å¾—åˆ† {score_500:.2f}/{weight_500}\n")
            if weight_1000 > 0:
                f.write(f"     å‰1000å­—è¦†ç›–: {val_1000:.1f}% â†’ å¾—åˆ† {score_1000:.2f}/{weight_1000}\n")
            if weight_1500 > 0:
                f.write(f"     å‰1500å­—è¦†ç›–: {val_1500:.1f}% â†’ å¾—åˆ† {score_1500:.2f}/{weight_1500}\n")
            f.write(f"     å°è®¡: {coverage_total:.2f}\n\n")

        # å­—æ•°ç»´åº¦
        chars_weight = WEIGHT_CHARS_95 + WEIGHT_CHARS_99
        if chars_weight > 0:
            score_95c, weight_95c, val_95c = score_details['chars_95']
            score_99c, weight_99c, val_99c = score_details['chars_99']
            chars_total = score_95c + score_99c
            chars_pct = chars_weight / total_weight * 100 if total_weight > 0 else 0

            f.write(f"   ã€å­—æ•°ç»´åº¦ã€‘ (æƒé‡ {chars_pct:.0f}%)\n")
            f.write(f"     è¯„åˆ†æ ‡å‡†: 95%åŒºé—´[{CHARS_95_MIN}-{CHARS_95_MAX}å­—], 99%åŒºé—´[{CHARS_99_MIN}-{CHARS_99_MAX}å­—]\n")
            if weight_95c > 0:
                f.write(f"     95%è¦†ç›–å­—æ•°: {val_95c} ä¸ª â†’ å¾—åˆ† {score_95c:.2f}/{weight_95c}\n")
            if weight_99c > 0:
                f.write(f"     99%è¦†ç›–å­—æ•°: {val_99c} ä¸ª â†’ å¾—åˆ† {score_99c:.2f}/{weight_99c}\n")
            f.write(f"     å°è®¡: {chars_total:.2f}\n\n")

        # å­—åºç»´åº¦
        order_weight = WEIGHT_ORDER_95 + WEIGHT_ORDER_99
        if order_weight > 0:
            score_95o, weight_95o, val_95o = score_details['order_95']
            score_99o, weight_99o, val_99o = score_details['order_99']
            order_total = score_95o + score_99o
            order_pct = order_weight / total_weight * 100 if total_weight > 0 else 0

            f.write(f"   ã€å­—åºç»´åº¦ã€‘ (æƒé‡ {order_pct:.0f}%)\n")
            f.write(f"     è¯„åˆ†æ ‡å‡†: 95%åŒºé—´[{ORDER_95_MIN}-{ORDER_95_MAX}], 99%åŒºé—´[{ORDER_99_MIN}-{ORDER_99_MAX}], åŠ é€Ÿç³»æ•°={ORDER_ACCELERATION}\n")
            if weight_95o > 0:
                if val_95o is not None:
                    f.write(f"     95%å¹³å‡å­—åº: {val_95o:.1f} â†’ å¾—åˆ† {score_95o:.2f}/{weight_95o}\n")
                else:
                    f.write(f"     95%å¹³å‡å­—åº: æ— æ•°æ® â†’ å¾—åˆ† {score_95o:.2f}/{weight_95o}\n")
            if weight_99o > 0:
                if val_99o is not None:
                    f.write(f"     99%å¹³å‡å­—åº: {val_99o:.1f} â†’ å¾—åˆ† {score_99o:.2f}/{weight_99o}\n")
                else:
                    f.write(f"     99%å¹³å‡å­—åº: æ— æ•°æ® â†’ å¾—åˆ† {score_99o:.2f}/{weight_99o}\n")
            f.write(f"     å°è®¡: {order_total:.2f}\n\n")

        # å­—ç§ç»´åº¦
        if WEIGHT_CHAR_TYPES > 0:
            score_types, weight_types, val_types = score_details['char_types']
            types_pct = WEIGHT_CHAR_TYPES / total_weight * 100 if total_weight > 0 else 0

            f.write(f"   ã€å­—ç§ç»´åº¦ã€‘ (æƒé‡ {types_pct:.0f}%)\n")
            f.write(f"     è¯„åˆ†æ ‡å‡†: å‰{CHAR_TYPES_BASELINE}å­—å¤–çš„å­—ç§æ•°, åŒºé—´[{CHAR_TYPES_MIN}-{CHAR_TYPES_MAX}ä¸ª]\n")
            f.write(f"     å‰1500å¤–å­—ç§: {val_types} ä¸ª â†’ å¾—åˆ† {score_types:.2f}/{weight_types}\n")
            f.write(f"     å°è®¡: {score_types:.2f}\n\n")

        # æ€»åˆ†è®¡ç®—
        raw_score = score_details['raw_score']
        f.write(f"   ã€æ€»åˆ†è®¡ç®—ã€‘\n")
        f.write(f"     åŸå§‹å¾—åˆ†: {raw_score:.2f}\n")
        f.write(f"     æ€»æƒé‡: {total_weight:.2f}\n")
        f.write(f"     å½’ä¸€åŒ–å…¬å¼: (åŸå§‹å¾—åˆ† / æ€»æƒé‡) Ã— 100\n")
        f.write(f"     æœ€ç»ˆéš¾åº¦: ({raw_score:.2f} / {total_weight:.2f}) Ã— 100 = {difficulty_score:.1f} åˆ†\n")
        f.write(f"   ------------------------------------------------------------------\n")
        f.write("\n")

        # å†™å…¥è¯¦ç»†å­—é¢‘è¡¨
        f.write("ã€è¯¦ç»†å­—é¢‘ç»Ÿè®¡è¡¨ã€‘\n")
        f.write("=" * 80 + "\n")
        f.write(f"{'å­—':<5}{'æ¬¡æ•°':<10}{'æ¯”ä¾‹(%)':<12}{'åŸæ¬¡åº':<10}\n")
        f.write("=" * 80 + "\n")

        # å†™å…¥åœ¨dict.yamlä¸­çš„å­—
        for char, count, order in chars_in_dict:
            percentage = (count / total_chars) * 100
            f.write(f"{char:<5}{count:<10}{percentage:<12.2f}{order:<10}\n")

        # å†™å…¥ä¸åœ¨dict.yamlä¸­çš„å­—
        if chars_not_in_dict:
            f.write("\n" + "-" * 80 + "\n")
            f.write("ä»¥ä¸‹å­—ç¬¦ä¸åœ¨dict.yamlä¸­ï¼ˆæŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åˆ—ï¼‰:\n")
            f.write("-" * 80 + "\n")
            for char, count in chars_not_in_dict:
                percentage = (count / total_chars) * 100
                f.write(f"{char:<5}{count:<10}{percentage:<12.2f}{'N/A':<10}\n")

        # å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒºï¼Œç¡®ä¿æ•°æ®ç«‹å³å†™å…¥ç£ç›˜
        f.flush()
        os.fsync(f.fileno())

    print(f"\nç»Ÿè®¡å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    # æ˜¾ç¤ºæ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡
    print("\n" + "=" * 70)
    print("ã€æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡ã€‘")
    print("=" * 70)
    print(f"æ–‡ä»¶: {base_filename}")
    print(f"ä¹¦ç±éš¾åº¦: {stars}  ({difficulty_score:.1f}/100)")
    print(f"å­—ç§æ•°: {len(char_counter)} ä¸ªï¼ˆå‰1500å†…: {len(char_counter) - extra_char_types}ï¼Œå‰1500å¤–: {extra_char_types}ï¼‰")
    print(f"ç”Ÿåƒ»å­—: {rare_analysis['rare_type_count']} ä¸ªï¼ˆ{rare_analysis['rare_type_ratio']*100:.1f}%ï¼‰")
    print(f"\nè¦†ç›–ç‡åˆ†æ:")
    print(f"  å‰500å­—:  {coverage_stats[500]['coverage']:.1f}%")
    print(f"  å‰1000å­—: {coverage_stats[1000]['coverage']:.1f}%")
    print(f"  å‰1500å­—: {coverage_stats[1500]['coverage']:.1f}%")

    # æ‰¾å‡º95%å’Œ99%çš„æ•°æ®
    chars_95, chars_99 = 0, 0
    for target_pct, char_count, _ in cumulative_coverage:
        if target_pct == 95:
            chars_95 = char_count
        if target_pct == 99:
            chars_99 = char_count

    print(f"\nç´¯ç§¯è¦†ç›–:")
    print(f"  95%: {chars_95}ä¸ªå­—", end="")
    if avg_order_95:
        print(f" (å¹³å‡å­—åº {avg_order_95:.0f})")
    else:
        print()
    print(f"  99%: {chars_99}ä¸ªå­—", end="")
    if avg_order_99:
        print(f" (å¹³å‡å­—åº {avg_order_99:.0f})")
    else:
        print()

    print("\n" + "=" * 70)

    # æ•°æ®åº“ä¸Šä¼ ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
    upload_success = False
    if DB_UPLOAD_AVAILABLE:
        try:
            success, returned_conn = handle_database_upload(
                base_filename, total_chars, char_counter, coverage_stats,
                avg_order_95, avg_order_99, chars_95, chars_99,
                chars_95_in_ref, chars_95_out_ref, chars_99_in_ref, chars_99_out_ref,
                extra_char_types, difficulty_score, stars, rare_analysis,
                batch_mode=batch_mode,
                db_conn=db_conn,
                db_config=db_config
            )
            upload_success = success
            # æ‰¹é‡æ¨¡å¼ä¸‹ï¼Œè¿”å›æ›´æ–°åçš„è¿æ¥
            if batch_mode and returned_conn is not None:
                db_conn = returned_conn

            # è¿”å›æ•°æ®åº“è¿æ¥ä¾›æ‰¹é‡æ¨¡å¼å¤ç”¨
            return {
                'filename': base_filename,
                'total_chars': total_chars,
                'char_type_count': len(char_counter),
                'extra_char_types': extra_char_types,
                'rare_type_count': rare_analysis['rare_type_count'],
                'rare_type_ratio': rare_analysis['rare_type_ratio'],
                'coverage_500': coverage_stats[500]['coverage'],
                'coverage_1000': coverage_stats[1000]['coverage'],
                'coverage_1500': coverage_stats[1500]['coverage'],
                'chars_95': chars_95,
                'chars_99': chars_99,
                'avg_order_95': avg_order_95,
                'avg_order_99': avg_order_99,
                'difficulty_score': difficulty_score,
                'stars': stars,
                'db_conn': db_conn,
                'db_config': db_config,
                'upload_success': upload_success
            }
        except Exception as e:
            print(f"\næ•°æ®åº“ä¸Šä¼ å‡ºé”™ï¼ˆå·²è·³è¿‡ï¼‰: {e}")

    # è¿”å›ç»Ÿè®¡ç»“æœç”¨äºæ±‡æ€»æŠ¥å‘Š
    return {
        'filename': base_filename,
        'total_chars': total_chars,
        'char_type_count': len(char_counter),
        'extra_char_types': extra_char_types,  # è¶…å‡ºå‰1500çš„å­—ç§æ•°
        'rare_type_count': rare_analysis['rare_type_count'],
        'rare_type_ratio': rare_analysis['rare_type_ratio'],
        'coverage_500': coverage_stats[500]['coverage'],
        'coverage_1000': coverage_stats[1000]['coverage'],
        'coverage_1500': coverage_stats[1500]['coverage'],
        'chars_95': chars_95,
        'chars_99': chars_99,
        'avg_order_95': avg_order_95,
        'avg_order_99': avg_order_99,
        'difficulty_score': difficulty_score,
        'stars': stars,
        'upload_success': upload_success
    }


def generate_summary_report(results):
    """ç”Ÿæˆæ‰€æœ‰ä¹¦ç±çš„æ±‡æ€»æŠ¥å‘Š"""
    output_file = os.path.join(OUTPUT_FOLDER, "ã€æ±‡æ€»æŠ¥å‘Šã€‘æ‰€æœ‰ä¹¦ç±éš¾åº¦å¯¹æ¯”.txt")

    # æŒ‰éš¾åº¦åˆ†æ•°æ’åº
    results_sorted = sorted(results, key=lambda x: x['difficulty_score'])

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("ã€æ‰€æœ‰ä¹¦ç±éš¾åº¦æ±‡æ€»æŠ¥å‘Šã€‘\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"ç»Ÿè®¡æ—¶é—´: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"ç»Ÿè®¡ä¹¦ç±æ•°: {len(results)} æœ¬\n")
        f.write("=" * 80 + "\n\n")

        # æŒ‰éš¾åº¦æ’åºçš„è¡¨æ ¼
        f.write("ã€æŒ‰éš¾åº¦æ’åºã€‘\n")
        f.write("-" * 80 + "\n")
        f.write(f"{'æ’å':<6}{'ä¹¦å':<30}{'éš¾åº¦':<8}{'åˆ†æ•°':<10}{'å­—ç§æ•°':<10}{'ç”Ÿåƒ»å­—':<10}\n")
        f.write("-" * 80 + "\n")

        for idx, r in enumerate(results_sorted, start=1):
            # æˆªæ–­è¿‡é•¿çš„æ–‡ä»¶å
            filename = r['filename'][:28] + '..' if len(r['filename']) > 30 else r['filename']
            f.write(f"{idx:<6}{filename:<30}{r['stars']:<8}{r['difficulty_score']:<10.1f}"
                   f"{r['char_type_count']:<10}{r['rare_type_count']:<10}\n")

        f.write("\n" + "=" * 80 + "\n\n")

        # è¯¦ç»†å¯¹æ¯”è¡¨
        f.write("ã€è¯¦ç»†æ•°æ®å¯¹æ¯”ã€‘\n")
        f.write("-" * 80 + "\n")

        for r in results_sorted:
            f.write(f"\nğŸ“– {r['filename']}\n")
            f.write(f"   éš¾åº¦: {r['stars']}  ({r['difficulty_score']:.1f}/100)\n")
            f.write(f"   å­—ç§æ•°: {r['char_type_count']} ä¸ªï¼ˆå‰1500å†…: {r['char_type_count'] - r['extra_char_types']}ï¼Œå‰1500å¤–: {r['extra_char_types']}ï¼‰\n")
            f.write(f"   ç”Ÿåƒ»å­—: {r['rare_type_count']} ä¸ª ({r['rare_type_ratio']*100:.1f}%)\n")
            f.write(f"   è¦†ç›–ç‡: å‰500å­—={r['coverage_500']:.1f}% | "
                   f"å‰1000å­—={r['coverage_1000']:.1f}% | "
                   f"å‰1500å­—={r['coverage_1500']:.1f}%\n")
            f.write(f"   ç´¯ç§¯è¦†ç›–: 95%éœ€{r['chars_95']}å­— | 99%éœ€{r['chars_99']}å­—\n")
            if r['avg_order_95'] and r['avg_order_99']:
                f.write(f"   å¹³å‡å­—åº: 95%={r['avg_order_95']:.0f} | 99%={r['avg_order_99']:.0f}\n")
            f.write("\n")

        f.write("=" * 80 + "\n\n")

        # ç»Ÿè®¡åˆ†æ
        f.write("ã€ç»Ÿè®¡åˆ†æã€‘\n")
        f.write("-" * 80 + "\n")

        scores = [r['difficulty_score'] for r in results]
        f.write(f"å¹³å‡éš¾åº¦: {sum(scores)/len(scores):.1f}åˆ†\n")
        f.write(f"æœ€ç®€å•: {results_sorted[0]['filename']} ({results_sorted[0]['difficulty_score']:.1f}åˆ†)\n")
        f.write(f"æœ€å›°éš¾: {results_sorted[-1]['filename']} ({results_sorted[-1]['difficulty_score']:.1f}åˆ†)\n")
        f.write(f"éš¾åº¦è·¨åº¦: {results_sorted[-1]['difficulty_score'] - results_sorted[0]['difficulty_score']:.1f}åˆ†\n")

        f.write("\n" + "=" * 80 + "\n")
        f.write("ğŸ’¡ è¯´æ˜ï¼šéš¾åº¦è¯„åˆ†ç»¼åˆè€ƒè™‘å­—ç§æ•°ã€è¦†ç›–ç‡ã€å­—æ•°éœ€æ±‚ã€å­—åºç­‰å¤šä¸ªç»´åº¦\n")
        f.write("=" * 80 + "\n")

    print(f"\næ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
    print(f"å…±ç»Ÿè®¡ {len(results)} æœ¬ä¹¦ç±")


if __name__ == '__main__':
    try:
        main()
    except Exception as e:
        print("\n" + "=" * 70)
        print("ç¨‹åºå‡ºç°é”™è¯¯ï¼š")
        print("=" * 70)
        import traceback
        traceback.print_exc()
        print("\n" + "=" * 70)
        input("\næŒ‰å›è½¦é”®é€€å‡º...")
